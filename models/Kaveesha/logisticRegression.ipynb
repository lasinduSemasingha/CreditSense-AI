{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4441ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2673ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Environment setup complete\n"
     ]
    }
   ],
   "source": [
    "# =============== COMPLETE LOGISTIC REGRESSION MODEL FOR DEFAULT RISK PREDICTION ===============\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix, \n",
    "                           roc_curve, auc, precision_recall_curve, roc_auc_score)\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "print(\"âœ… Environment setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9694d826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 1: DATA LOADING\n",
      "======================================================================\n",
      "âœ… Dataset loaded successfully!\n",
      "   Rows: 188866, Columns: 30\n",
      "\n",
      "ðŸ“Š Dataset Overview:\n",
      "Shape: (188866, 30)\n",
      "Columns: ['Branch', 'FacilityAmount', 'Granted Date', 'Tenor', 'Effective Rate', 'FlatRate', 'Type of Rental Paid', 'SchemeType', 'Prepayment', 'NetRental', 'DownPayment', 'No of Rental in arrears', 'Age', 'ArrearsCapital', 'ArrearsInterest', 'ArrearsVat', 'ArrearsOD', 'ArrearsOther', 'ArrearsInsu', 'ArrearsSundry', 'Advance', 'AdvanceRental', 'AdvanceSundry', 'AdvanceOther', 'Equipment Type', 'Status', 'Last Receipt Paid Amount', 'NET-OUTSTANDING', 'ArrearsInsuEasyPay', 'arrears_intensity']\n",
      "\n",
      "First 3 rows:\n",
      "     Branch  FacilityAmount Granted Date  Tenor  Effective Rate  FlatRate  \\\n",
      "0  GODAGAMA        288330.0     4/9/2018     36            25.0     20.06   \n",
      "1  GODAGAMA        311430.0     4/9/2018     36            25.0     20.33   \n",
      "2  GODAGAMA       2200000.0     4/9/2018     60            20.0     12.43   \n",
      "\n",
      "  Type of Rental Paid SchemeType  Prepayment  NetRental  ...  Advance  \\\n",
      "0             MONTHLY     NORMAL           0    12828.0  ...      0.0   \n",
      "1             MONTHLY     NORMAL           0    13927.0  ...      0.0   \n",
      "2             MONTHLY     NORMAL           0    59459.0  ...      0.0   \n",
      "\n",
      "   AdvanceRental  AdvanceSundry  AdvanceOther  Equipment Type  \\\n",
      "0            0.0              0             0    MOTOR CYCLES   \n",
      "1            0.0              0             0    MOTOR CYCLES   \n",
      "2            0.0              0             0      MOTOR CARS   \n",
      "\n",
      "                       Status  Last Receipt Paid Amount  NET-OUTSTANDING  \\\n",
      "0  Early Settlement Completed                   53241.0              0.0   \n",
      "1                   Write Off                  196000.0              0.0   \n",
      "2  Early Settlement Completed                 2185000.0              0.0   \n",
      "\n",
      "   ArrearsInsuEasyPay  arrears_intensity  \n",
      "0                 0.0                0.0  \n",
      "1                 0.0                0.0  \n",
      "2                 0.0                0.0  \n",
      "\n",
      "[3 rows x 30 columns]\n",
      "\n",
      "Data types:\n",
      "float64    19\n",
      "object      6\n",
      "int64       5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# =============== 1. DATA LOADING ===============\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 1: DATA LOADING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    # Try to load the dataset\n",
    "    df = pd.read_csv('data.csv')\n",
    "    print(f\"âœ… Dataset loaded successfully!\")\n",
    "    print(f\"   Rows: {df.shape[0]}, Columns: {df.shape[1]}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ File 'data.csv' not found in current directory\")\n",
    "    print(\"Creating sample dataset based on your feature specifications...\")\n",
    "    \n",
    "    # Create a sample dataset with your specified features\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    \n",
    "    data = {\n",
    "        'FacilityAmount': np.random.uniform(100000, 500000, n_samples),\n",
    "        'Tenor': np.random.choice([12, 24, 36, 48, 60], n_samples),\n",
    "        'Effective Rate': np.random.uniform(15, 40, n_samples),\n",
    "        'FlatRate': np.random.uniform(10, 30, n_samples),\n",
    "        'NetRental': np.random.uniform(5000, 30000, n_samples),\n",
    "        'DownPayment': np.random.uniform(0, 100000, n_samples),\n",
    "        'Age': np.random.randint(20, 65, n_samples),\n",
    "        'No of Rental in arrears': np.random.poisson(1, n_samples),\n",
    "        'ArrearsCapital': np.random.exponential(10000, n_samples),\n",
    "        'ArrearsInterest': np.random.exponential(5000, n_samples),\n",
    "        'ArrearsVat': np.random.exponential(2000, n_samples),\n",
    "        'ArrearsOD': np.random.exponential(3000, n_samples),\n",
    "        'arrears_intensity': np.random.uniform(0, 0.5, n_samples),\n",
    "        'debt_to_income_ratio': np.random.uniform(10, 50, n_samples),\n",
    "        'payment_coverage': np.random.uniform(10, 50, n_samples),\n",
    "        'arrears_ratio': np.random.uniform(0, 0.3, n_samples),\n",
    "        'overdue_intensity': np.random.uniform(0, 0.4, n_samples),\n",
    "        'payment_regularity': np.random.choice([0, 1], n_samples, p=[0.3, 0.7]),\n",
    "        'has_arrears': np.random.choice([0, 1], n_samples, p=[0.6, 0.4]),\n",
    "        'high_interest_flag': np.random.choice([0, 1], n_samples, p=[0.5, 0.5]),\n",
    "        'early_settlement': np.random.choice([0, 1], n_samples, p=[0.8, 0.2]),\n",
    "        'equipment_risk_score': np.random.choice([1, 2, 3], n_samples),\n",
    "        'branch_encoded': np.random.choice([0, 1, 2], n_samples),\n",
    "        'scheme_encoded': np.random.choice([0, 1], n_samples),\n",
    "        'loan_age': np.random.randint(1, 60, n_samples),\n",
    "        'tenor_to_age_ratio': np.random.uniform(0.1, 2, n_samples),\n",
    "        'Last Receipt Paid Amount': np.random.uniform(5000, 25000, n_samples),\n",
    "        'Prepayment': np.random.uniform(0, 50000, n_samples),\n",
    "        'Status': np.random.choice(['Current Running', 'Write Off', 'Normal Settlement Completed'], \n",
    "                                  n_samples, p=[0.7, 0.1, 0.2])\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"âœ… Created sample dataset with {n_samples} rows\")\n",
    "    df.to_csv('kaveesha_sample.csv', index=False)\n",
    "    print(\"âœ… Sample dataset saved as 'kaveesha_sample.csv'\")\n",
    "\n",
    "# Display basic info\n",
    "print(\"\\nðŸ“Š Dataset Overview:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst 3 rows:\")\n",
    "print(df.head(3))\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2feeac06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 2: DATA CLEANING\n",
      "======================================================================\n",
      "ðŸ” Checking for missing values...\n",
      "Missing values found:\n",
      "                          Missing_Count  Missing_Percentage\n",
      "Last Receipt Paid Amount           1173            0.621075\n",
      "Equipment Type                     1127            0.596719\n",
      "DownPayment                         293            0.155136\n",
      "NetRental                           293            0.155136\n",
      "FlatRate                            293            0.155136\n",
      "arrears_intensity                   231            0.122309\n",
      "Granted Date                         40            0.021179\n",
      "\n",
      "ðŸ”„ Handling missing values...\n",
      "  âœ… Granted Date: Filled with mode ('2/28/2025')\n",
      "  âœ… FlatRate: Filled 0 values with median (21.52)\n",
      "  âœ… NetRental: Filled 0 values with median (13758.00)\n",
      "  âœ… DownPayment: Filled 0 values with median (0.00)\n",
      "  âœ… Equipment Type: Filled with mode ('MOTOR CYCLES')\n",
      "  âœ… Last Receipt Paid Amount: Filled 0 values with median (26522.00)\n",
      "  âœ… arrears_intensity: Filled 0 values with median (0.00)\n",
      "âœ… Missing values handled. Remaining missing: 0\n",
      "\n",
      "ðŸ“ Checking data types...\n",
      "  âœ… Removed 118 duplicate rows\n"
     ]
    }
   ],
   "source": [
    "# =============== 2. DATA CLEANING ===============\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 2: DATA CLEANING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 2.1 Check for missing values\n",
    "print(\"ðŸ” Checking for missing values...\")\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing_values,\n",
    "    'Missing_Percentage': missing_percentage\n",
    "}).sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "missing_cols = missing_df[missing_df['Missing_Count'] > 0]\n",
    "if len(missing_cols) > 0:\n",
    "    print(\"Missing values found:\")\n",
    "    print(missing_cols)\n",
    "else:\n",
    "    print(\"âœ… No missing values found!\")\n",
    "\n",
    "# 2.2 Handle missing values\n",
    "print(\"\\nðŸ”„ Handling missing values...\")\n",
    "for column in df.columns:\n",
    "    if df[column].isnull().sum() > 0:\n",
    "        # For numerical columns\n",
    "        if df[column].dtype in ['int64', 'float64', 'int32', 'float32']:\n",
    "            median_val = df[column].median()\n",
    "            df[column].fillna(median_val, inplace=True)\n",
    "            print(f\"  âœ… {column}: Filled {df[column].isnull().sum()} values with median ({median_val:.2f})\")\n",
    "        # For categorical columns\n",
    "        elif df[column].dtype == 'object':\n",
    "            mode_val = df[column].mode()[0] if not df[column].mode().empty else 'Unknown'\n",
    "            df[column].fillna(mode_val, inplace=True)\n",
    "            print(f\"  âœ… {column}: Filled with mode ('{mode_val}')\")\n",
    "\n",
    "print(f\"âœ… Missing values handled. Remaining missing: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# 2.3 Check and fix data types\n",
    "print(\"\\nðŸ“ Checking data types...\")\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object':\n",
    "        try:\n",
    "            # Try to convert to numeric if possible\n",
    "            converted = pd.to_numeric(df[column], errors='coerce')\n",
    "            if converted.notna().sum() > len(df) * 0.7:  # If >70% can be converted\n",
    "                df[column] = converted\n",
    "                print(f\"  âœ… {column}: Converted to numeric\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# 2.4 Remove duplicate rows\n",
    "initial_rows = len(df)\n",
    "df = df.drop_duplicates()\n",
    "final_rows = len(df)\n",
    "duplicates_removed = initial_rows - final_rows\n",
    "if duplicates_removed > 0:\n",
    "    print(f\"  âœ… Removed {duplicates_removed} duplicate rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f59ee6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 3: TARGET VARIABLE CREATION\n",
      "======================================================================\n",
      "Creating target variable based on business rules:\n",
      "  â€¢ High Risk/Default: PD â‰¥ 0.80\n",
      "  â€¢ Medium Risk: 0.20 â‰¤ PD < 0.80\n",
      "  â€¢ Low Risk: PD < 0.20\n",
      "\n",
      "Calculating Probability of Default (PD) scores...\n",
      "\n",
      "ðŸ“Š Risk Distribution:\n",
      "Risk_Category\n",
      "Low Risk       187459\n",
      "Medium Risk      1289\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ðŸ“ˆ Default Rate: 0.00%\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'labels' must be of length 'x', not 2",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 155\u001b[39m\n\u001b[32m    153\u001b[39m default_counts = df[\u001b[33m'\u001b[39m\u001b[33mDefault\u001b[39m\u001b[33m'\u001b[39m].value_counts()\n\u001b[32m    154\u001b[39m labels = [\u001b[33m'\u001b[39m\u001b[33mNon-Default\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mDefault\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpie\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefault_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautopct\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m%1.1f\u001b[39;49;00m\u001b[38;5;132;43;01m%%\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolors\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m#4CAF50\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m#F44336\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstartangle\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m90\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mDefault Distribution\u001b[39m\u001b[33m'\u001b[39m, fontsize=\u001b[32m12\u001b[39m, fontweight=\u001b[33m'\u001b[39m\u001b[33mbold\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    159\u001b[39m plt.tight_layout()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\matplotlib\\_api\\deprecation.py:453\u001b[39m, in \u001b[36mmake_keyword_only.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    447\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > name_idx:\n\u001b[32m    448\u001b[39m     warn_deprecated(\n\u001b[32m    449\u001b[39m         since, message=\u001b[33m\"\u001b[39m\u001b[33mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    450\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[33m; the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    451\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mparameter will become keyword-only in \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    452\u001b[39m         name=name, obj_type=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m()\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\matplotlib\\pyplot.py:3806\u001b[39m, in \u001b[36mpie\u001b[39m\u001b[34m(x, explode, labels, colors, autopct, pctdistance, shadow, labeldistance, startangle, radius, counterclock, wedgeprops, textprops, center, frame, rotatelabels, normalize, hatch, data)\u001b[39m\n\u001b[32m   3783\u001b[39m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes.pie)\n\u001b[32m   3784\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpie\u001b[39m(\n\u001b[32m   3785\u001b[39m     x: ArrayLike,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3804\u001b[39m     data=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   3805\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Wedge], \u001b[38;5;28mlist\u001b[39m[Text]] | \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Wedge], \u001b[38;5;28mlist\u001b[39m[Text], \u001b[38;5;28mlist\u001b[39m[Text]]:\n\u001b[32m-> \u001b[39m\u001b[32m3806\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpie\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3807\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3808\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexplode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexplode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3809\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3810\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3811\u001b[39m \u001b[43m        \u001b[49m\u001b[43mautopct\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautopct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3812\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpctdistance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpctdistance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshadow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshadow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3814\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabeldistance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabeldistance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3815\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstartangle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstartangle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3816\u001b[39m \u001b[43m        \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m=\u001b[49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3817\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcounterclock\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcounterclock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3818\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwedgeprops\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwedgeprops\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3819\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtextprops\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtextprops\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3820\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3821\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3822\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrotatelabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrotatelabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3823\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3825\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\matplotlib\\_api\\deprecation.py:453\u001b[39m, in \u001b[36mmake_keyword_only.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    447\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > name_idx:\n\u001b[32m    448\u001b[39m     warn_deprecated(\n\u001b[32m    449\u001b[39m         since, message=\u001b[33m\"\u001b[39m\u001b[33mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    450\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[33m; the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    451\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mparameter will become keyword-only in \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    452\u001b[39m         name=name, obj_type=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m()\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\matplotlib\\__init__.py:1524\u001b[39m, in \u001b[36m_preprocess_data.<locals>.inner\u001b[39m\u001b[34m(ax, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1521\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(ax, *args, data=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m   1523\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1524\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1525\u001b[39m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1526\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1527\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1529\u001b[39m     bound = new_sig.bind(ax, *args, **kwargs)\n\u001b[32m   1530\u001b[39m     auto_label = (bound.arguments.get(label_namer)\n\u001b[32m   1531\u001b[39m                   \u001b[38;5;129;01mor\u001b[39;00m bound.kwargs.get(label_namer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:3376\u001b[39m, in \u001b[36mAxes.pie\u001b[39m\u001b[34m(self, x, explode, labels, colors, autopct, pctdistance, shadow, labeldistance, startangle, radius, counterclock, wedgeprops, textprops, center, frame, rotatelabels, normalize, hatch)\u001b[39m\n\u001b[32m   3374\u001b[39m     explode = [\u001b[32m0\u001b[39m] * \u001b[38;5;28mlen\u001b[39m(x)\n\u001b[32m   3375\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) != \u001b[38;5;28mlen\u001b[39m(labels):\n\u001b[32m-> \u001b[39m\u001b[32m3376\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m\u001b[33m must be of length \u001b[39m\u001b[33m'\u001b[39m\u001b[33mx\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(labels)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   3377\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) != \u001b[38;5;28mlen\u001b[39m(explode):\n\u001b[32m   3378\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mexplode\u001b[39m\u001b[33m'\u001b[39m\u001b[33m must be of length \u001b[39m\u001b[33m'\u001b[39m\u001b[33mx\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(explode)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: 'labels' must be of length 'x', not 2"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============== 3. TARGET VARIABLE CREATION ===============\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3: TARGET VARIABLE CREATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"Creating target variable based on business rules:\")\n",
    "print(\"  â€¢ High Risk/Default: PD â‰¥ 0.80\")\n",
    "print(\"  â€¢ Medium Risk: 0.20 â‰¤ PD < 0.80\")\n",
    "print(\"  â€¢ Low Risk: PD < 0.20\")\n",
    "\n",
    "# 3.1 Create synthetic Probability of Default (PD) based on features\n",
    "def calculate_pd_score(row):\n",
    "    \"\"\"\n",
    "    Calculate Probability of Default based on multiple risk factors\n",
    "    \"\"\"\n",
    "    pd_score = 0.0\n",
    "    \n",
    "    # 1. Arrears indicators (40% weight)\n",
    "    arrears_score = 0.0\n",
    "    \n",
    "    # Number of arrears\n",
    "    if 'No of Rental in arrears' in row.index:\n",
    "        arrears_count = float(row['No of Rental in arrears'] or 0)\n",
    "        if arrears_count > 10:\n",
    "            arrears_score += 0.4\n",
    "        elif arrears_count > 5:\n",
    "            arrears_score += 0.3\n",
    "        elif arrears_count > 0:\n",
    "            arrears_score += 0.2\n",
    "    \n",
    "    # Arrears ratio\n",
    "    if 'arrears_ratio' in row.index:\n",
    "        arrears_ratio = float(row['arrears_ratio'] or 0)\n",
    "        if arrears_ratio > 0.3:\n",
    "            arrears_score += 0.4\n",
    "        elif arrears_ratio > 0.1:\n",
    "            arrears_score += 0.25\n",
    "    \n",
    "    arrears_score = min(arrears_score, 0.8)\n",
    "    pd_score += arrears_score * 0.4\n",
    "    \n",
    "    # 2. Payment behavior (30% weight)\n",
    "    payment_score = 0.0\n",
    "    \n",
    "    # Payment coverage\n",
    "    if 'payment_coverage' in row.index:\n",
    "        coverage = float(row['payment_coverage'] or 25)\n",
    "        if coverage < 10:\n",
    "            payment_score += 0.3\n",
    "        elif coverage < 20:\n",
    "            payment_score += 0.15\n",
    "    \n",
    "    # Payment regularity\n",
    "    if 'payment_regularity' in row.index:\n",
    "        regularity = float(row['payment_regularity'] or 1)\n",
    "        if regularity < 0.5:\n",
    "            payment_score += 0.2\n",
    "    \n",
    "    pd_score += payment_score * 0.3\n",
    "    \n",
    "    # 3. Debt burden (20% weight)\n",
    "    debt_score = 0.0\n",
    "    \n",
    "    # Debt to income ratio\n",
    "    if 'debt_to_income_ratio' in row.index:\n",
    "        dti = float(row['debt_to_income_ratio'] or 25)\n",
    "        if dti > 40:\n",
    "            debt_score += 0.4\n",
    "        elif dti > 30:\n",
    "            debt_score += 0.2\n",
    "    \n",
    "    # High interest flag\n",
    "    if 'high_interest_flag' in row.index:\n",
    "        if float(row['high_interest_flag'] or 0) == 1:\n",
    "            debt_score += 0.1\n",
    "    \n",
    "    pd_score += debt_score * 0.2\n",
    "    \n",
    "    # 4. Customer profile (10% weight)\n",
    "    profile_score = 0.0\n",
    "    \n",
    "    # Age factor\n",
    "    if 'Age' in row.index:\n",
    "        age = float(row['Age'] or 30)\n",
    "        if age > 60:\n",
    "            profile_score += 0.1\n",
    "    \n",
    "    # Early settlement (reduces risk)\n",
    "    if 'early_settlement' in row.index:\n",
    "        if float(row['early_settlement'] or 0) == 1:\n",
    "            profile_score -= 0.05\n",
    "    \n",
    "    pd_score += profile_score * 0.1\n",
    "    \n",
    "    # Add small random variation (Â±0.05)\n",
    "    pd_score += np.random.uniform(-0.05, 0.05)\n",
    "    \n",
    "    # Ensure PD is between 0 and 1\n",
    "    return max(0.0, min(1.0, pd_score))\n",
    "\n",
    "print(\"\\nCalculating Probability of Default (PD) scores...\")\n",
    "df['PD_Score'] = df.apply(calculate_pd_score, axis=1)\n",
    "\n",
    "# 3.2 Create risk categories\n",
    "def create_risk_category(pd_score):\n",
    "    if pd_score >= 0.80:\n",
    "        return 'High Risk'\n",
    "    elif pd_score >= 0.20:\n",
    "        return 'Medium Risk'\n",
    "    else:\n",
    "        return 'Low Risk'\n",
    "\n",
    "df['Risk_Category'] = df['PD_Score'].apply(create_risk_category)\n",
    "\n",
    "# 3.3 Create binary target (Default vs Non-Default)\n",
    "# High Risk = Default (1), Others = Non-Default (0)\n",
    "df['Default'] = (df['Risk_Category'] == 'High Risk').astype(int)\n",
    "\n",
    "print(\"\\nðŸ“Š Risk Distribution:\")\n",
    "print(df['Risk_Category'].value_counts())\n",
    "print(f\"\\nðŸ“ˆ Default Rate: {df['Default'].mean():.2%}\")\n",
    "\n",
    "# 3.4 Visualize risk distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Risk category distribution\n",
    "plt.subplot(1, 3, 1)\n",
    "risk_counts = df['Risk_Category'].value_counts()\n",
    "colors = ['#4CAF50', '#FFC107', '#F44336']\n",
    "plt.bar(risk_counts.index, risk_counts.values, color=colors, alpha=0.8)\n",
    "plt.title('Risk Category Distribution', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Risk Category')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add value labels\n",
    "for i, (category, count) in enumerate(risk_counts.items()):\n",
    "    plt.text(i, count + max(risk_counts.values)*0.01, str(count), \n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Plot 2: PD score distribution\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(df['PD_Score'], bins=30, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "plt.axvline(x=0.2, color='green', linestyle='--', label='Low/Medium Boundary')\n",
    "plt.axvline(x=0.8, color='red', linestyle='--', label='Medium/High Boundary')\n",
    "plt.title('PD Score Distribution', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Probability of Default (PD)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "# Plot 3: Default vs Non-Default\n",
    "plt.subplot(1, 3, 3)\n",
    "default_counts = df['Default'].value_counts()\n",
    "labels = ['Non-Default', 'Default']\n",
    "plt.pie(default_counts, labels=labels, autopct='%1.1f%%', \n",
    "        colors=['#4CAF50', '#F44336'], startangle=90, explode=(0.05, 0.05))\n",
    "plt.title('Default Distribution', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('risk_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "602257c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot 3: Default vs Non-Default\n",
    "plt.subplot(1, 3, 3)\n",
    "default_counts = df['Default'].value_counts()\n",
    "\n",
    "# Handle the case where we might not have both classes\n",
    "default_labels = {0: 'Non-Default', 1: 'Default'}\n",
    "labels = [default_labels.get(idx, f'Class {idx}') for idx in default_counts.index]\n",
    "explode = [0.05] * len(default_counts)  # Dynamic explode based on number of classes\n",
    "\n",
    "plt.pie(default_counts, labels=labels, autopct='%1.1f%%', \n",
    "        colors=['#4CAF50', '#F44336'][:len(default_counts)], \n",
    "        startangle=90, explode=explode)\n",
    "plt.title('Default Distribution', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('risk_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aac983ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot 3: Default vs Non-Default\n",
    "plt.subplot(1, 3, 3)\n",
    "\n",
    "# Ensure we always have both categories even if count is 0\n",
    "default_counts = df['Default'].value_counts().reindex([0, 1], fill_value=0)\n",
    "labels = ['Non-Default', 'Default']\n",
    "colors = ['#4CAF50', '#F44336']\n",
    "explode = (0.05, 0.05)\n",
    "\n",
    "# Only show pie chart if we have data\n",
    "if default_counts.sum() > 0:\n",
    "    plt.pie(default_counts, labels=labels, autopct='%1.1f%%', \n",
    "            colors=colors, startangle=90, explode=explode)\n",
    "    plt.title('Default Distribution', fontsize=12, fontweight='bold')\n",
    "else:\n",
    "    plt.text(0.5, 0.5, 'No data available', \n",
    "             ha='center', va='center', fontsize=12)\n",
    "    plt.title('Default Distribution', fontsize=12, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('risk_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f87b679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 4: FEATURE ENGINEERING & SELECTION\n",
      "======================================================================\n",
      "âœ… 15 out of 28 features available\n",
      "Available features: ['FacilityAmount', 'Tenor', 'Effective Rate', 'FlatRate', 'NetRental', 'DownPayment', 'Age', 'No of Rental in arrears', 'ArrearsCapital', 'ArrearsInterest', 'ArrearsVat', 'ArrearsOD', 'arrears_intensity', 'Last Receipt Paid Amount', 'Prepayment']\n",
      "\n",
      "ðŸ“Š Feature Matrix Shape: (188748, 15)\n",
      "ðŸ“Š Target Vector Shape: (188748,)\n",
      "\n",
      "âœ… Features prepared:\n",
      "  - Missing values handled\n",
      "  - Features scaled (mean=0, std=1)\n",
      "  - Default rate in dataset: 0.00%\n",
      "\n",
      "======================================================================\n",
      "STEP 5: TRAIN-TEST SPLIT\n",
      "======================================================================\n",
      "Training set: 132123 samples (70.0%)\n",
      "Testing set: 56625 samples (30.0%)\n",
      "Total: 188748 samples\n",
      "\n",
      "ðŸ“Š Class distribution in training set:\n",
      "  Non-Default (0): 132123 samples (100.0%)\n",
      "  Default (1): 0 samples (0.0%)\n",
      "\n",
      "ðŸ“Š Class distribution in testing set:\n",
      "  Non-Default (0): 56625 samples (100.0%)\n",
      "  Default (1): 0 samples (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# =============== 4. FEATURE ENGINEERING & SELECTION ===============\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 4: FEATURE ENGINEERING & SELECTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 4.1 Define your features\n",
    "features = [\n",
    "    'FacilityAmount', 'Tenor', 'Effective Rate', 'FlatRate',\n",
    "    'NetRental', 'DownPayment', 'Age', 'No of Rental in arrears',\n",
    "    'ArrearsCapital', 'ArrearsInterest', 'ArrearsVat', 'ArrearsOD',\n",
    "    'arrears_intensity', 'debt_to_income_ratio', 'payment_coverage',\n",
    "    'arrears_ratio', 'overdue_intensity', 'payment_regularity',\n",
    "    'has_arrears', 'high_interest_flag', 'early_settlement',\n",
    "    'equipment_risk_score', 'branch_encoded', 'scheme_encoded',\n",
    "    'loan_age', 'tenor_to_age_ratio', 'Last Receipt Paid Amount',\n",
    "    'Prepayment'\n",
    "]\n",
    "\n",
    "# Check which features are available\n",
    "available_features = [f for f in features if f in df.columns]\n",
    "print(f\"âœ… {len(available_features)} out of {len(features)} features available\")\n",
    "print(f\"Available features: {available_features}\")\n",
    "\n",
    "# 4.2 Create feature matrix and target\n",
    "X = df[available_features].copy()\n",
    "y = df['Default'].copy()  # Binary target: 1 = Default, 0 = Non-Default\n",
    "\n",
    "print(f\"\\nðŸ“Š Feature Matrix Shape: {X.shape}\")\n",
    "print(f\"ðŸ“Š Target Vector Shape: {y.shape}\")\n",
    "\n",
    "# 4.3 Handle any remaining missing values in features\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# 4.4 Scale features (important for logistic regression)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X_imputed), columns=X_imputed.columns)\n",
    "\n",
    "print(\"\\nâœ… Features prepared:\")\n",
    "print(f\"  - Missing values handled\")\n",
    "print(f\"  - Features scaled (mean=0, std=1)\")\n",
    "print(f\"  - Default rate in dataset: {y.mean():.2%}\")\n",
    "\n",
    "# =============== 5. TRAIN-TEST SPLIT ===============\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 5: TRAIN-TEST SPLIT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Split the data (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, \n",
    "    test_size=0.3, \n",
    "    random_state=42,\n",
    "    stratify=y  # Maintain class distribution\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Testing set: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Total: {X_train.shape[0] + X_test.shape[0]} samples\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Class distribution in training set:\")\n",
    "print(f\"  Non-Default (0): {(y_train == 0).sum()} samples ({(y_train == 0).mean()*100:.1f}%)\")\n",
    "print(f\"  Default (1): {(y_train == 1).sum()} samples ({(y_train == 1).mean()*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Class distribution in testing set:\")\n",
    "print(f\"  Non-Default (0): {(y_test == 0).sum()} samples ({(y_test == 0).mean()*100:.1f}%)\")\n",
    "print(f\"  Default (1): {(y_test == 1).sum()} samples ({(y_test == 1).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f10cbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 6: LOGISTIC REGRESSION MODEL TRAINING\n",
      "======================================================================\n",
      "Training Logistic Regression model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining Logistic Regression model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m log_reg = LogisticRegression(\n\u001b[32m     10\u001b[39m     random_state=\u001b[32m42\u001b[39m,\n\u001b[32m     11\u001b[39m     max_iter=\u001b[32m1000\u001b[39m,  \u001b[38;5;66;03m# Ensure convergence\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     C=\u001b[32m1.0\u001b[39m  \u001b[38;5;66;03m# Regularization strength\u001b[39;00m\n\u001b[32m     15\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43mlog_reg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… Model training complete!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# 6.2 Make predictions\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1335\u001b[39m, in \u001b[36mLogisticRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1333\u001b[39m classes_ = \u001b[38;5;28mself\u001b[39m.classes_\n\u001b[32m   1334\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_classes < \u001b[32m2\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1335\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1336\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThis solver needs samples of at least 2 classes\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1337\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m in the data, but the data contains only one\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1338\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m % classes_[\u001b[32m0\u001b[39m]\n\u001b[32m   1339\u001b[39m     )\n\u001b[32m   1341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.classes_) == \u001b[32m2\u001b[39m:\n\u001b[32m   1342\u001b[39m     n_classes = \u001b[32m1\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(0)"
     ]
    }
   ],
   "source": [
    "# =============== 6. LOGISTIC REGRESSION MODEL TRAINING ===============\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 6: LOGISTIC REGRESSION MODEL TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 6.1 Initialize and train the model\n",
    "print(\"Training Logistic Regression model...\")\n",
    "\n",
    "log_reg = LogisticRegression(\n",
    "    random_state=42,\n",
    "    max_iter=1000,  # Ensure convergence\n",
    "    class_weight='balanced',  # Handle class imbalance\n",
    "    solver='lbfgs',  # Good for medium-sized datasets\n",
    "    C=1.0  # Regularization strength\n",
    ")\n",
    "\n",
    "log_reg.fit(X_train, y_train)\n",
    "print(\"âœ… Model training complete!\")\n",
    "\n",
    "# 6.2 Make predictions\n",
    "y_pred = log_reg.predict(X_test)\n",
    "y_pred_proba = log_reg.predict_proba(X_test)[:, 1]  # Probability of Default\n",
    "\n",
    "print(\"\\nðŸ“Š Model Performance Metrics:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nðŸ“‹ Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Non-Default', 'Default']))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"ðŸ“ˆ Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75232912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 6: LOGISTIC REGRESSION MODEL TRAINING\n",
      "======================================================================\n",
      "Checking class distribution in training data...\n",
      "Unique classes in y_train: [0]\n",
      "Class distribution: [132123]\n",
      "âš ï¸  WARNING: Only one class found in training data!\n",
      "Checking test data...\n",
      "Unique classes in y_test: [0]\n",
      "\n",
      "ðŸ”§ Re-splitting data using StratifiedShuffleSplit to preserve class distribution...\n",
      "âœ… Data re-split with stratification!\n",
      "New y_train classes: [0]\n",
      "New y_train distribution: [150998]\n",
      "\n",
      "Training Logistic Regression model...\n",
      "âš ï¸  Only one class available. Cannot train logistic regression.\n",
      "Skipping to next model...\n",
      "\n",
      "âš ï¸  Cannot calculate metrics - only one class present in test data\n",
      "This suggests a severe class imbalance. Consider:\n",
      "1. Check your target variable creation\n",
      "2. Use stratified sampling\n",
      "3. Consider oversampling/undersampling techniques\n"
     ]
    }
   ],
   "source": [
    "# =============== 6. LOGISTIC REGRESSION MODEL TRAINING ===============\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 6: LOGISTIC REGRESSION MODEL TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# First, check if we have both classes in training data\n",
    "print(\"Checking class distribution in training data...\")\n",
    "unique_classes = np.unique(y_train)\n",
    "print(f\"Unique classes in y_train: {unique_classes}\")\n",
    "print(f\"Class distribution: {np.bincount(y_train.astype(int))}\")\n",
    "\n",
    "if len(unique_classes) < 2:\n",
    "    print(\"âš ï¸  WARNING: Only one class found in training data!\")\n",
    "    print(\"Checking test data...\")\n",
    "    test_classes = np.unique(y_test)\n",
    "    print(f\"Unique classes in y_test: {test_classes}\")\n",
    "    \n",
    "    # If both classes exist in the full dataset but got separated in split\n",
    "    # Use StratifiedShuffleSplit instead\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "    \n",
    "    print(\"\\nðŸ”§ Re-splitting data using StratifiedShuffleSplit to preserve class distribution...\")\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Assuming X and y are your full datasets\n",
    "    for train_idx, test_idx in sss.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    print(\"âœ… Data re-split with stratification!\")\n",
    "    print(f\"New y_train classes: {np.unique(y_train)}\")\n",
    "    print(f\"New y_train distribution: {np.bincount(y_train.astype(int))}\")\n",
    "\n",
    "# 6.1 Initialize and train the model\n",
    "print(\"\\nTraining Logistic Regression model...\")\n",
    "\n",
    "# If still only one class, we need to handle it differently\n",
    "if len(np.unique(y_train)) < 2:\n",
    "    print(\"âš ï¸  Only one class available. Cannot train logistic regression.\")\n",
    "    print(\"Skipping to next model...\")\n",
    "    # You might want to skip or use a different approach\n",
    "    log_reg = None\n",
    "    y_pred = np.zeros_like(y_test)  # Predict all as the single available class\n",
    "    y_pred_proba = np.zeros_like(y_test, dtype=float)\n",
    "else:\n",
    "    log_reg = LogisticRegression(\n",
    "        random_state=42,\n",
    "        max_iter=1000,  # Ensure convergence\n",
    "        class_weight='balanced',  # Handle class imbalance\n",
    "        solver='lbfgs',  # Good for medium-sized datasets\n",
    "        C=1.0  # Regularization strength\n",
    "    )\n",
    "    \n",
    "    log_reg.fit(X_train, y_train)\n",
    "    print(\"âœ… Model training complete!\")\n",
    "    \n",
    "    # 6.2 Make predictions\n",
    "    y_pred = log_reg.predict(X_test)\n",
    "    y_pred_proba = log_reg.predict_proba(X_test)[:, 1]  # Probability of Default\n",
    "\n",
    "# Only calculate metrics if we have both classes in test data\n",
    "if len(np.unique(y_test)) > 1 and log_reg is not None:\n",
    "    print(\"\\nðŸ“Š Model Performance Metrics:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    \n",
    "    # Detailed classification report\n",
    "    print(\"\\nðŸ“‹ Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Non-Default', 'Default']))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    print(\"ðŸ“ˆ Confusion Matrix:\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    \n",
    "    # Visualize confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Non-Default', 'Default'],\n",
    "                yticklabels=['Non-Default', 'Default'])\n",
    "    plt.title('Confusion Matrix - Logistic Regression')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nâš ï¸  Cannot calculate metrics - only one class present in test data\")\n",
    "    print(\"This suggests a severe class imbalance. Consider:\")\n",
    "    print(\"1. Check your target variable creation\")\n",
    "    print(\"2. Use stratified sampling\")\n",
    "    print(\"3. Consider oversampling/undersampling techniques\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec96c91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 7: VISUALIZATIONS\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Visualization 1: Confusion Matrix Heatmap\u001b[39;00m\n\u001b[32m      7\u001b[39m plt.figure(figsize=(\u001b[32m8\u001b[39m, \u001b[32m6\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m sns.heatmap(\u001b[43mcm\u001b[49m, annot=\u001b[38;5;28;01mTrue\u001b[39;00m, fmt=\u001b[33m'\u001b[39m\u001b[33md\u001b[39m\u001b[33m'\u001b[39m, cmap=\u001b[33m'\u001b[39m\u001b[33mBlues\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m      9\u001b[39m             xticklabels=[\u001b[33m'\u001b[39m\u001b[33mNon-Default\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mDefault\u001b[39m\u001b[33m'\u001b[39m], \n\u001b[32m     10\u001b[39m             yticklabels=[\u001b[33m'\u001b[39m\u001b[33mNon-Default\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mDefault\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     11\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mConfusion Matrix - Logistic Regression\u001b[39m\u001b[33m'\u001b[39m, fontsize=\u001b[32m14\u001b[39m, fontweight=\u001b[33m'\u001b[39m\u001b[33mbold\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     12\u001b[39m plt.ylabel(\u001b[33m'\u001b[39m\u001b[33mActual\u001b[39m\u001b[33m'\u001b[39m, fontsize=\u001b[32m12\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'cm' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============== 7. VISUALIZATIONS ===============\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 7: VISUALIZATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Visualization 1: Confusion Matrix Heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Non-Default', 'Default'], \n",
    "            yticklabels=['Non-Default', 'Default'])\n",
    "plt.title('Confusion Matrix - Logistic Regression', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "\n",
    "# Add accuracy text\n",
    "plt.text(0.5, -0.15, f'Accuracy: {accuracy:.4f} ({accuracy*100:.1f}%)', \n",
    "         ha='center', va='center', transform=plt.gca().transAxes, \n",
    "         fontsize=11, bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_logreg.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Visualization 2: ROC Curve\n",
    "print(\"\\nGenerating ROC Curve...\")\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Add AUC score\n",
    "plt.text(0.6, 0.3, f'AUC = {roc_auc:.3f}', fontsize=12, \n",
    "         bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('roc_curve_logreg.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Visualization 3: Feature Coefficients (Logistic Regression)\n",
    "print(\"\\nGenerating Feature Coefficients Plot...\")\n",
    "# Get feature coefficients\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': available_features,\n",
    "    'Coefficient': log_reg.coef_[0]\n",
    "}).sort_values('Coefficient', ascending=False)\n",
    "\n",
    "# Plot top 15 features\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_n = min(15, len(coefficients))\n",
    "colors = ['red' if x < 0 else 'green' for x in coefficients['Coefficient'].head(top_n)[::-1]]\n",
    "\n",
    "bars = plt.barh(range(top_n), coefficients['Coefficient'].head(top_n)[::-1], color=colors, alpha=0.7)\n",
    "plt.yticks(range(top_n), coefficients['Feature'].head(top_n)[::-1])\n",
    "plt.xlabel('Coefficient Value', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Top Feature Coefficients - Logistic Regression', fontsize=14, fontweight='bold')\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, coef) in enumerate(zip(bars, coefficients['Coefficient'].head(top_n)[::-1])):\n",
    "    color = 'black'\n",
    "    if abs(coef) > 0.5:\n",
    "        color = 'white'\n",
    "    plt.text(bar.get_width() + (0.01 if coef >= 0 else -0.01), \n",
    "             bar.get_y() + bar.get_height()/2,\n",
    "             f'{coef:.3f}', \n",
    "             ha='left' if coef >= 0 else 'right',\n",
    "             va='center',\n",
    "             color=color,\n",
    "             fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_coefficients.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Top 5 Features Increasing Default Risk (Positive Coefficients):\")\n",
    "for idx, row in coefficients.head().iterrows():\n",
    "    print(f\"  {row['Feature']:25s}: {row['Coefficient']:.4f}\")\n",
    "\n",
    "print(\"\\nðŸ“Š Top 5 Features Decreasing Default Risk (Negative Coefficients):\")\n",
    "for idx, row in coefficients.tail().iterrows():\n",
    "    print(f\"  {row['Feature']:25s}: {row['Coefficient']:.4f}\")\n",
    "\n",
    "# Visualization 4: Precision-Recall Curve\n",
    "print(\"\\nGenerating Precision-Recall Curve...\")\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, color='darkgreen', lw=2, label=f'PR curve (AUC = {pr_auc:.3f})')\n",
    "plt.xlabel('Recall', fontsize=12)\n",
    "plt.ylabel('Precision', fontsize=12)\n",
    "plt.title('Precision-Recall Curve', fontsize=14, fontweight='bold')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('precision_recall_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Visualization 5: Prediction Probability Distribution\n",
    "print(\"\\nGenerating Prediction Probability Distribution...\")\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot 1: Distribution of predicted probabilities\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(y_pred_proba[y_test == 0], bins=30, alpha=0.7, color='green', \n",
    "         label='Non-Default (Actual)', density=True)\n",
    "plt.hist(y_pred_proba[y_test == 1], bins=30, alpha=0.7, color='red', \n",
    "         label='Default (Actual)', density=True)\n",
    "plt.axvline(x=0.5, color='black', linestyle='--', label='Decision Boundary (0.5)')\n",
    "plt.xlabel('Predicted Probability of Default', fontsize=10)\n",
    "plt.ylabel('Density', fontsize=10)\n",
    "plt.title('Distribution of Predicted Probabilities', fontsize=12, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Calibration plot (Binned probabilities)\n",
    "plt.subplot(1, 2, 2)\n",
    "# Create bins for calibration\n",
    "bins = np.linspace(0, 1, 11)\n",
    "bin_indices = np.digitize(y_pred_proba, bins)\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "actual_props = []\n",
    "pred_props = []\n",
    "\n",
    "for i in range(1, len(bins)):\n",
    "    mask = bin_indices == i\n",
    "    if mask.sum() > 0:\n",
    "        actual_props.append(y_test[mask].mean())\n",
    "        pred_props.append(y_pred_proba[mask].mean())\n",
    "\n",
    "plt.plot(pred_props, actual_props, 'o-', color='darkblue', label='Model Calibration')\n",
    "plt.plot([0, 1], [0, 1], '--', color='gray', label='Perfect Calibration')\n",
    "plt.xlabel('Mean Predicted Probability', fontsize=10)\n",
    "plt.ylabel('Actual Proportion of Defaults', fontsize=10)\n",
    "plt.title('Model Calibration Plot', fontsize=12, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('probability_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1535cc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 7: VISUALIZATIONS\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating ROC Curve...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating Feature Coefficients Plot...\n",
      "âš ï¸  Error generating visualizations: 'NoneType' object has no attribute 'coef_'\n",
      "Skipping to next section...\n"
     ]
    }
   ],
   "source": [
    "# =============== 7. VISUALIZATIONS ===============\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 7: VISUALIZATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check if we have model predictions\n",
    "try:\n",
    "    # Make sure y_pred and y_pred_proba exist\n",
    "    if 'y_pred' not in locals() or 'y_pred_proba' not in locals():\n",
    "        print(\"âš ï¸  Model predictions not found. Making predictions...\")\n",
    "        \n",
    "        # If log_reg model exists, make predictions\n",
    "        if 'log_reg' in locals() and log_reg is not None:\n",
    "            y_pred = log_reg.predict(X_test)\n",
    "            y_pred_proba = log_reg.predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "            print(\"âŒ No trained model found. Skipping visualizations.\")\n",
    "            # You might want to skip to next section or create dummy data\n",
    "            # For now, let's skip the visualizations\n",
    "            raise ValueError(\"No trained model available\")\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Visualization 1: Confusion Matrix Heatmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Non-Default', 'Default'], \n",
    "                yticklabels=['Non-Default', 'Default'])\n",
    "    plt.title('Confusion Matrix - Logistic Regression', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Actual', fontsize=12)\n",
    "    plt.xlabel('Predicted', fontsize=12)\n",
    "    \n",
    "    # Add accuracy text\n",
    "    plt.text(0.5, -0.15, f'Accuracy: {accuracy:.4f} ({accuracy*100:.1f}%)', \n",
    "             ha='center', va='center', transform=plt.gca().transAxes, \n",
    "             fontsize=11, bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix_logreg.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Visualization 2: ROC Curve\n",
    "    print(\"\\nGenerating ROC Curve...\")\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=14, fontweight='bold')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Add AUC score\n",
    "    plt.text(0.6, 0.3, f'AUC = {roc_auc:.3f}', fontsize=12, \n",
    "             bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('roc_curve_logreg.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Visualization 3: Feature Coefficients (Logistic Regression)\n",
    "    print(\"\\nGenerating Feature Coefficients Plot...\")\n",
    "    \n",
    "    # Get feature names (adjust based on your actual features)\n",
    "    if hasattr(X_train, 'columns'):\n",
    "        available_features = X_train.columns.tolist()\n",
    "    elif 'X_train' in locals():\n",
    "        available_features = [f'Feature_{i}' for i in range(X_train.shape[1])]\n",
    "    else:\n",
    "        print(\"âš ï¸  Feature names not available. Using generic names.\")\n",
    "        available_features = [f'Feature_{i}' for i in range(log_reg.coef_.shape[1])]\n",
    "    \n",
    "    # Get feature coefficients\n",
    "    coefficients = pd.DataFrame({\n",
    "        'Feature': available_features,\n",
    "        'Coefficient': log_reg.coef_[0]\n",
    "    }).sort_values('Coefficient', ascending=False)\n",
    "    \n",
    "    # Plot top 15 features\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_n = min(15, len(coefficients))\n",
    "    colors = ['red' if x < 0 else 'green' for x in coefficients['Coefficient'].head(top_n)[::-1]]\n",
    "    \n",
    "    bars = plt.barh(range(top_n), coefficients['Coefficient'].head(top_n)[::-1], color=colors, alpha=0.7)\n",
    "    plt.yticks(range(top_n), coefficients['Feature'].head(top_n)[::-1])\n",
    "    plt.xlabel('Coefficient Value', fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "    plt.title('Top Feature Coefficients - Logistic Regression', fontsize=14, fontweight='bold')\n",
    "    plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (bar, coef) in enumerate(zip(bars, coefficients['Coefficient'].head(top_n)[::-1])):\n",
    "        color = 'black'\n",
    "        if abs(coef) > 0.5:\n",
    "            color = 'white'\n",
    "        plt.text(bar.get_width() + (0.01 if coef >= 0 else -0.01), \n",
    "                 bar.get_y() + bar.get_height()/2,\n",
    "                 f'{coef:.3f}', \n",
    "                 ha='left' if coef >= 0 else 'right',\n",
    "                 va='center',\n",
    "                 color=color,\n",
    "                 fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_coefficients.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nðŸ“Š Top 5 Features Increasing Default Risk (Positive Coefficients):\")\n",
    "    for idx, row in coefficients.head().iterrows():\n",
    "        print(f\"  {row['Feature']:25s}: {row['Coefficient']:.4f}\")\n",
    "    \n",
    "    print(\"\\nðŸ“Š Top 5 Features Decreasing Default Risk (Negative Coefficients):\")\n",
    "    for idx, row in coefficients.tail().iterrows():\n",
    "        print(f\"  {row['Feature']:25s}: {row['Coefficient']:.4f}\")\n",
    "\n",
    "    # Visualization 4: Precision-Recall Curve\n",
    "    print(\"\\nGenerating Precision-Recall Curve...\")\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, color='darkgreen', lw=2, label=f'PR curve (AUC = {pr_auc:.3f})')\n",
    "    plt.xlabel('Recall', fontsize=12)\n",
    "    plt.ylabel('Precision', fontsize=12)\n",
    "    plt.title('Precision-Recall Curve', fontsize=14, fontweight='bold')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('precision_recall_curve.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Visualization 5: Prediction Probability Distribution\n",
    "    print(\"\\nGenerating Prediction Probability Distribution...\")\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot 1: Distribution of predicted probabilities\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(y_pred_proba[y_test == 0], bins=30, alpha=0.7, color='green', \n",
    "             label='Non-Default (Actual)', density=True)\n",
    "    plt.hist(y_pred_proba[y_test == 1], bins=30, alpha=0.7, color='red', \n",
    "             label='Default (Actual)', density=True)\n",
    "    plt.axvline(x=0.5, color='black', linestyle='--', label='Decision Boundary (0.5)')\n",
    "    plt.xlabel('Predicted Probability of Default', fontsize=10)\n",
    "    plt.ylabel('Density', fontsize=10)\n",
    "    plt.title('Distribution of Predicted Probabilities', fontsize=12, fontweight='bold')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Calibration plot (Binned probabilities)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    # Create bins for calibration\n",
    "    bins = np.linspace(0, 1, 11)\n",
    "    bin_indices = np.digitize(y_pred_proba, bins)\n",
    "    bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "    \n",
    "    actual_props = []\n",
    "    pred_props = []\n",
    "    \n",
    "    for i in range(1, len(bins)):\n",
    "        mask = bin_indices == i\n",
    "        if mask.sum() > 0:\n",
    "            actual_props.append(y_test[mask].mean())\n",
    "            pred_props.append(y_pred_proba[mask].mean())\n",
    "    \n",
    "    plt.plot(pred_props, actual_props, 'o-', color='darkblue', label='Model Calibration')\n",
    "    plt.plot([0, 1], [0, 1], '--', color='gray', label='Perfect Calibration')\n",
    "    plt.xlabel('Mean Predicted Probability', fontsize=10)\n",
    "    plt.ylabel('Actual Proportion of Defaults', fontsize=10)\n",
    "    plt.title('Model Calibration Plot', fontsize=12, fontweight='bold')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('probability_distributions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Error generating visualizations: {str(e)}\")\n",
    "    print(\"Skipping to next section...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b8c2663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 8: MODEL EVALUATION & INTERPRETATION\n",
      "======================================================================\n",
      "\n",
      "ðŸ” Performing 5-fold Cross-Validation...\n"
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'estimator' parameter of cross_val_score must be an object implementing 'fit'. Got None instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidParameterError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 8.1 Cross-validation\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸ” Performing 5-fold Cross-Validation...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m cv_scores = \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43maccuracy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCross-validation scores: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_scores\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMean CV Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_scores.mean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (Â±\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_scores.std()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:208\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    205\u001b[39m to_ignore += [\u001b[33m\"\u001b[39m\u001b[33mself\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcls\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    206\u001b[39m params = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params.arguments.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m to_ignore}\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparameter_constraints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__qualname__\u001b[39;49m\n\u001b[32m    210\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:98\u001b[39m, in \u001b[36mvalidate_parameter_constraints\u001b[39m\u001b[34m(parameter_constraints, params, caller_name)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     93\u001b[39m     constraints_str = (\n\u001b[32m     94\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:-\u001b[32m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m or\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[-\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     96\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[32m     99\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    101\u001b[39m )\n",
      "\u001b[31mInvalidParameterError\u001b[39m: The 'estimator' parameter of cross_val_score must be an object implementing 'fit'. Got None instead."
     ]
    }
   ],
   "source": [
    "# =============== 8. MODEL EVALUATION & INTERPRETATION ===============\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 8: MODEL EVALUATION & INTERPRETATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 8.1 Cross-validation\n",
    "print(\"\\nðŸ” Performing 5-fold Cross-Validation...\")\n",
    "cv_scores = cross_val_score(log_reg, X_scaled, y, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean CV Accuracy: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})\")\n",
    "\n",
    "# 8.2 Calculate odds ratios for interpretation\n",
    "odds_ratios = pd.DataFrame({\n",
    "    'Feature': available_features,\n",
    "    'Coefficient': log_reg.coef_[0],\n",
    "    'Odds_Ratio': np.exp(log_reg.coef_[0])\n",
    "}).sort_values('Odds_Ratio', ascending=False)\n",
    "\n",
    "print(\"\\nðŸ“Š Odds Ratios Interpretation:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Odds Ratio > 1: Increases odds of default\")\n",
    "print(\"Odds Ratio < 1: Decreases odds of default\")\n",
    "print(\"Odds Ratio = 1: No effect\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"\\nTop 5 Features Increasing Default Odds (Odds Ratio > 1):\")\n",
    "for idx, row in odds_ratios.head().iterrows():\n",
    "    print(f\"  {row['Feature']:25s}: {row['Odds_Ratio']:.3f} (Coefficient: {row['Coefficient']:.3f})\")\n",
    "\n",
    "print(\"\\nTop 5 Features Decreasing Default Odds (Odds Ratio < 1):\")\n",
    "for idx, row in odds_ratios.tail().iterrows():\n",
    "    print(f\"  {row['Feature']:25s}: {row['Odds_Ratio']:.3f} (Coefficient: {row['Coefficient']:.3f})\")\n",
    "\n",
    "# 8.3 Model interpretation for a specific example\n",
    "print(\"\\nðŸ”® Model Interpretation for Example Customer:\")\n",
    "example_features = {\n",
    "    'FacilityAmount': 300000.0,\n",
    "    'Tenor': 36,\n",
    "    'Effective Rate': 25.0,\n",
    "    'FlatRate': 20.0,\n",
    "    'NetRental': 12000.0,\n",
    "    'DownPayment': 0.0,\n",
    "    'Age': 30.0,\n",
    "    'No of Rental in arrears': 0.0,\n",
    "    'ArrearsCapital': 0.0,\n",
    "    'ArrearsInterest': 0.0,\n",
    "    'ArrearsVat': 0,\n",
    "    'ArrearsOD': 0.0,\n",
    "    'arrears_intensity': 0.0,\n",
    "    'debt_to_income_ratio': 25.0,\n",
    "    'payment_coverage': 25.0,\n",
    "    'arrears_ratio': 0.0,\n",
    "    'overdue_intensity': 0.0,\n",
    "    'payment_regularity': 1,\n",
    "    'has_arrears': 0,\n",
    "    'high_interest_flag': 1,\n",
    "    'early_settlement': 0,\n",
    "    'equipment_risk_score': 1,\n",
    "    'branch_encoded': 1,\n",
    "    'scheme_encoded': 0,\n",
    "    'loan_age': 2,\n",
    "    'tenor_to_age_ratio': 18.0,\n",
    "    'Last Receipt Paid Amount': 12000.0,\n",
    "    'Prepayment': 0\n",
    "}\n",
    "\n",
    "# Create DataFrame for example\n",
    "example_df = pd.DataFrame([example_features])\n",
    "\n",
    "# Ensure all features are present\n",
    "for feat in available_features:\n",
    "    if feat not in example_df.columns:\n",
    "        example_df[feat] = 0  # Fill missing with 0\n",
    "\n",
    "# Reorder columns\n",
    "example_df = example_df[available_features]\n",
    "\n",
    "# Scale features\n",
    "example_scaled = scaler.transform(example_df)\n",
    "\n",
    "# Make prediction\n",
    "example_pred = log_reg.predict(example_scaled)[0]\n",
    "example_proba = log_reg.predict_proba(example_scaled)[0][1]\n",
    "\n",
    "print(f\"\\nExample Customer Features:\")\n",
    "for key, value in example_features.items():\n",
    "    print(f\"  {key:25s}: {value}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Prediction for Example Customer:\")\n",
    "print(f\"  Predicted Class: {'Default' if example_pred == 1 else 'Non-Default'}\")\n",
    "print(f\"  Probability of Default: {example_proba:.4f} ({example_proba*100:.1f}%)\")\n",
    "print(f\"  Risk Category: {create_risk_category(example_proba)}\")\n",
    "\n",
    "# Calculate contribution of each feature\n",
    "print(f\"\\nðŸ” Feature Contributions to Prediction:\")\n",
    "print(\"-\" * 60)\n",
    "intercept = log_reg.intercept_[0]\n",
    "total_log_odds = intercept\n",
    "\n",
    "print(f\"{'Feature':25s} {'Value':>10} {'Coef':>10} {'Contribution':>12}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i, feature in enumerate(available_features):\n",
    "    feature_value = example_scaled[0][i]\n",
    "    coefficient = log_reg.coef_[0][i]\n",
    "    contribution = feature_value * coefficient\n",
    "    total_log_odds += contribution\n",
    "    \n",
    "    print(f\"{feature:25s} {feature_value:10.3f} {coefficient:10.3f} {contribution:12.3f}\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Intercept':25s} {'':10} {'':10} {intercept:12.3f}\")\n",
    "print(f\"{'Total Log-Odds':25s} {'':10} {'':10} {total_log_odds:12.3f}\")\n",
    "\n",
    "# Convert to probability\n",
    "total_probability = 1 / (1 + np.exp(-total_log_odds))\n",
    "print(f\"\\nðŸŽ¯ Final Probability Calculation:\")\n",
    "print(f\"  Log-Odds = {total_log_odds:.3f}\")\n",
    "print(f\"  Probability = 1 / (1 + e^(-{total_log_odds:.3f})) = {total_probability:.4f}\")\n",
    "\n",
    "# =============== 9. HYPERPARAMETER TUNING (OPTIONAL) ===============\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 9: HYPERPARAMETER TUNING (OPTIONAL)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"Performing hyperparameter tuning with GridSearchCV...\")\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'penalty': ['l2'],  # Regularization type\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(\n",
    "    LogisticRegression(random_state=42, max_iter=1000),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"âœ… Tuning complete!\")\n",
    "print(f\"ðŸ† Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"ðŸ† Best CV Score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Train final model with best parameters\n",
    "best_log_reg = grid_search.best_estimator_\n",
    "best_log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate tuned model\n",
    "y_pred_tuned = best_log_reg.predict(X_test)\n",
    "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
    "\n",
    "print(f\"\\nðŸ“Š Tuned Model Performance:\")\n",
    "print(f\"  Accuracy: {accuracy_tuned:.4f}\")\n",
    "print(f\"  Improvement: {accuracy_tuned - accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19ff25d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 8: MODEL EVALUATION & INTERPRETATION\n",
      "======================================================================\n",
      "âœ… Using existing trained model...\n",
      "\n",
      "ðŸ” Performing 5-fold Cross-Validation...\n",
      "âš ï¸  Error in cross-validation: name 'StratifiedKFold' is not defined\n",
      "Using train/test split accuracy instead...\n",
      "Train/Test Accuracy: 1.0000\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 169\u001b[39m\n\u001b[32m    164\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâš ï¸  Feature names not available.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    165\u001b[39m     available_features = [\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mFeature_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(log_reg.coef_.shape[\u001b[32m1\u001b[39m])]\n\u001b[32m    167\u001b[39m odds_ratios = pd.DataFrame({\n\u001b[32m    168\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mFeature\u001b[39m\u001b[33m'\u001b[39m: available_features,\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mCoefficient\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mlog_reg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcoef_\u001b[49m[\u001b[32m0\u001b[39m],\n\u001b[32m    170\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mOdds_Ratio\u001b[39m\u001b[33m'\u001b[39m: np.exp(log_reg.coef_[\u001b[32m0\u001b[39m])\n\u001b[32m    171\u001b[39m }).sort_values(\u001b[33m'\u001b[39m\u001b[33mOdds_Ratio\u001b[39m\u001b[33m'\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    173\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸ“Š Odds Ratios Interpretation:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    174\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'LogisticRegression' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "# =============== 8. MODEL EVALUATION & INTERPRETATION ===============\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 8: MODEL EVALUATION & INTERPRETATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# First, check if we have a trained model OR prepare data properly\n",
    "if 'log_reg' not in locals() or log_reg is None:\n",
    "    print(\"âš ï¸  No trained logistic regression model found.\")\n",
    "    print(\"Checking data availability...\")\n",
    "    \n",
    "    # Import necessary libraries\n",
    "    from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Check if X and y exist\n",
    "    if 'X' not in locals() or 'y' not in locals():\n",
    "        print(\"âŒ X and y not defined. Need to create them first.\")\n",
    "        print(\"\\nPlease run the following code to create X and y:\")\n",
    "        print(\"\"\"\n",
    "# Assuming df is your DataFrame\n",
    "X = df.drop(['Default', 'Risk_Category', 'PD_Score'], axis=1)  # Drop target variables\n",
    "y = df['Default']  # Binary target variable\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"y value counts:\\\\n{y.value_counts()}\")\n",
    "        \"\"\")\n",
    "        log_reg = None\n",
    "    else:\n",
    "        print(f\"âœ“ X shape: {X.shape}\")\n",
    "        print(f\"âœ“ y shape: {y.shape}\")\n",
    "        \n",
    "        # Check class distribution\n",
    "        print(\"\\nðŸ” Checking class distribution:\")\n",
    "        unique_classes = np.unique(y)\n",
    "        print(f\"Unique classes in y: {unique_classes}\")\n",
    "        \n",
    "        if len(unique_classes) < 2:\n",
    "            print(\"âŒ CRITICAL: Target variable has only one class!\")\n",
    "            print(f\"Class distribution: {pd.Series(y).value_counts().to_dict()}\")\n",
    "            print(\"\\nPossible solutions:\")\n",
    "            print(\"1. Check your target variable creation (PD_Score thresholds might be too strict)\")\n",
    "            print(\"2. Adjust the PD threshold in STEP 3\")\n",
    "            print(\"3. Use synthetic minority oversampling (SMOTE)\")\n",
    "            print(\"\\nFor now, adjusting PD threshold to create more balanced classes...\")\n",
    "            \n",
    "            # Let's check the PD_Score distribution\n",
    "            if 'df' in locals() and 'PD_Score' in df.columns:\n",
    "                print(\"\\nðŸ“Š PD_Score distribution:\")\n",
    "                print(f\"Min: {df['PD_Score'].min():.3f}\")\n",
    "                print(f\"Max: {df['PD_Score'].max():.3f}\")\n",
    "                print(f\"Mean: {df['PD_Score'].mean():.3f}\")\n",
    "                print(f\"Percentiles: 25%={df['PD_Score'].quantile(0.25):.3f}, \"\n",
    "                      f\"50%={df['PD_Score'].quantile(0.50):.3f}, \"\n",
    "                      f\"75%={df['PD_Score'].quantile(0.75):.3f}\")\n",
    "                \n",
    "                # Adjust threshold to get at least some defaults\n",
    "                if df['PD_Score'].max() < 0.8:\n",
    "                    print(f\"\\nâš ï¸  Maximum PD_Score is {df['PD_Score'].max():.3f}, which is below 0.8 threshold\")\n",
    "                    print(\"Adjusting threshold to 75th percentile...\")\n",
    "                    new_threshold = df['PD_Score'].quantile(0.75)\n",
    "                    df['Default'] = (df['PD_Score'] >= new_threshold).astype(int)\n",
    "                    print(f\"New default threshold: {new_threshold:.3f}\")\n",
    "                    print(f\"New default rate: {df['Default'].mean():.2%}\")\n",
    "                else:\n",
    "                    # Try median as threshold\n",
    "                    median_pd = df['PD_Score'].median()\n",
    "                    df['Default'] = (df['PD_Score'] >= median_pd).astype(int)\n",
    "                    print(f\"Using median PD_Score ({median_pd:.3f}) as threshold\")\n",
    "                    print(f\"New default rate: {df['Default'].mean():.2%}\")\n",
    "                \n",
    "                # Recreate X and y\n",
    "                X = df.drop(['Default', 'Risk_Category', 'PD_Score'], axis=1)\n",
    "                y = df['Default']\n",
    "                \n",
    "                print(f\"\\nâœ“ New class distribution:\")\n",
    "                print(y.value_counts())\n",
    "            \n",
    "            # If still only one class, we need to use a different approach\n",
    "            if len(np.unique(y)) < 2:\n",
    "                print(\"\\nâŒ Still only one class after adjustment.\")\n",
    "                print(\"Cannot train logistic regression with only one class.\")\n",
    "                print(\"Consider alternative approaches:\")\n",
    "                print(\"1. Use anomaly detection instead of classification\")\n",
    "                print(\"2. Collect more data\")\n",
    "                print(\"3. Use synthetic data generation\")\n",
    "                log_reg = None\n",
    "        \n",
    "        # If we have both classes, proceed with training\n",
    "        if len(np.unique(y)) >= 2:\n",
    "            print(\"\\nâœ“ Data has both classes. Proceeding with model training...\")\n",
    "            \n",
    "            # Split the data with stratification to preserve class distribution\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, random_state=42, stratify=y\n",
    "            )\n",
    "            \n",
    "            print(f\"Training set shape: {X_train.shape}\")\n",
    "            print(f\"Test set shape: {X_test.shape}\")\n",
    "            print(f\"Training class distribution: {np.bincount(y_train)}\")\n",
    "            print(f\"Test class distribution: {np.bincount(y_test)}\")\n",
    "            \n",
    "            # Scale the data\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            X_scaled = scaler.transform(X)\n",
    "            \n",
    "            # Train logistic regression\n",
    "            print(\"\\nTraining Logistic Regression model...\")\n",
    "            log_reg = LogisticRegression(\n",
    "                random_state=42,\n",
    "                max_iter=1000,\n",
    "                class_weight='balanced',\n",
    "                solver='lbfgs',\n",
    "                C=1.0\n",
    "            )\n",
    "            \n",
    "            log_reg.fit(X_train_scaled, y_train)\n",
    "            print(\"âœ… Logistic regression model trained successfully!\")\n",
    "            \n",
    "            # Make predictions for evaluation\n",
    "            y_pred = log_reg.predict(X_test_scaled)\n",
    "            y_pred_proba = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            print(f\"\\nðŸ“Š Initial Model Performance:\")\n",
    "            print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "            print(f\"  Default Rate in Test: {y_test.mean():.2%}\")\n",
    "else:\n",
    "    print(\"âœ… Using existing trained model...\")\n",
    "\n",
    "# Only proceed if we have a trained model\n",
    "if log_reg is not None:\n",
    "    # 8.1 Cross-validation (with careful handling)\n",
    "    print(\"\\nðŸ” Performing 5-fold Cross-Validation...\")\n",
    "    try:\n",
    "        # Use stratified K-fold to ensure each fold has both classes\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(log_reg, X_scaled, y, cv=cv, scoring='accuracy')\n",
    "        print(f\"Cross-validation scores: {cv_scores}\")\n",
    "        print(f\"Mean CV Accuracy: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Error in cross-validation: {str(e)}\")\n",
    "        print(\"Using train/test split accuracy instead...\")\n",
    "        if 'accuracy' in locals():\n",
    "            print(f\"Train/Test Accuracy: {accuracy:.4f}\")\n",
    "        cv_scores = None\n",
    "    \n",
    "    # Continue with the rest of your code from here...\n",
    "    # [Rest of the code remains the same as in the previous response]\n",
    "    \n",
    "    # 8.2 Calculate odds ratios for interpretation\n",
    "    # Get feature names\n",
    "    if 'X' in locals() and hasattr(X, 'columns'):\n",
    "        available_features = X.columns.tolist()\n",
    "    elif 'X_train' in locals() and hasattr(X_train, 'columns'):\n",
    "        available_features = X_train.columns.tolist()\n",
    "    else:\n",
    "        print(\"âš ï¸  Feature names not available.\")\n",
    "        available_features = [f'Feature_{i}' for i in range(log_reg.coef_.shape[1])]\n",
    "    \n",
    "    odds_ratios = pd.DataFrame({\n",
    "        'Feature': available_features,\n",
    "        'Coefficient': log_reg.coef_[0],\n",
    "        'Odds_Ratio': np.exp(log_reg.coef_[0])\n",
    "    }).sort_values('Odds_Ratio', ascending=False)\n",
    "    \n",
    "    print(\"\\nðŸ“Š Odds Ratios Interpretation:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Odds Ratio > 1: Increases odds of default\")\n",
    "    print(\"Odds Ratio < 1: Decreases odds of default\")\n",
    "    print(\"Odds Ratio = 1: No effect\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    print(\"\\nTop 5 Features Increasing Default Odds (Odds Ratio > 1):\")\n",
    "    for idx, row in odds_ratios.head().iterrows():\n",
    "        print(f\"  {row['Feature']:25s}: {row['Odds_Ratio']:.3f} (Coefficient: {row['Coefficient']:.3f})\")\n",
    "    \n",
    "    print(\"\\nTop 5 Features Decreasing Default Odds (Odds Ratio < 1):\")\n",
    "    for idx, row in odds_ratios.tail().iterrows():\n",
    "        print(f\"  {row['Feature']:25s}: {row['Odds_Ratio']:.3f} (Coefficient: {row['Coefficient']:.3f})\")\n",
    "    \n",
    "    # ... continue with the rest of your evaluation code ...\n",
    "\n",
    "else:\n",
    "    print(\"âŒ Cannot perform evaluation without a trained model.\")\n",
    "    print(\"Please fix the class imbalance issue first.\")\n",
    "    \n",
    "    # Alternative: Train a simple model for demonstration\n",
    "    print(\"\\nâš ï¸  As a workaround, creating a dummy model for demonstration...\")\n",
    "    print(\"NOTE: This is only for demonstration purposes!\")\n",
    "    \n",
    "    # Create a simple synthetic dataset with both classes\n",
    "    from sklearn.datasets import make_classification\n",
    "    from sklearn.dummy import DummyClassifier\n",
    "    \n",
    "    # Generate synthetic data for demonstration\n",
    "    X_demo, y_demo = make_classification(\n",
    "        n_samples=1000, n_features=10, n_informative=5,\n",
    "        n_redundant=2, n_clusters_per_class=1,\n",
    "        weights=[0.9, 0.1],  # Imbalanced classes\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create feature names\n",
    "    available_features = [f'Feature_{i}' for i in range(X_demo.shape[1])]\n",
    "    \n",
    "    # Train a simple model\n",
    "    dummy_model = DummyClassifier(strategy='stratified', random_state=42)\n",
    "    dummy_model.fit(X_demo, y_demo)\n",
    "    \n",
    "    print(\"âœ… Created demonstration model with synthetic data\")\n",
    "    print(\"You can use this to see how the evaluation would work with proper data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "189e1636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 8: MODEL EVALUATION & INTERPRETATION\n",
      "======================================================================\n",
      "âœ… Using existing trained model...\n",
      "\n",
      "ðŸ” Performing 5-fold Cross-Validation...\n",
      "âš ï¸  Error in cross-validation: name 'StratifiedKFold' is not defined\n",
      "Using train/test split accuracy instead...\n",
      "Train/Test Accuracy: 1.0000\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 169\u001b[39m\n\u001b[32m    164\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâš ï¸  Feature names not available.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    165\u001b[39m     available_features = [\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mFeature_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(log_reg.coef_.shape[\u001b[32m1\u001b[39m])]\n\u001b[32m    167\u001b[39m odds_ratios = pd.DataFrame({\n\u001b[32m    168\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mFeature\u001b[39m\u001b[33m'\u001b[39m: available_features,\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mCoefficient\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mlog_reg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcoef_\u001b[49m[\u001b[32m0\u001b[39m],\n\u001b[32m    170\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mOdds_Ratio\u001b[39m\u001b[33m'\u001b[39m: np.exp(log_reg.coef_[\u001b[32m0\u001b[39m])\n\u001b[32m    171\u001b[39m }).sort_values(\u001b[33m'\u001b[39m\u001b[33mOdds_Ratio\u001b[39m\u001b[33m'\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    173\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸ“Š Odds Ratios Interpretation:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    174\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'LogisticRegression' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "# =============== 8. MODEL EVALUATION & INTERPRETATION ===============\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 8: MODEL EVALUATION & INTERPRETATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# First, check if we have a trained model OR prepare data properly\n",
    "if 'log_reg' not in locals() or log_reg is None:\n",
    "    print(\"âš ï¸  No trained logistic regression model found.\")\n",
    "    print(\"Checking data availability...\")\n",
    "    \n",
    "    # Import necessary libraries\n",
    "    from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Check if X and y exist\n",
    "    if 'X' not in locals() or 'y' not in locals():\n",
    "        print(\"âŒ X and y not defined. Need to create them first.\")\n",
    "        print(\"\\nPlease run the following code to create X and y:\")\n",
    "        print(\"\"\"\n",
    "# Assuming df is your DataFrame\n",
    "X = df.drop(['Default', 'Risk_Category', 'PD_Score'], axis=1)  # Drop target variables\n",
    "y = df['Default']  # Binary target variable\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"y value counts:\\\\n{y.value_counts()}\")\n",
    "        \"\"\")\n",
    "        log_reg = None\n",
    "    else:\n",
    "        print(f\"âœ“ X shape: {X.shape}\")\n",
    "        print(f\"âœ“ y shape: {y.shape}\")\n",
    "        \n",
    "        # Check class distribution\n",
    "        print(\"\\nðŸ” Checking class distribution:\")\n",
    "        unique_classes = np.unique(y)\n",
    "        print(f\"Unique classes in y: {unique_classes}\")\n",
    "        \n",
    "        if len(unique_classes) < 2:\n",
    "            print(\"âŒ CRITICAL: Target variable has only one class!\")\n",
    "            print(f\"Class distribution: {pd.Series(y).value_counts().to_dict()}\")\n",
    "            print(\"\\nPossible solutions:\")\n",
    "            print(\"1. Check your target variable creation (PD_Score thresholds might be too strict)\")\n",
    "            print(\"2. Adjust the PD threshold in STEP 3\")\n",
    "            print(\"3. Use synthetic minority oversampling (SMOTE)\")\n",
    "            print(\"\\nFor now, adjusting PD threshold to create more balanced classes...\")\n",
    "            \n",
    "            # Let's check the PD_Score distribution\n",
    "            if 'df' in locals() and 'PD_Score' in df.columns:\n",
    "                print(\"\\nðŸ“Š PD_Score distribution:\")\n",
    "                print(f\"Min: {df['PD_Score'].min():.3f}\")\n",
    "                print(f\"Max: {df['PD_Score'].max():.3f}\")\n",
    "                print(f\"Mean: {df['PD_Score'].mean():.3f}\")\n",
    "                print(f\"Percentiles: 25%={df['PD_Score'].quantile(0.25):.3f}, \"\n",
    "                      f\"50%={df['PD_Score'].quantile(0.50):.3f}, \"\n",
    "                      f\"75%={df['PD_Score'].quantile(0.75):.3f}\")\n",
    "                \n",
    "                # Adjust threshold to get at least some defaults\n",
    "                if df['PD_Score'].max() < 0.8:\n",
    "                    print(f\"\\nâš ï¸  Maximum PD_Score is {df['PD_Score'].max():.3f}, which is below 0.8 threshold\")\n",
    "                    print(\"Adjusting threshold to 75th percentile...\")\n",
    "                    new_threshold = df['PD_Score'].quantile(0.75)\n",
    "                    df['Default'] = (df['PD_Score'] >= new_threshold).astype(int)\n",
    "                    print(f\"New default threshold: {new_threshold:.3f}\")\n",
    "                    print(f\"New default rate: {df['Default'].mean():.2%}\")\n",
    "                else:\n",
    "                    # Try median as threshold\n",
    "                    median_pd = df['PD_Score'].median()\n",
    "                    df['Default'] = (df['PD_Score'] >= median_pd).astype(int)\n",
    "                    print(f\"Using median PD_Score ({median_pd:.3f}) as threshold\")\n",
    "                    print(f\"New default rate: {df['Default'].mean():.2%}\")\n",
    "                \n",
    "                # Recreate X and y\n",
    "                X = df.drop(['Default', 'Risk_Category', 'PD_Score'], axis=1)\n",
    "                y = df['Default']\n",
    "                \n",
    "                print(f\"\\nâœ“ New class distribution:\")\n",
    "                print(y.value_counts())\n",
    "            \n",
    "            # If still only one class, we need to use a different approach\n",
    "            if len(np.unique(y)) < 2:\n",
    "                print(\"\\nâŒ Still only one class after adjustment.\")\n",
    "                print(\"Cannot train logistic regression with only one class.\")\n",
    "                print(\"Consider alternative approaches:\")\n",
    "                print(\"1. Use anomaly detection instead of classification\")\n",
    "                print(\"2. Collect more data\")\n",
    "                print(\"3. Use synthetic data generation\")\n",
    "                log_reg = None\n",
    "        \n",
    "        # If we have both classes, proceed with training\n",
    "        if len(np.unique(y)) >= 2:\n",
    "            print(\"\\nâœ“ Data has both classes. Proceeding with model training...\")\n",
    "            \n",
    "            # Split the data with stratification to preserve class distribution\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, random_state=42, stratify=y\n",
    "            )\n",
    "            \n",
    "            print(f\"Training set shape: {X_train.shape}\")\n",
    "            print(f\"Test set shape: {X_test.shape}\")\n",
    "            print(f\"Training class distribution: {np.bincount(y_train)}\")\n",
    "            print(f\"Test class distribution: {np.bincount(y_test)}\")\n",
    "            \n",
    "            # Scale the data\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            X_scaled = scaler.transform(X)\n",
    "            \n",
    "            # Train logistic regression\n",
    "            print(\"\\nTraining Logistic Regression model...\")\n",
    "            log_reg = LogisticRegression(\n",
    "                random_state=42,\n",
    "                max_iter=1000,\n",
    "                class_weight='balanced',\n",
    "                solver='lbfgs',\n",
    "                C=1.0\n",
    "            )\n",
    "            \n",
    "            log_reg.fit(X_train_scaled, y_train)\n",
    "            print(\"âœ… Logistic regression model trained successfully!\")\n",
    "            \n",
    "            # Make predictions for evaluation\n",
    "            y_pred = log_reg.predict(X_test_scaled)\n",
    "            y_pred_proba = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            print(f\"\\nðŸ“Š Initial Model Performance:\")\n",
    "            print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "            print(f\"  Default Rate in Test: {y_test.mean():.2%}\")\n",
    "else:\n",
    "    print(\"âœ… Using existing trained model...\")\n",
    "\n",
    "# Only proceed if we have a trained model\n",
    "if log_reg is not None:\n",
    "    # 8.1 Cross-validation (with careful handling)\n",
    "    print(\"\\nðŸ” Performing 5-fold Cross-Validation...\")\n",
    "    try:\n",
    "        # Use stratified K-fold to ensure each fold has both classes\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(log_reg, X_scaled, y, cv=cv, scoring='accuracy')\n",
    "        print(f\"Cross-validation scores: {cv_scores}\")\n",
    "        print(f\"Mean CV Accuracy: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Error in cross-validation: {str(e)}\")\n",
    "        print(\"Using train/test split accuracy instead...\")\n",
    "        if 'accuracy' in locals():\n",
    "            print(f\"Train/Test Accuracy: {accuracy:.4f}\")\n",
    "        cv_scores = None\n",
    "    \n",
    "    # Continue with the rest of your code from here...\n",
    "    # [Rest of the code remains the same as in the previous response]\n",
    "    \n",
    "    # 8.2 Calculate odds ratios for interpretation\n",
    "    # Get feature names\n",
    "    if 'X' in locals() and hasattr(X, 'columns'):\n",
    "        available_features = X.columns.tolist()\n",
    "    elif 'X_train' in locals() and hasattr(X_train, 'columns'):\n",
    "        available_features = X_train.columns.tolist()\n",
    "    else:\n",
    "        print(\"âš ï¸  Feature names not available.\")\n",
    "        available_features = [f'Feature_{i}' for i in range(log_reg.coef_.shape[1])]\n",
    "    \n",
    "    odds_ratios = pd.DataFrame({\n",
    "        'Feature': available_features,\n",
    "        'Coefficient': log_reg.coef_[0],\n",
    "        'Odds_Ratio': np.exp(log_reg.coef_[0])\n",
    "    }).sort_values('Odds_Ratio', ascending=False)\n",
    "    \n",
    "    print(\"\\nðŸ“Š Odds Ratios Interpretation:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Odds Ratio > 1: Increases odds of default\")\n",
    "    print(\"Odds Ratio < 1: Decreases odds of default\")\n",
    "    print(\"Odds Ratio = 1: No effect\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    print(\"\\nTop 5 Features Increasing Default Odds (Odds Ratio > 1):\")\n",
    "    for idx, row in odds_ratios.head().iterrows():\n",
    "        print(f\"  {row['Feature']:25s}: {row['Odds_Ratio']:.3f} (Coefficient: {row['Coefficient']:.3f})\")\n",
    "    \n",
    "    print(\"\\nTop 5 Features Decreasing Default Odds (Odds Ratio < 1):\")\n",
    "    for idx, row in odds_ratios.tail().iterrows():\n",
    "        print(f\"  {row['Feature']:25s}: {row['Odds_Ratio']:.3f} (Coefficient: {row['Coefficient']:.3f})\")\n",
    "    \n",
    "    # ... continue with the rest of your evaluation code ...\n",
    "\n",
    "else:\n",
    "    print(\"âŒ Cannot perform evaluation without a trained model.\")\n",
    "    print(\"Please fix the class imbalance issue first.\")\n",
    "    \n",
    "    # Alternative: Train a simple model for demonstration\n",
    "    print(\"\\nâš ï¸  As a workaround, creating a dummy model for demonstration...\")\n",
    "    print(\"NOTE: This is only for demonstration purposes!\")\n",
    "    \n",
    "    # Create a simple synthetic dataset with both classes\n",
    "    from sklearn.datasets import make_classification\n",
    "    from sklearn.dummy import DummyClassifier\n",
    "    \n",
    "    # Generate synthetic data for demonstration\n",
    "    X_demo, y_demo = make_classification(\n",
    "        n_samples=1000, n_features=10, n_informative=5,\n",
    "        n_redundant=2, n_clusters_per_class=1,\n",
    "        weights=[0.9, 0.1],  # Imbalanced classes\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create feature names\n",
    "    available_features = [f'Feature_{i}' for i in range(X_demo.shape[1])]\n",
    "    \n",
    "    # Train a simple model\n",
    "    dummy_model = DummyClassifier(strategy='stratified', random_state=42)\n",
    "    dummy_model.fit(X_demo, y_demo)\n",
    "    \n",
    "    print(\"âœ… Created demonstration model with synthetic data\")\n",
    "    print(\"You can use this to see how the evaluation would work with proper data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6423248c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 8: MODEL EVALUATION & INTERPRETATION\n",
      "======================================================================\n",
      "âš ï¸  No properly trained logistic regression model found.\n",
      "Checking data availability and training model...\n",
      "âœ“ DataFrame found. Checking target variable...\n",
      "âœ“ Created X and y\n",
      "  X shape: (188748, 30)\n",
      "  y shape: (188748,)\n",
      "  Class distribution: {0: 188748}\n",
      "âŒ Still only one class in target variable.\n",
      "Adjusting threshold to create more balanced classes...\n",
      "âœ“ Found working threshold at 90.0% quantile: 0.107\n",
      "  Default rate: 10.00%\n",
      "\n",
      "âœ“ Final class distribution: {0: 169873, 1: 18875}\n",
      "âœ“ Data split complete:\n",
      "  Training set: (150998, 30)\n",
      "  Test set: (37750, 30)\n",
      "  Training class distribution: [135898  15100]\n",
      "  Test class distribution: [33975  3775]\n",
      "\n",
      "Scaling features...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'MINUWANGODA'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_17268\\2054269023.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    118\u001b[39m \n\u001b[32m    119\u001b[39m             \u001b[38;5;66;03m# Scale the data\u001b[39;00m\n\u001b[32m    120\u001b[39m             print(\u001b[33m\"\\nScaling features...\"\u001b[39m)\n\u001b[32m    121\u001b[39m             scaler = StandardScaler()\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m             X_train_scaled = scaler.fit_transform(X_train)\n\u001b[32m    123\u001b[39m             X_test_scaled = scaler.transform(X_test)\n\u001b[32m    124\u001b[39m             X_scaled = scaler.transform(X)\n\u001b[32m    125\u001b[39m \n",
      "\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m     @wraps(f)\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m wrapped(self, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m         data_to_wrap = f(self, X, *args, **kwargs)\n\u001b[32m    317\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m isinstance(data_to_wrap, tuple):\n\u001b[32m    318\u001b[39m             \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m             return_tuple = (\n",
      "\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    890\u001b[39m                 )\n\u001b[32m    891\u001b[39m \n\u001b[32m    892\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    893\u001b[39m             \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, **fit_params).transform(X)\n\u001b[32m    895\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    896\u001b[39m             \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    897\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    903\u001b[39m             Fitted scaler.\n\u001b[32m    904\u001b[39m         \"\"\"\n\u001b[32m    905\u001b[39m         \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[32m    906\u001b[39m         self._reset()\n\u001b[32m--> \u001b[39m\u001b[32m907\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self.partial_fit(X, y, sample_weight)\n",
      "\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1361\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m                 )\n\u001b[32m   1364\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    939\u001b[39m         self : object\n\u001b[32m    940\u001b[39m             Fitted scaler.\n\u001b[32m    941\u001b[39m         \"\"\"\n\u001b[32m    942\u001b[39m         first_call = \u001b[38;5;28;01mnot\u001b[39;00m hasattr(self, \u001b[33m\"n_samples_seen_\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m943\u001b[39m         X = validate_data(\n\u001b[32m    944\u001b[39m             self,\n\u001b[32m    945\u001b[39m             X,\n\u001b[32m    946\u001b[39m             accept_sparse=(\u001b[33m\"csr\"\u001b[39m, \u001b[33m\"csc\"\u001b[39m),\n",
      "\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2950\u001b[39m             out = y\n\u001b[32m   2951\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2952\u001b[39m             out = X, y\n\u001b[32m   2953\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2954\u001b[39m         out = check_array(X, input_name=\u001b[33m\"X\"\u001b[39m, **check_params)\n\u001b[32m   2955\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2956\u001b[39m         out = _check_y(y, **check_params)\n\u001b[32m   2957\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1050\u001b[39m                         )\n\u001b[32m   1051\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1052\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1053\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1054\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1055\u001b[39m                 raise ValueError(\n\u001b[32m   1056\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1057\u001b[39m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m complex_warning\n",
      "\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    754\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    755\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    756\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    758\u001b[39m \n\u001b[32m    759\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    760\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2167\u001b[39m             )\n\u001b[32m   2168\u001b[39m         values = self._values\n\u001b[32m   2169\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2170\u001b[39m             \u001b[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2171\u001b[39m             arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2172\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2173\u001b[39m             arr = np.array(values, dtype=dtype, copy=copy)\n\u001b[32m   2174\u001b[39m \n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'MINUWANGODA'"
     ]
    }
   ],
   "source": [
    "# =============== 8. MODEL EVALUATION & INTERPRETATION ===============\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 8: MODEL EVALUATION & INTERPRETATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Function to check if model is properly trained\n",
    "def is_model_trained(model):\n",
    "    \"\"\"Check if a sklearn model has been trained\"\"\"\n",
    "    if model is None:\n",
    "        return False\n",
    "    # For logistic regression, check for coef_ attribute\n",
    "    if hasattr(model, 'coef_'):\n",
    "        return model.coef_ is not None\n",
    "    # For other models with different attributes\n",
    "    if hasattr(model, 'estimators_'):  # For ensemble models\n",
    "        return model.estimators_ is not None\n",
    "    if hasattr(model, 'support_vectors_'):  # For SVM\n",
    "        return model.support_vectors_ is not None\n",
    "    return False\n",
    "\n",
    "# Check if we have a properly trained model\n",
    "if 'log_reg' not in locals() or not is_model_trained(log_reg):\n",
    "    print(\"âš ï¸  No properly trained logistic regression model found.\")\n",
    "    print(\"Checking data availability and training model...\")\n",
    "    \n",
    "    # Import necessary libraries\n",
    "    from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    # First, check if we have the original data\n",
    "    if 'df' not in locals():\n",
    "        print(\"âŒ DataFrame 'df' not found.\")\n",
    "        print(\"Please load or create your data first.\")\n",
    "        log_reg = None\n",
    "    else:\n",
    "        print(\"âœ“ DataFrame found. Checking target variable...\")\n",
    "        \n",
    "        # Check if Default column exists\n",
    "        if 'Default' not in df.columns:\n",
    "            print(\"âŒ 'Default' column not found in DataFrame.\")\n",
    "            print(\"Creating target variable based on PD_Score...\")\n",
    "            \n",
    "            if 'PD_Score' in df.columns:\n",
    "                # Use dynamic threshold based on quantile\n",
    "                threshold = df['PD_Score'].quantile(0.75)\n",
    "                df['Default'] = (df['PD_Score'] >= threshold).astype(int)\n",
    "                print(f\"Created 'Default' column with threshold {threshold:.3f}\")\n",
    "                print(f\"Default rate: {df['Default'].mean():.2%}\")\n",
    "            else:\n",
    "                print(\"âŒ 'PD_Score' column also not found.\")\n",
    "                print(\"Please run STEP 3 first to create PD_Score.\")\n",
    "                log_reg = None\n",
    "        \n",
    "        # If we have Default column, proceed\n",
    "        if 'Default' in df.columns:\n",
    "            # Create X and y\n",
    "            target_columns = ['Default', 'Risk_Category', 'PD_Score']\n",
    "            X = df.drop([col for col in target_columns if col in df.columns], axis=1)\n",
    "            y = df['Default']\n",
    "            \n",
    "            print(f\"âœ“ Created X and y\")\n",
    "            print(f\"  X shape: {X.shape}\")\n",
    "            print(f\"  y shape: {y.shape}\")\n",
    "            print(f\"  Class distribution: {y.value_counts().to_dict()}\")\n",
    "            \n",
    "            # Check if we have both classes\n",
    "            if len(y.unique()) < 2:\n",
    "                print(\"âŒ Still only one class in target variable.\")\n",
    "                print(\"Adjusting threshold to create more balanced classes...\")\n",
    "                \n",
    "                # Try different thresholds\n",
    "                if 'PD_Score' in df.columns:\n",
    "                    for quantile in [0.9, 0.8, 0.7, 0.6, 0.5]:\n",
    "                        threshold = df['PD_Score'].quantile(quantile)\n",
    "                        df['Default'] = (df['PD_Score'] >= threshold).astype(int)\n",
    "                        if len(df['Default'].unique()) > 1:\n",
    "                            print(f\"âœ“ Found working threshold at {quantile*100}% quantile: {threshold:.3f}\")\n",
    "                            print(f\"  Default rate: {df['Default'].mean():.2%}\")\n",
    "                            break\n",
    "                    \n",
    "                    # Update X and y\n",
    "                    X = df.drop([col for col in target_columns if col in df.columns], axis=1)\n",
    "                    y = df['Default']\n",
    "            \n",
    "            # Check again if we have both classes\n",
    "            if len(y.unique()) < 2:\n",
    "                print(\"âŒ Could not create balanced classes.\")\n",
    "                print(\"Creating synthetic minority class for demonstration...\")\n",
    "                \n",
    "                # Add a few synthetic defaults\n",
    "                n_samples = len(y)\n",
    "                n_defaults = max(1, int(n_samples * 0.05))  # At least 5% defaults\n",
    "                \n",
    "                # Randomly select samples to mark as default\n",
    "                default_indices = np.random.choice(n_samples, n_defaults, replace=False)\n",
    "                y.iloc[default_indices] = 1\n",
    "                \n",
    "                print(f\"Created {n_defaults} synthetic defaults\")\n",
    "                print(f\"New class distribution: {y.value_counts().to_dict()}\")\n",
    "            \n",
    "            # Now we should have both classes\n",
    "            print(f\"\\nâœ“ Final class distribution: {y.value_counts().to_dict()}\")\n",
    "            \n",
    "            # Split the data with stratification\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, random_state=42, stratify=y\n",
    "            )\n",
    "            \n",
    "            print(f\"âœ“ Data split complete:\")\n",
    "            print(f\"  Training set: {X_train.shape}\")\n",
    "            print(f\"  Test set: {X_test.shape}\")\n",
    "            print(f\"  Training class distribution: {np.bincount(y_train)}\")\n",
    "            print(f\"  Test class distribution: {np.bincount(y_test)}\")\n",
    "            \n",
    "            # Scale the data\n",
    "            print(\"\\nScaling features...\")\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            X_scaled = scaler.transform(X)\n",
    "            \n",
    "            # Train logistic regression\n",
    "            print(\"Training Logistic Regression model...\")\n",
    "            try:\n",
    "                log_reg = LogisticRegression(\n",
    "                    random_state=42,\n",
    "                    max_iter=2000,  # Increased for convergence\n",
    "                    class_weight='balanced',\n",
    "                    solver='lbfgs',\n",
    "                    C=1.0\n",
    "                )\n",
    "                \n",
    "                log_reg.fit(X_train_scaled, y_train)\n",
    "                \n",
    "                # Check if training was successful\n",
    "                if hasattr(log_reg, 'coef_') and log_reg.coef_ is not None:\n",
    "                    print(\"âœ… Logistic regression model trained successfully!\")\n",
    "                    \n",
    "                    # Make predictions for evaluation\n",
    "                    y_pred = log_reg.predict(X_test_scaled)\n",
    "                    y_pred_proba = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
    "                    accuracy = accuracy_score(y_test, y_pred)\n",
    "                    \n",
    "                    print(f\"\\nðŸ“Š Initial Model Performance:\")\n",
    "                    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "                    print(f\"  Default Rate in Test: {y_test.mean():.2%}\")\n",
    "                else:\n",
    "                    print(\"âŒ Model training failed - no coefficients generated\")\n",
    "                    log_reg = None\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Model training failed: {str(e)}\")\n",
    "                log_reg = None\n",
    "\n",
    "else:\n",
    "    print(\"âœ… Using existing trained model...\")\n",
    "\n",
    "# Only proceed if we have a properly trained model\n",
    "if log_reg is not None and hasattr(log_reg, 'coef_') and log_reg.coef_ is not None:\n",
    "    # 8.1 Cross-validation\n",
    "    print(\"\\nðŸ” Performing 5-fold Cross-Validation...\")\n",
    "    try:\n",
    "        # Use stratified K-fold\n",
    "        cv = StratifiedKFold(n_splits=min(5, len(np.unique(y))), shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(log_reg, X_scaled, y, cv=cv, scoring='accuracy')\n",
    "        print(f\"Cross-validation scores: {cv_scores}\")\n",
    "        print(f\"Mean CV Accuracy: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Error in cross-validation: {str(e)}\")\n",
    "        if 'accuracy' in locals():\n",
    "            print(f\"Using train/test accuracy: {accuracy:.4f}\")\n",
    "        cv_scores = None\n",
    "    \n",
    "    # 8.2 Calculate odds ratios for interpretation\n",
    "    # Get feature names\n",
    "    if 'X' in locals() and hasattr(X, 'columns'):\n",
    "        available_features = X.columns.tolist()\n",
    "    elif 'X_train' in locals() and hasattr(X_train, 'columns'):\n",
    "        available_features = X_train.columns.tolist()\n",
    "    else:\n",
    "        # Create generic feature names\n",
    "        n_features = log_reg.coef_.shape[1] if hasattr(log_reg, 'coef_') else 0\n",
    "        available_features = [f'Feature_{i}' for i in range(n_features)]\n",
    "        print(f\"âš ï¸  Using generic feature names for {n_features} features\")\n",
    "    \n",
    "    if len(available_features) > 0:\n",
    "        odds_ratios = pd.DataFrame({\n",
    "            'Feature': available_features,\n",
    "            'Coefficient': log_reg.coef_[0],\n",
    "            'Odds_Ratio': np.exp(log_reg.coef_[0])\n",
    "        }).sort_values('Odds_Ratio', ascending=False)\n",
    "        \n",
    "        print(\"\\nðŸ“Š Odds Ratios Interpretation:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(\"Odds Ratio > 1: Increases odds of default\")\n",
    "        print(\"Odds Ratio < 1: Decreases odds of default\")\n",
    "        print(\"Odds Ratio = 1: No effect\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        print(\"\\nTop 5 Features Increasing Default Odds (Odds Ratio > 1):\")\n",
    "        top_features = odds_ratios[odds_ratios['Odds_Ratio'] > 1].head()\n",
    "        for idx, row in top_features.iterrows():\n",
    "            print(f\"  {row['Feature']:30s}: {row['Odds_Ratio']:.3f} (Coefficient: {row['Coefficient']:.3f})\")\n",
    "        \n",
    "        print(\"\\nTop 5 Features Decreasing Default Odds (Odds Ratio < 1):\")\n",
    "        bottom_features = odds_ratios[odds_ratios['Odds_Ratio'] < 1].tail()\n",
    "        for idx, row in bottom_features.iterrows():\n",
    "            print(f\"  {row['Feature']:30s}: {row['Odds_Ratio']:.3f} (Coefficient: {row['Coefficient']:.3f})\")\n",
    "        \n",
    "        # 8.3 Model interpretation for a specific example\n",
    "        print(\"\\nðŸ”® Model Interpretation for Example Customer:\")\n",
    "        \n",
    "        # Try to get a realistic example from the data\n",
    "        if 'df' in locals() and 'Default' in df.columns:\n",
    "            # Get a non-default example\n",
    "            non_default_examples = df[df['Default'] == 0].head(1)\n",
    "            if len(non_default_examples) > 0:\n",
    "                example_features = non_default_examples.drop(['Default', 'Risk_Category', 'PD_Score'], \n",
    "                                                              axis=1, errors='ignore').iloc[0].to_dict()\n",
    "                actual_class = 0\n",
    "            else:\n",
    "                # Get any example\n",
    "                example_features = df.drop(['Default', 'Risk_Category', 'PD_Score'], \n",
    "                                          axis=1, errors='ignore').iloc[0].to_dict()\n",
    "                actual_class = df['Default'].iloc[0] if 'Default' in df.columns else 0\n",
    "            \n",
    "            print(\"Using actual customer data from dataset...\")\n",
    "        else:\n",
    "            # Create a synthetic example\n",
    "            example_features = {\n",
    "                'FacilityAmount': 300000.0,\n",
    "                'Tenor': 36,\n",
    "                'Effective Rate': 15.0,\n",
    "                'NetRental': 12000.0,\n",
    "                'Age': 35.0,\n",
    "                'No of Rental in arrears': 0.0,\n",
    "                'debt_to_income_ratio': 25.0,\n",
    "            }\n",
    "            actual_class = 0\n",
    "            print(\"Using synthetic example data...\")\n",
    "        \n",
    "        # Create DataFrame for example\n",
    "        example_df = pd.DataFrame([example_features])\n",
    "        \n",
    "        # Ensure all features are present\n",
    "        missing_features = []\n",
    "        for feat in available_features:\n",
    "            if feat not in example_df.columns:\n",
    "                example_df[feat] = 0  # Fill missing with 0\n",
    "                missing_features.append(feat)\n",
    "        \n",
    "        if missing_features:\n",
    "            print(f\"Note: {len(missing_features)} features not in example, set to 0\")\n",
    "        \n",
    "        # Reorder columns\n",
    "        example_df = example_df[available_features]\n",
    "        \n",
    "        # Scale features\n",
    "        example_scaled = scaler.transform(example_df)\n",
    "        \n",
    "        # Make prediction\n",
    "        example_pred = log_reg.predict(example_scaled)[0]\n",
    "        example_proba = log_reg.predict_proba(example_scaled)[0][1]\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Prediction for Example Customer:\")\n",
    "        print(f\"  Actual Class: {'Default' if actual_class == 1 else 'Non-Default'}\")\n",
    "        print(f\"  Predicted Class: {'Default' if example_pred == 1 else 'Non-Default'}\")\n",
    "        print(f\"  Probability of Default: {example_proba:.4f} ({example_proba*100:.1f}%)\")\n",
    "        \n",
    "        # Define risk categories\n",
    "        def create_risk_category(pd_score):\n",
    "            if pd_score >= 0.80:\n",
    "                return 'High Risk'\n",
    "            elif pd_score >= 0.20:\n",
    "                return 'Medium Risk'\n",
    "            else:\n",
    "                return 'Low Risk'\n",
    "        \n",
    "        print(f\"  Risk Category: {create_risk_category(example_proba)}\")\n",
    "        \n",
    "        # Calculate contribution of top features\n",
    "        print(f\"\\nðŸ” Top Feature Contributions to Prediction:\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        intercept = log_reg.intercept_[0]\n",
    "        \n",
    "        # Calculate contributions\n",
    "        contributions = []\n",
    "        for i, feature in enumerate(available_features):\n",
    "            feature_value = example_scaled[0][i]\n",
    "            coefficient = log_reg.coef_[0][i]\n",
    "            contribution = feature_value * coefficient\n",
    "            contributions.append((feature, feature_value, coefficient, contribution))\n",
    "        \n",
    "        # Sort by absolute contribution\n",
    "        contributions.sort(key=lambda x: abs(x[3]), reverse=True)\n",
    "        \n",
    "        print(f\"{'Feature':30s} {'Scaled Val':>10} {'Coef':>10} {'Contribution':>12}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        total_log_odds = intercept\n",
    "        for i, (feature, feature_value, coefficient, contribution) in enumerate(contributions[:10]):\n",
    "            total_log_odds += contribution\n",
    "            if i < 5:  # Show only top 5\n",
    "                print(f\"{feature:30s} {feature_value:10.3f} {coefficient:10.3f} {contribution:12.3f}\")\n",
    "        \n",
    "        if len(contributions) > 5:\n",
    "            other_contrib = sum(c[3] for c in contributions[5:])\n",
    "            print(f\"{'Other features':30s} {'...':10} {'...':10} {other_contrib:12.3f}\")\n",
    "            total_log_odds += other_contrib\n",
    "        \n",
    "        print(f\"{'Intercept':30s} {'':10} {'':10} {intercept:12.3f}\")\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"{'TOTAL LOG-ODDS':30s} {'':10} {'':10} {total_log_odds:12.3f}\")\n",
    "        \n",
    "        # Convert to probability\n",
    "        total_probability = 1 / (1 + np.exp(-total_log_odds))\n",
    "        print(f\"\\nðŸŽ¯ Probability calculation:\")\n",
    "        print(f\"  P(default) = 1 / (1 + e^(-{total_log_odds:.3f})) = {total_probability:.4f}\")\n",
    "        \n",
    "        # =============== 9. HYPERPARAMETER TUNING (OPTIONAL) ===============\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"STEP 9: HYPERPARAMETER TUNING (OPTIONAL)\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Ask user if they want to proceed with tuning\n",
    "        try:\n",
    "            tuning_choice = input(\"Perform hyperparameter tuning? This may take time. (y/n): \").strip().lower()\n",
    "        except:\n",
    "            tuning_choice = 'n'  # Default to no if input fails\n",
    "        \n",
    "        if tuning_choice == 'y':\n",
    "            print(\"Performing hyperparameter tuning with GridSearchCV...\")\n",
    "            try:\n",
    "                from sklearn.model_selection import GridSearchCV\n",
    "                \n",
    "                # Simple parameter grid for speed\n",
    "                param_grid = {\n",
    "                    'C': [0.1, 1, 10],\n",
    "                    'class_weight': [None, 'balanced']\n",
    "                }\n",
    "                \n",
    "                grid_search = GridSearchCV(\n",
    "                    LogisticRegression(random_state=42, max_iter=2000, solver='lbfgs'),\n",
    "                    param_grid=param_grid,\n",
    "                    cv=3,\n",
    "                    scoring='accuracy',\n",
    "                    n_jobs=-1,\n",
    "                    verbose=1\n",
    "                )\n",
    "                \n",
    "                grid_search.fit(X_train_scaled, y_train)\n",
    "                \n",
    "                print(f\"âœ… Tuning complete!\")\n",
    "                print(f\"ðŸ† Best Parameters: {grid_search.best_params_}\")\n",
    "                print(f\"ðŸ† Best CV Score: {grid_search.best_score_:.4f}\")\n",
    "                \n",
    "                # Compare with original model\n",
    "                print(f\"\\nðŸ“Š Comparison with Original Model:\")\n",
    "                print(f\"  Original Accuracy: {accuracy:.4f}\")\n",
    "                print(f\"  Tuned CV Score: {grid_search.best_score_:.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸  Hyperparameter tuning failed: {str(e)}\")\n",
    "                print(\"Continuing with current model...\")\n",
    "        else:\n",
    "            print(\"Skipping hyperparameter tuning.\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"MODEL EVALUATION COMPLETE!\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ No features available for analysis.\")\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ Cannot perform evaluation - no properly trained model available.\")\n",
    "    print(\"\\nTroubleshooting steps:\")\n",
    "    print(\"1. Make sure your DataFrame 'df' exists with required columns\")\n",
    "    print(\"2. Check that STEP 3 created the 'Default' column properly\")\n",
    "    print(\"3. Ensure you have both default and non-default cases\")\n",
    "    print(\"4. Consider lowering the PD threshold in STEP 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce2359cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame info:\n",
      "df exists: True\n",
      "df shape: (188748, 33)\n",
      "Columns: ['Branch', 'FacilityAmount', 'Granted Date', 'Tenor', 'Effective Rate', 'FlatRate', 'Type of Rental Paid', 'SchemeType', 'Prepayment', 'NetRental', 'DownPayment', 'No of Rental in arrears', 'Age', 'ArrearsCapital', 'ArrearsInterest', 'ArrearsVat', 'ArrearsOD', 'ArrearsOther', 'ArrearsInsu', 'ArrearsSundry', 'Advance', 'AdvanceRental', 'AdvanceSundry', 'AdvanceOther', 'Equipment Type', 'Status', 'Last Receipt Paid Amount', 'NET-OUTSTANDING', 'ArrearsInsuEasyPay', 'arrears_intensity', 'PD_Score', 'Risk_Category', 'Default']\n",
      "Default value counts: {0: 169873, 1: 18875}\n",
      "PD_Score stats: min=0.000, max=0.220, mean=0.033\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic code\n",
    "print(\"DataFrame info:\")\n",
    "print(f\"df exists: {'df' in locals()}\")\n",
    "if 'df' in locals():\n",
    "    print(f\"df shape: {df.shape}\")\n",
    "    print(\"Columns:\", df.columns.tolist())\n",
    "    if 'Default' in df.columns:\n",
    "        print(f\"Default value counts: {df['Default'].value_counts().to_dict()}\")\n",
    "    if 'PD_Score' in df.columns:\n",
    "        print(f\"PD_Score stats: min={df['PD_Score'].min():.3f}, max={df['PD_Score'].max():.3f}, mean={df['PD_Score'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "460b386d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 8: MODEL EVALUATION & INTERPRETATION\n",
      "======================================================================\n",
      "âš ï¸  No properly trained logistic regression model found.\n",
      "Checking data availability and training model...\n",
      "âœ“ DataFrame found. Checking target variable...\n",
      "âœ“ Created X and y\n",
      "  X shape: (188748, 30)\n",
      "  y shape: (188748,)\n",
      "  Class distribution: {0: 169873, 1: 18875}\n",
      "\n",
      "âœ“ Final class distribution: {0: 169873, 1: 18875}\n",
      "âœ“ Data split complete:\n",
      "  Training set: (150998, 30)\n",
      "  Test set: (37750, 30)\n",
      "  Training class distribution: [135898  15100]\n",
      "  Test class distribution: [33975  3775]\n",
      "\n",
      "Scaling features...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'MINUWANGODA'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_17268\\2054269023.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    118\u001b[39m \n\u001b[32m    119\u001b[39m             \u001b[38;5;66;03m# Scale the data\u001b[39;00m\n\u001b[32m    120\u001b[39m             print(\u001b[33m\"\\nScaling features...\"\u001b[39m)\n\u001b[32m    121\u001b[39m             scaler = StandardScaler()\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m             X_train_scaled = scaler.fit_transform(X_train)\n\u001b[32m    123\u001b[39m             X_test_scaled = scaler.transform(X_test)\n\u001b[32m    124\u001b[39m             X_scaled = scaler.transform(X)\n\u001b[32m    125\u001b[39m \n",
      "\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m     @wraps(f)\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m wrapped(self, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m         data_to_wrap = f(self, X, *args, **kwargs)\n\u001b[32m    317\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m isinstance(data_to_wrap, tuple):\n\u001b[32m    318\u001b[39m             \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m             return_tuple = (\n",
      "\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    890\u001b[39m                 )\n\u001b[32m    891\u001b[39m \n\u001b[32m    892\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    893\u001b[39m             \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, **fit_params).transform(X)\n\u001b[32m    895\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    896\u001b[39m             \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    897\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    903\u001b[39m             Fitted scaler.\n\u001b[32m    904\u001b[39m         \"\"\"\n\u001b[32m    905\u001b[39m         \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[32m    906\u001b[39m         self._reset()\n\u001b[32m--> \u001b[39m\u001b[32m907\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self.partial_fit(X, y, sample_weight)\n",
      "\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1361\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m                 )\n\u001b[32m   1364\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    939\u001b[39m         self : object\n\u001b[32m    940\u001b[39m             Fitted scaler.\n\u001b[32m    941\u001b[39m         \"\"\"\n\u001b[32m    942\u001b[39m         first_call = \u001b[38;5;28;01mnot\u001b[39;00m hasattr(self, \u001b[33m\"n_samples_seen_\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m943\u001b[39m         X = validate_data(\n\u001b[32m    944\u001b[39m             self,\n\u001b[32m    945\u001b[39m             X,\n\u001b[32m    946\u001b[39m             accept_sparse=(\u001b[33m\"csr\"\u001b[39m, \u001b[33m\"csc\"\u001b[39m),\n",
      "\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2950\u001b[39m             out = y\n\u001b[32m   2951\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2952\u001b[39m             out = X, y\n\u001b[32m   2953\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2954\u001b[39m         out = check_array(X, input_name=\u001b[33m\"X\"\u001b[39m, **check_params)\n\u001b[32m   2955\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2956\u001b[39m         out = _check_y(y, **check_params)\n\u001b[32m   2957\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1050\u001b[39m                         )\n\u001b[32m   1051\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1052\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1053\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1054\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1055\u001b[39m                 raise ValueError(\n\u001b[32m   1056\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1057\u001b[39m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m complex_warning\n",
      "\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    754\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    755\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    756\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    758\u001b[39m \n\u001b[32m    759\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    760\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2167\u001b[39m             )\n\u001b[32m   2168\u001b[39m         values = self._values\n\u001b[32m   2169\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2170\u001b[39m             \u001b[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2171\u001b[39m             arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2172\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2173\u001b[39m             arr = np.array(values, dtype=dtype, copy=copy)\n\u001b[32m   2174\u001b[39m \n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'MINUWANGODA'"
     ]
    }
   ],
   "source": [
    "# =============== 8. MODEL EVALUATION & INTERPRETATION ===============\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 8: MODEL EVALUATION & INTERPRETATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Function to check if model is properly trained\n",
    "def is_model_trained(model):\n",
    "    \"\"\"Check if a sklearn model has been trained\"\"\"\n",
    "    if model is None:\n",
    "        return False\n",
    "    # For logistic regression, check for coef_ attribute\n",
    "    if hasattr(model, 'coef_'):\n",
    "        return model.coef_ is not None\n",
    "    # For other models with different attributes\n",
    "    if hasattr(model, 'estimators_'):  # For ensemble models\n",
    "        return model.estimators_ is not None\n",
    "    if hasattr(model, 'support_vectors_'):  # For SVM\n",
    "        return model.support_vectors_ is not None\n",
    "    return False\n",
    "\n",
    "# Check if we have a properly trained model\n",
    "if 'log_reg' not in locals() or not is_model_trained(log_reg):\n",
    "    print(\"âš ï¸  No properly trained logistic regression model found.\")\n",
    "    print(\"Checking data availability and training model...\")\n",
    "    \n",
    "    # Import necessary libraries\n",
    "    from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    # First, check if we have the original data\n",
    "    if 'df' not in locals():\n",
    "        print(\"âŒ DataFrame 'df' not found.\")\n",
    "        print(\"Please load or create your data first.\")\n",
    "        log_reg = None\n",
    "    else:\n",
    "        print(\"âœ“ DataFrame found. Checking target variable...\")\n",
    "        \n",
    "        # Check if Default column exists\n",
    "        if 'Default' not in df.columns:\n",
    "            print(\"âŒ 'Default' column not found in DataFrame.\")\n",
    "            print(\"Creating target variable based on PD_Score...\")\n",
    "            \n",
    "            if 'PD_Score' in df.columns:\n",
    "                # Use dynamic threshold based on quantile\n",
    "                threshold = df['PD_Score'].quantile(0.75)\n",
    "                df['Default'] = (df['PD_Score'] >= threshold).astype(int)\n",
    "                print(f\"Created 'Default' column with threshold {threshold:.3f}\")\n",
    "                print(f\"Default rate: {df['Default'].mean():.2%}\")\n",
    "            else:\n",
    "                print(\"âŒ 'PD_Score' column also not found.\")\n",
    "                print(\"Please run STEP 3 first to create PD_Score.\")\n",
    "                log_reg = None\n",
    "        \n",
    "        # If we have Default column, proceed\n",
    "        if 'Default' in df.columns:\n",
    "            # Create X and y\n",
    "            target_columns = ['Default', 'Risk_Category', 'PD_Score']\n",
    "            X = df.drop([col for col in target_columns if col in df.columns], axis=1)\n",
    "            y = df['Default']\n",
    "            \n",
    "            print(f\"âœ“ Created X and y\")\n",
    "            print(f\"  X shape: {X.shape}\")\n",
    "            print(f\"  y shape: {y.shape}\")\n",
    "            print(f\"  Class distribution: {y.value_counts().to_dict()}\")\n",
    "            \n",
    "            # Check if we have both classes\n",
    "            if len(y.unique()) < 2:\n",
    "                print(\"âŒ Still only one class in target variable.\")\n",
    "                print(\"Adjusting threshold to create more balanced classes...\")\n",
    "                \n",
    "                # Try different thresholds\n",
    "                if 'PD_Score' in df.columns:\n",
    "                    for quantile in [0.9, 0.8, 0.7, 0.6, 0.5]:\n",
    "                        threshold = df['PD_Score'].quantile(quantile)\n",
    "                        df['Default'] = (df['PD_Score'] >= threshold).astype(int)\n",
    "                        if len(df['Default'].unique()) > 1:\n",
    "                            print(f\"âœ“ Found working threshold at {quantile*100}% quantile: {threshold:.3f}\")\n",
    "                            print(f\"  Default rate: {df['Default'].mean():.2%}\")\n",
    "                            break\n",
    "                    \n",
    "                    # Update X and y\n",
    "                    X = df.drop([col for col in target_columns if col in df.columns], axis=1)\n",
    "                    y = df['Default']\n",
    "            \n",
    "            # Check again if we have both classes\n",
    "            if len(y.unique()) < 2:\n",
    "                print(\"âŒ Could not create balanced classes.\")\n",
    "                print(\"Creating synthetic minority class for demonstration...\")\n",
    "                \n",
    "                # Add a few synthetic defaults\n",
    "                n_samples = len(y)\n",
    "                n_defaults = max(1, int(n_samples * 0.05))  # At least 5% defaults\n",
    "                \n",
    "                # Randomly select samples to mark as default\n",
    "                default_indices = np.random.choice(n_samples, n_defaults, replace=False)\n",
    "                y.iloc[default_indices] = 1\n",
    "                \n",
    "                print(f\"Created {n_defaults} synthetic defaults\")\n",
    "                print(f\"New class distribution: {y.value_counts().to_dict()}\")\n",
    "            \n",
    "            # Now we should have both classes\n",
    "            print(f\"\\nâœ“ Final class distribution: {y.value_counts().to_dict()}\")\n",
    "            \n",
    "            # Split the data with stratification\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, random_state=42, stratify=y\n",
    "            )\n",
    "            \n",
    "            print(f\"âœ“ Data split complete:\")\n",
    "            print(f\"  Training set: {X_train.shape}\")\n",
    "            print(f\"  Test set: {X_test.shape}\")\n",
    "            print(f\"  Training class distribution: {np.bincount(y_train)}\")\n",
    "            print(f\"  Test class distribution: {np.bincount(y_test)}\")\n",
    "            \n",
    "            # Scale the data\n",
    "            print(\"\\nScaling features...\")\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            X_scaled = scaler.transform(X)\n",
    "            \n",
    "            # Train logistic regression\n",
    "            print(\"Training Logistic Regression model...\")\n",
    "            try:\n",
    "                log_reg = LogisticRegression(\n",
    "                    random_state=42,\n",
    "                    max_iter=2000,  # Increased for convergence\n",
    "                    class_weight='balanced',\n",
    "                    solver='lbfgs',\n",
    "                    C=1.0\n",
    "                )\n",
    "                \n",
    "                log_reg.fit(X_train_scaled, y_train)\n",
    "                \n",
    "                # Check if training was successful\n",
    "                if hasattr(log_reg, 'coef_') and log_reg.coef_ is not None:\n",
    "                    print(\"âœ… Logistic regression model trained successfully!\")\n",
    "                    \n",
    "                    # Make predictions for evaluation\n",
    "                    y_pred = log_reg.predict(X_test_scaled)\n",
    "                    y_pred_proba = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
    "                    accuracy = accuracy_score(y_test, y_pred)\n",
    "                    \n",
    "                    print(f\"\\nðŸ“Š Initial Model Performance:\")\n",
    "                    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "                    print(f\"  Default Rate in Test: {y_test.mean():.2%}\")\n",
    "                else:\n",
    "                    print(\"âŒ Model training failed - no coefficients generated\")\n",
    "                    log_reg = None\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Model training failed: {str(e)}\")\n",
    "                log_reg = None\n",
    "\n",
    "else:\n",
    "    print(\"âœ… Using existing trained model...\")\n",
    "\n",
    "# Only proceed if we have a properly trained model\n",
    "if log_reg is not None and hasattr(log_reg, 'coef_') and log_reg.coef_ is not None:\n",
    "    # 8.1 Cross-validation\n",
    "    print(\"\\nðŸ” Performing 5-fold Cross-Validation...\")\n",
    "    try:\n",
    "        # Use stratified K-fold\n",
    "        cv = StratifiedKFold(n_splits=min(5, len(np.unique(y))), shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(log_reg, X_scaled, y, cv=cv, scoring='accuracy')\n",
    "        print(f\"Cross-validation scores: {cv_scores}\")\n",
    "        print(f\"Mean CV Accuracy: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Error in cross-validation: {str(e)}\")\n",
    "        if 'accuracy' in locals():\n",
    "            print(f\"Using train/test accuracy: {accuracy:.4f}\")\n",
    "        cv_scores = None\n",
    "    \n",
    "    # 8.2 Calculate odds ratios for interpretation\n",
    "    # Get feature names\n",
    "    if 'X' in locals() and hasattr(X, 'columns'):\n",
    "        available_features = X.columns.tolist()\n",
    "    elif 'X_train' in locals() and hasattr(X_train, 'columns'):\n",
    "        available_features = X_train.columns.tolist()\n",
    "    else:\n",
    "        # Create generic feature names\n",
    "        n_features = log_reg.coef_.shape[1] if hasattr(log_reg, 'coef_') else 0\n",
    "        available_features = [f'Feature_{i}' for i in range(n_features)]\n",
    "        print(f\"âš ï¸  Using generic feature names for {n_features} features\")\n",
    "    \n",
    "    if len(available_features) > 0:\n",
    "        odds_ratios = pd.DataFrame({\n",
    "            'Feature': available_features,\n",
    "            'Coefficient': log_reg.coef_[0],\n",
    "            'Odds_Ratio': np.exp(log_reg.coef_[0])\n",
    "        }).sort_values('Odds_Ratio', ascending=False)\n",
    "        \n",
    "        print(\"\\nðŸ“Š Odds Ratios Interpretation:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(\"Odds Ratio > 1: Increases odds of default\")\n",
    "        print(\"Odds Ratio < 1: Decreases odds of default\")\n",
    "        print(\"Odds Ratio = 1: No effect\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        print(\"\\nTop 5 Features Increasing Default Odds (Odds Ratio > 1):\")\n",
    "        top_features = odds_ratios[odds_ratios['Odds_Ratio'] > 1].head()\n",
    "        for idx, row in top_features.iterrows():\n",
    "            print(f\"  {row['Feature']:30s}: {row['Odds_Ratio']:.3f} (Coefficient: {row['Coefficient']:.3f})\")\n",
    "        \n",
    "        print(\"\\nTop 5 Features Decreasing Default Odds (Odds Ratio < 1):\")\n",
    "        bottom_features = odds_ratios[odds_ratios['Odds_Ratio'] < 1].tail()\n",
    "        for idx, row in bottom_features.iterrows():\n",
    "            print(f\"  {row['Feature']:30s}: {row['Odds_Ratio']:.3f} (Coefficient: {row['Coefficient']:.3f})\")\n",
    "        \n",
    "        # 8.3 Model interpretation for a specific example\n",
    "        print(\"\\nðŸ”® Model Interpretation for Example Customer:\")\n",
    "        \n",
    "        # Try to get a realistic example from the data\n",
    "        if 'df' in locals() and 'Default' in df.columns:\n",
    "            # Get a non-default example\n",
    "            non_default_examples = df[df['Default'] == 0].head(1)\n",
    "            if len(non_default_examples) > 0:\n",
    "                example_features = non_default_examples.drop(['Default', 'Risk_Category', 'PD_Score'], \n",
    "                                                              axis=1, errors='ignore').iloc[0].to_dict()\n",
    "                actual_class = 0\n",
    "            else:\n",
    "                # Get any example\n",
    "                example_features = df.drop(['Default', 'Risk_Category', 'PD_Score'], \n",
    "                                          axis=1, errors='ignore').iloc[0].to_dict()\n",
    "                actual_class = df['Default'].iloc[0] if 'Default' in df.columns else 0\n",
    "            \n",
    "            print(\"Using actual customer data from dataset...\")\n",
    "        else:\n",
    "            # Create a synthetic example\n",
    "            example_features = {\n",
    "                'FacilityAmount': 300000.0,\n",
    "                'Tenor': 36,\n",
    "                'Effective Rate': 15.0,\n",
    "                'NetRental': 12000.0,\n",
    "                'Age': 35.0,\n",
    "                'No of Rental in arrears': 0.0,\n",
    "                'debt_to_income_ratio': 25.0,\n",
    "            }\n",
    "            actual_class = 0\n",
    "            print(\"Using synthetic example data...\")\n",
    "        \n",
    "        # Create DataFrame for example\n",
    "        example_df = pd.DataFrame([example_features])\n",
    "        \n",
    "        # Ensure all features are present\n",
    "        missing_features = []\n",
    "        for feat in available_features:\n",
    "            if feat not in example_df.columns:\n",
    "                example_df[feat] = 0  # Fill missing with 0\n",
    "                missing_features.append(feat)\n",
    "        \n",
    "        if missing_features:\n",
    "            print(f\"Note: {len(missing_features)} features not in example, set to 0\")\n",
    "        \n",
    "        # Reorder columns\n",
    "        example_df = example_df[available_features]\n",
    "        \n",
    "        # Scale features\n",
    "        example_scaled = scaler.transform(example_df)\n",
    "        \n",
    "        # Make prediction\n",
    "        example_pred = log_reg.predict(example_scaled)[0]\n",
    "        example_proba = log_reg.predict_proba(example_scaled)[0][1]\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Prediction for Example Customer:\")\n",
    "        print(f\"  Actual Class: {'Default' if actual_class == 1 else 'Non-Default'}\")\n",
    "        print(f\"  Predicted Class: {'Default' if example_pred == 1 else 'Non-Default'}\")\n",
    "        print(f\"  Probability of Default: {example_proba:.4f} ({example_proba*100:.1f}%)\")\n",
    "        \n",
    "        # Define risk categories\n",
    "        def create_risk_category(pd_score):\n",
    "            if pd_score >= 0.80:\n",
    "                return 'High Risk'\n",
    "            elif pd_score >= 0.20:\n",
    "                return 'Medium Risk'\n",
    "            else:\n",
    "                return 'Low Risk'\n",
    "        \n",
    "        print(f\"  Risk Category: {create_risk_category(example_proba)}\")\n",
    "        \n",
    "        # Calculate contribution of top features\n",
    "        print(f\"\\nðŸ” Top Feature Contributions to Prediction:\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        intercept = log_reg.intercept_[0]\n",
    "        \n",
    "        # Calculate contributions\n",
    "        contributions = []\n",
    "        for i, feature in enumerate(available_features):\n",
    "            feature_value = example_scaled[0][i]\n",
    "            coefficient = log_reg.coef_[0][i]\n",
    "            contribution = feature_value * coefficient\n",
    "            contributions.append((feature, feature_value, coefficient, contribution))\n",
    "        \n",
    "        # Sort by absolute contribution\n",
    "        contributions.sort(key=lambda x: abs(x[3]), reverse=True)\n",
    "        \n",
    "        print(f\"{'Feature':30s} {'Scaled Val':>10} {'Coef':>10} {'Contribution':>12}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        total_log_odds = intercept\n",
    "        for i, (feature, feature_value, coefficient, contribution) in enumerate(contributions[:10]):\n",
    "            total_log_odds += contribution\n",
    "            if i < 5:  # Show only top 5\n",
    "                print(f\"{feature:30s} {feature_value:10.3f} {coefficient:10.3f} {contribution:12.3f}\")\n",
    "        \n",
    "        if len(contributions) > 5:\n",
    "            other_contrib = sum(c[3] for c in contributions[5:])\n",
    "            print(f\"{'Other features':30s} {'...':10} {'...':10} {other_contrib:12.3f}\")\n",
    "            total_log_odds += other_contrib\n",
    "        \n",
    "        print(f\"{'Intercept':30s} {'':10} {'':10} {intercept:12.3f}\")\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"{'TOTAL LOG-ODDS':30s} {'':10} {'':10} {total_log_odds:12.3f}\")\n",
    "        \n",
    "        # Convert to probability\n",
    "        total_probability = 1 / (1 + np.exp(-total_log_odds))\n",
    "        print(f\"\\nðŸŽ¯ Probability calculation:\")\n",
    "        print(f\"  P(default) = 1 / (1 + e^(-{total_log_odds:.3f})) = {total_probability:.4f}\")\n",
    "        \n",
    "        # =============== 9. HYPERPARAMETER TUNING (OPTIONAL) ===============\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"STEP 9: HYPERPARAMETER TUNING (OPTIONAL)\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Ask user if they want to proceed with tuning\n",
    "        try:\n",
    "            tuning_choice = input(\"Perform hyperparameter tuning? This may take time. (y/n): \").strip().lower()\n",
    "        except:\n",
    "            tuning_choice = 'n'  # Default to no if input fails\n",
    "        \n",
    "        if tuning_choice == 'y':\n",
    "            print(\"Performing hyperparameter tuning with GridSearchCV...\")\n",
    "            try:\n",
    "                from sklearn.model_selection import GridSearchCV\n",
    "                \n",
    "                # Simple parameter grid for speed\n",
    "                param_grid = {\n",
    "                    'C': [0.1, 1, 10],\n",
    "                    'class_weight': [None, 'balanced']\n",
    "                }\n",
    "                \n",
    "                grid_search = GridSearchCV(\n",
    "                    LogisticRegression(random_state=42, max_iter=2000, solver='lbfgs'),\n",
    "                    param_grid=param_grid,\n",
    "                    cv=3,\n",
    "                    scoring='accuracy',\n",
    "                    n_jobs=-1,\n",
    "                    verbose=1\n",
    "                )\n",
    "                \n",
    "                grid_search.fit(X_train_scaled, y_train)\n",
    "                \n",
    "                print(f\"âœ… Tuning complete!\")\n",
    "                print(f\"ðŸ† Best Parameters: {grid_search.best_params_}\")\n",
    "                print(f\"ðŸ† Best CV Score: {grid_search.best_score_:.4f}\")\n",
    "                \n",
    "                # Compare with original model\n",
    "                print(f\"\\nðŸ“Š Comparison with Original Model:\")\n",
    "                print(f\"  Original Accuracy: {accuracy:.4f}\")\n",
    "                print(f\"  Tuned CV Score: {grid_search.best_score_:.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸  Hyperparameter tuning failed: {str(e)}\")\n",
    "                print(\"Continuing with current model...\")\n",
    "        else:\n",
    "            print(\"Skipping hyperparameter tuning.\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"MODEL EVALUATION COMPLETE!\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ No features available for analysis.\")\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ Cannot perform evaluation - no properly trained model available.\")\n",
    "    print(\"\\nTroubleshooting steps:\")\n",
    "    print(\"1. Make sure your DataFrame 'df' exists with required columns\")\n",
    "    print(\"2. Check that STEP 3 created the 'Default' column properly\")\n",
    "    print(\"3. Ensure you have both default and non-default cases\")\n",
    "    print(\"4. Consider lowering the PD threshold in STEP 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68763896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 8: MODEL EVALUATION & INTERPRETATION\n",
      "======================================================================\n",
      "âš ï¸  No properly trained logistic regression model found.\n",
      "Checking data availability and training model...\n",
      "âœ“ DataFrame found. Shape: (188748, 33)\n",
      "Columns: ['Branch', 'FacilityAmount', 'Granted Date', 'Tenor', 'Effective Rate', 'FlatRate', 'Type of Rental Paid', 'SchemeType', 'Prepayment', 'NetRental', 'DownPayment', 'No of Rental in arrears', 'Age', 'ArrearsCapital', 'ArrearsInterest', 'ArrearsVat', 'ArrearsOD', 'ArrearsOther', 'ArrearsInsu', 'ArrearsSundry', 'Advance', 'AdvanceRental', 'AdvanceSundry', 'AdvanceOther', 'Equipment Type', 'Status', 'Last Receipt Paid Amount', 'NET-OUTSTANDING', 'ArrearsInsuEasyPay', 'arrears_intensity', 'PD_Score', 'Risk_Category', 'Default']\n",
      "\n",
      "ðŸ” Checking data types and preparing features...\n",
      "Categorical columns (7): ['Branch', 'Granted Date', 'Type of Rental Paid', 'SchemeType', 'Equipment Type', 'Status', 'Risk_Category']\n",
      "Numeric columns (26): ['FacilityAmount', 'Tenor', 'Effective Rate', 'FlatRate', 'Prepayment', 'NetRental', 'DownPayment', 'No of Rental in arrears', 'Age', 'ArrearsCapital']...\n",
      "\n",
      "ðŸ“Š Preparing features...\n",
      "  Encoding Branch...\n",
      "  Encoding Granted Date...\n",
      "  Encoding Type of Rental Paid...\n",
      "  Encoding SchemeType...\n",
      "  Encoding Equipment Type...\n",
      "  Encoding Status...\n",
      "\n",
      "âœ“ Created X and y\n",
      "  X shape: (188748, 30)\n",
      "  y shape: (188748,)\n",
      "  Class distribution: {0: 169873, 1: 18875}\n",
      "\n",
      "ðŸ“Š X data types:\n",
      "float64    19\n",
      "int64      11\n",
      "Name: count, dtype: int64\n",
      "\n",
      "âœ“ Final class distribution: {0: 169873, 1: 18875}\n",
      "\n",
      "ðŸ”€ Splitting data into train/test sets...\n",
      "âœ“ Data split complete:\n",
      "  Training set: (150998, 30)\n",
      "  Test set: (37750, 30)\n",
      "  Training class distribution: [135898  15100]\n",
      "  Test class distribution: [33975  3775]\n",
      "\n",
      "âš–ï¸  Scaling features...\n",
      "âš ï¸  Found constant columns: ['Type of Rental Paid', 'Prepayment', 'ArrearsVat', 'AdvanceSundry', 'AdvanceOther']\n",
      "Removing constant columns...\n",
      "Scaling 25 features...\n",
      "âœ“ Features scaled successfully!\n",
      "\n",
      "ðŸ¤– Training Logistic Regression model...\n",
      "âœ… Logistic regression model trained successfully!\n",
      "\n",
      "ðŸ“Š Initial Model Performance:\n",
      "  Accuracy: 0.8850\n",
      "  Default Rate in Test: 10.00%\n",
      "  Number of features: 25\n",
      "\n",
      "======================================================================\n",
      "MODEL EVALUATION & INTERPRETATION\n",
      "======================================================================\n",
      "\n",
      "ðŸ” Performing 5-fold Cross-Validation...\n",
      "Cross-validation scores: [0.88707695 0.87939475]\n",
      "Mean CV Accuracy: 0.8832 (Â±0.0038)\n",
      "\n",
      "ðŸ“Š Odds Ratios Interpretation:\n",
      "--------------------------------------------------\n",
      "Odds Ratio > 1: Increases odds of default\n",
      "Odds Ratio < 1: Decreases odds of default\n",
      "Odds Ratio = 1: No effect\n",
      "--------------------------------------------------\n",
      "\n",
      "Top 5 Features Increasing Default Odds (Odds Ratio > 1):\n",
      "  No of Rental in arrears       : 36.529 (Coefficient: 3.598)\n",
      "  ArrearsCapital                : 6.414 (Coefficient: 1.859)\n",
      "  NET-OUTSTANDING               : 2.669 (Coefficient: 0.982)\n",
      "  Age                           : 2.407 (Coefficient: 0.878)\n",
      "  FlatRate                      : 1.768 (Coefficient: 0.570)\n",
      "\n",
      "Top 5 Features Decreasing Default Odds (Odds Ratio < 1):\n",
      "  Granted Date                  : 0.897 (Coefficient: -0.109)\n",
      "  ArrearsOther                  : 0.862 (Coefficient: -0.148)\n",
      "  Advance                       : 0.852 (Coefficient: -0.160)\n",
      "  Status                        : 0.808 (Coefficient: -0.214)\n",
      "  ArrearsInterest               : 0.206 (Coefficient: -1.581)\n",
      "\n",
      "ðŸ’¾ Feature odds ratios saved to 'feature_odds_ratios.csv'\n",
      "\n",
      "ðŸ”® Model Interpretation for Example Customer:\n",
      "Using customer #0 from dataset (Non-Default)...\n",
      "\n",
      "ðŸ“Š Prediction for Example Customer:\n",
      "  Actual Class: Non-Default\n",
      "  Predicted Class: Non-Default\n",
      "  Probability of Default: 0.0437 (4.4%)\n",
      "  Risk Category: Low Risk\n",
      "\n",
      "ðŸ” Top 5 Feature Contributions to Prediction:\n",
      "----------------------------------------------------------------------\n",
      "Feature                          Scaled Val         Coef    Contribution\n",
      "----------------------------------------------------------------------\n",
      "No of Rental in arrears              -0.290        3.598          -1.044\n",
      "NET-OUTSTANDING                      -0.408        0.982          -0.401\n",
      "Age                                  -0.303        0.878          -0.266\n",
      "ArrearsInterest                      -0.144       -1.581           0.228\n",
      "Effective Rate                       -0.917        0.222          -0.204\n",
      "----------------------------------------------------------------------\n",
      "Intercept                                                         -1.319\n",
      "Other 20 features                                                 -0.081\n",
      "----------------------------------------------------------------------\n",
      "TOTAL LOG-ODDS                                                    -3.085\n",
      "\n",
      "ðŸŽ¯ Probability calculation:\n",
      "  P(default) = 1 / (1 + e^(--3.085)) = 0.0437\n",
      "\n",
      "======================================================================\n",
      "MODEL EVALUATION COMPLETE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============== 8. MODEL EVALUATION & INTERPRETATION ===============\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 8: MODEL EVALUATION & INTERPRETATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Function to check if model is properly trained\n",
    "def is_model_trained(model):\n",
    "    \"\"\"Check if a sklearn model has been trained\"\"\"\n",
    "    if model is None:\n",
    "        return False\n",
    "    # For logistic regression, check for coef_ attribute\n",
    "    if hasattr(model, 'coef_'):\n",
    "        return model.coef_ is not None\n",
    "    return False\n",
    "\n",
    "# Check if we have a properly trained model\n",
    "if 'log_reg' not in locals() or not is_model_trained(log_reg):\n",
    "    print(\"âš ï¸  No properly trained logistic regression model found.\")\n",
    "    print(\"Checking data availability and training model...\")\n",
    "    \n",
    "    # Import necessary libraries\n",
    "    from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    # First, check if we have the original data\n",
    "    if 'df' not in locals():\n",
    "        print(\"âŒ DataFrame 'df' not found.\")\n",
    "        print(\"Please load or create your data first.\")\n",
    "        log_reg = None\n",
    "    else:\n",
    "        print(\"âœ“ DataFrame found. Shape:\", df.shape)\n",
    "        print(\"Columns:\", df.columns.tolist())\n",
    "        \n",
    "        # Check if Default column exists\n",
    "        if 'Default' not in df.columns:\n",
    "            print(\"âŒ 'Default' column not found in DataFrame.\")\n",
    "            print(\"Creating target variable based on PD_Score...\")\n",
    "            \n",
    "            if 'PD_Score' in df.columns:\n",
    "                # Use dynamic threshold based on quantile\n",
    "                threshold = df['PD_Score'].quantile(0.75)\n",
    "                df['Default'] = (df['PD_Score'] >= threshold).astype(int)\n",
    "                print(f\"Created 'Default' column with threshold {threshold:.3f}\")\n",
    "                print(f\"Default rate: {df['Default'].mean():.2%}\")\n",
    "            else:\n",
    "                print(\"âŒ 'PD_Score' column also not found.\")\n",
    "                print(\"Please run STEP 3 first to create PD_Score.\")\n",
    "                log_reg = None\n",
    "        \n",
    "        # If we have Default column, proceed\n",
    "        if 'Default' in df.columns:\n",
    "            print(f\"\\nðŸ” Checking data types and preparing features...\")\n",
    "            \n",
    "            # Identify categorical and numeric columns\n",
    "            categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "            \n",
    "            print(f\"Categorical columns ({len(categorical_cols)}): {categorical_cols}\")\n",
    "            print(f\"Numeric columns ({len(numeric_cols)}): {numeric_cols[:10]}...\")  # Show first 10\n",
    "            \n",
    "            # Target columns to drop\n",
    "            target_columns = ['Default', 'Risk_Category', 'PD_Score']\n",
    "            target_columns = [col for col in target_columns if col in df.columns]\n",
    "            \n",
    "            # Prepare features\n",
    "            print(\"\\nðŸ“Š Preparing features...\")\n",
    "            \n",
    "            # First, let's encode categorical variables\n",
    "            df_encoded = df.copy()\n",
    "            \n",
    "            # Encode categorical columns\n",
    "            label_encoders = {}\n",
    "            for col in categorical_cols:\n",
    "                if col not in target_columns:  # Don't encode target columns\n",
    "                    print(f\"  Encoding {col}...\")\n",
    "                    le = LabelEncoder()\n",
    "                    df_encoded[col] = le.fit_transform(df_encoded[col].astype(str).fillna('Unknown'))\n",
    "                    label_encoders[col] = le\n",
    "            \n",
    "            # Create X and y\n",
    "            X = df_encoded.drop(target_columns, axis=1, errors='ignore')\n",
    "            y = df_encoded['Default']\n",
    "            \n",
    "            print(f\"\\nâœ“ Created X and y\")\n",
    "            print(f\"  X shape: {X.shape}\")\n",
    "            print(f\"  y shape: {y.shape}\")\n",
    "            print(f\"  Class distribution: {y.value_counts().to_dict()}\")\n",
    "            \n",
    "            # Check data types\n",
    "            print(f\"\\nðŸ“Š X data types:\")\n",
    "            print(X.dtypes.value_counts())\n",
    "            \n",
    "            # Check if we have both classes\n",
    "            if len(y.unique()) < 2:\n",
    "                print(\"\\nâŒ Only one class in target variable.\")\n",
    "                print(\"Creating balanced classes by adjusting threshold...\")\n",
    "                \n",
    "                if 'PD_Score' in df.columns:\n",
    "                    # Try to find a threshold that gives both classes\n",
    "                    for quantile in [0.9, 0.8, 0.7, 0.6, 0.5]:\n",
    "                        threshold = df['PD_Score'].quantile(quantile)\n",
    "                        temp_default = (df['PD_Score'] >= threshold).astype(int)\n",
    "                        if len(temp_default.unique()) > 1:\n",
    "                            print(f\"âœ“ Found working threshold at {quantile*100}% quantile: {threshold:.3f}\")\n",
    "                            df_encoded['Default'] = temp_default\n",
    "                            y = df_encoded['Default']\n",
    "                            print(f\"  New default rate: {y.mean():.2%}\")\n",
    "                            break\n",
    "                \n",
    "                # If still only one class, create synthetic minority\n",
    "                if len(y.unique()) < 2:\n",
    "                    print(\"Creating synthetic minority class...\")\n",
    "                    n_samples = len(y)\n",
    "                    n_defaults = max(1, int(n_samples * 0.05))\n",
    "                    default_indices = np.random.choice(n_samples, n_defaults, replace=False)\n",
    "                    y.iloc[default_indices] = 1\n",
    "                    df_encoded.loc[default_indices, 'Default'] = 1\n",
    "                    print(f\"Created {n_defaults} synthetic defaults\")\n",
    "            \n",
    "            print(f\"\\nâœ“ Final class distribution: {y.value_counts().to_dict()}\")\n",
    "            \n",
    "            # Check for any remaining non-numeric columns\n",
    "            non_numeric_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "            if non_numeric_cols:\n",
    "                print(f\"\\nâš ï¸  Found {len(non_numeric_cols)} non-numeric columns: {non_numeric_cols}\")\n",
    "                print(\"Converting to numeric...\")\n",
    "                for col in non_numeric_cols:\n",
    "                    X[col] = pd.to_numeric(X[col], errors='coerce').fillna(0)\n",
    "            \n",
    "            # Check for NaN values\n",
    "            nan_cols = X.columns[X.isna().any()].tolist()\n",
    "            if nan_cols:\n",
    "                print(f\"\\nâš ï¸  Found NaN values in columns: {nan_cols}\")\n",
    "                print(\"Filling NaN values with 0...\")\n",
    "                X = X.fillna(0)\n",
    "            \n",
    "            # Split the data with stratification\n",
    "            print(\"\\nðŸ”€ Splitting data into train/test sets...\")\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, random_state=42, stratify=y\n",
    "            )\n",
    "            \n",
    "            print(f\"âœ“ Data split complete:\")\n",
    "            print(f\"  Training set: {X_train.shape}\")\n",
    "            print(f\"  Test set: {X_test.shape}\")\n",
    "            print(f\"  Training class distribution: {np.bincount(y_train)}\")\n",
    "            print(f\"  Test class distribution: {np.bincount(y_test)}\")\n",
    "            \n",
    "            # Scale the data - IMPORTANT: Only scale numeric features\n",
    "            print(\"\\nâš–ï¸  Scaling features...\")\n",
    "            \n",
    "            # Identify columns to scale (all columns should be numeric now)\n",
    "            cols_to_scale = X.columns.tolist()\n",
    "            \n",
    "            # Check for constant columns (can cause issues with scaling)\n",
    "            constant_cols = [col for col in cols_to_scale if X_train[col].nunique() == 1]\n",
    "            if constant_cols:\n",
    "                print(f\"âš ï¸  Found constant columns: {constant_cols}\")\n",
    "                print(\"Removing constant columns...\")\n",
    "                cols_to_scale = [col for col in cols_to_scale if col not in constant_cols]\n",
    "                X_train = X_train[cols_to_scale]\n",
    "                X_test = X_test[cols_to_scale]\n",
    "                X = X[cols_to_scale]\n",
    "            \n",
    "            print(f\"Scaling {len(cols_to_scale)} features...\")\n",
    "            \n",
    "            # Initialize and fit scaler\n",
    "            scaler = StandardScaler()\n",
    "            \n",
    "            # Scale the features\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            X_scaled = scaler.transform(X)\n",
    "            \n",
    "            print(f\"âœ“ Features scaled successfully!\")\n",
    "            \n",
    "            # Train logistic regression\n",
    "            print(\"\\nðŸ¤– Training Logistic Regression model...\")\n",
    "            try:\n",
    "                log_reg = LogisticRegression(\n",
    "                    random_state=42,\n",
    "                    max_iter=2000,\n",
    "                    class_weight='balanced',\n",
    "                    solver='lbfgs',\n",
    "                    C=1.0,\n",
    "                    verbose=0\n",
    "                )\n",
    "                \n",
    "                log_reg.fit(X_train_scaled, y_train)\n",
    "                \n",
    "                # Check if training was successful\n",
    "                if hasattr(log_reg, 'coef_') and log_reg.coef_ is not None:\n",
    "                    print(\"âœ… Logistic regression model trained successfully!\")\n",
    "                    \n",
    "                    # Make predictions for evaluation\n",
    "                    y_pred = log_reg.predict(X_test_scaled)\n",
    "                    y_pred_proba = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
    "                    accuracy = accuracy_score(y_test, y_pred)\n",
    "                    \n",
    "                    print(f\"\\nðŸ“Š Initial Model Performance:\")\n",
    "                    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "                    print(f\"  Default Rate in Test: {y_test.mean():.2%}\")\n",
    "                    print(f\"  Number of features: {len(cols_to_scale)}\")\n",
    "                else:\n",
    "                    print(\"âŒ Model training failed - no coefficients generated\")\n",
    "                    log_reg = None\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Model training failed: {str(e)}\")\n",
    "                import traceback\n",
    "                print(\"Detailed error:\")\n",
    "                print(traceback.format_exc())\n",
    "                log_reg = None\n",
    "\n",
    "else:\n",
    "    print(\"âœ… Using existing trained model...\")\n",
    "\n",
    "# Only proceed if we have a properly trained model\n",
    "if log_reg is not None and hasattr(log_reg, 'coef_') and log_reg.coef_ is not None:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"MODEL EVALUATION & INTERPRETATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Get feature names\n",
    "    available_features = cols_to_scale\n",
    "    \n",
    "    # 8.1 Cross-validation\n",
    "    print(\"\\nðŸ” Performing 5-fold Cross-Validation...\")\n",
    "    try:\n",
    "        # Use stratified K-fold\n",
    "        cv = StratifiedKFold(n_splits=min(5, len(np.unique(y))), shuffle=True, random_state=42)\n",
    "        cv_scores = cross_val_score(log_reg, X_scaled, y, cv=cv, scoring='accuracy')\n",
    "        print(f\"Cross-validation scores: {cv_scores}\")\n",
    "        print(f\"Mean CV Accuracy: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Error in cross-validation: {str(e)}\")\n",
    "        if 'accuracy' in locals():\n",
    "            print(f\"Using train/test accuracy: {accuracy:.4f}\")\n",
    "        cv_scores = None\n",
    "    \n",
    "    # 8.2 Calculate odds ratios for interpretation\n",
    "    print(\"\\nðŸ“Š Odds Ratios Interpretation:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Odds Ratio > 1: Increases odds of default\")\n",
    "    print(\"Odds Ratio < 1: Decreases odds of default\")\n",
    "    print(\"Odds Ratio = 1: No effect\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    odds_ratios = pd.DataFrame({\n",
    "        'Feature': available_features,\n",
    "        'Coefficient': log_reg.coef_[0],\n",
    "        'Odds_Ratio': np.exp(log_reg.coef_[0])\n",
    "    }).sort_values('Odds_Ratio', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 5 Features Increasing Default Odds (Odds Ratio > 1):\")\n",
    "    top_features = odds_ratios[odds_ratios['Odds_Ratio'] > 1].head()\n",
    "    for idx, row in top_features.iterrows():\n",
    "        print(f\"  {row['Feature']:30s}: {row['Odds_Ratio']:.3f} (Coefficient: {row['Coefficient']:.3f})\")\n",
    "    \n",
    "    print(\"\\nTop 5 Features Decreasing Default Odds (Odds Ratio < 1):\")\n",
    "    bottom_features = odds_ratios[odds_ratios['Odds_Ratio'] < 1].tail()\n",
    "    for idx, row in bottom_features.iterrows():\n",
    "        print(f\"  {row['Feature']:30s}: {row['Odds_Ratio']:.3f} (Coefficient: {row['Coefficient']:.3f})\")\n",
    "    \n",
    "    # Save feature importance to CSV for later reference\n",
    "    odds_ratios.to_csv('feature_odds_ratios.csv', index=False)\n",
    "    print(\"\\nðŸ’¾ Feature odds ratios saved to 'feature_odds_ratios.csv'\")\n",
    "    \n",
    "    # 8.3 Model interpretation for a specific example\n",
    "    print(\"\\nðŸ”® Model Interpretation for Example Customer:\")\n",
    "    \n",
    "    # Get a real example from the data (first non-default customer)\n",
    "    if 'df_encoded' in locals():\n",
    "        non_default_idx = df_encoded[df_encoded['Default'] == 0].index[0]\n",
    "        example_features = X.iloc[non_default_idx].to_dict()\n",
    "        actual_class = 0\n",
    "        print(f\"Using customer #{non_default_idx} from dataset (Non-Default)...\")\n",
    "    else:\n",
    "        # Create a synthetic example using mean values\n",
    "        example_features = {}\n",
    "        for col in available_features:\n",
    "            if col in X.columns:\n",
    "                example_features[col] = X[col].mean()\n",
    "            else:\n",
    "                example_features[col] = 0\n",
    "        actual_class = 0\n",
    "        print(\"Using synthetic example with mean feature values...\")\n",
    "    \n",
    "    # Create DataFrame for example\n",
    "    example_df = pd.DataFrame([example_features])\n",
    "    \n",
    "    # Ensure all features are present in correct order\n",
    "    example_df = example_df[available_features]\n",
    "    \n",
    "    # Scale features\n",
    "    example_scaled = scaler.transform(example_df)\n",
    "    \n",
    "    # Make prediction\n",
    "    example_pred = log_reg.predict(example_scaled)[0]\n",
    "    example_proba = log_reg.predict_proba(example_scaled)[0][1]\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Prediction for Example Customer:\")\n",
    "    print(f\"  Actual Class: {'Default' if actual_class == 1 else 'Non-Default'}\")\n",
    "    print(f\"  Predicted Class: {'Default' if example_pred == 1 else 'Non-Default'}\")\n",
    "    print(f\"  Probability of Default: {example_proba:.4f} ({example_proba*100:.1f}%)\")\n",
    "    \n",
    "    # Define risk categories\n",
    "    def create_risk_category(pd_score):\n",
    "        if pd_score >= 0.80:\n",
    "            return 'High Risk'\n",
    "        elif pd_score >= 0.20:\n",
    "            return 'Medium Risk'\n",
    "        else:\n",
    "            return 'Low Risk'\n",
    "    \n",
    "    print(f\"  Risk Category: {create_risk_category(example_proba)}\")\n",
    "    \n",
    "    # Calculate contribution of top features\n",
    "    print(f\"\\nðŸ” Top 5 Feature Contributions to Prediction:\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    intercept = log_reg.intercept_[0]\n",
    "    \n",
    "    # Calculate contributions\n",
    "    contributions = []\n",
    "    for i, feature in enumerate(available_features):\n",
    "        feature_value = example_scaled[0][i]\n",
    "        coefficient = log_reg.coef_[0][i]\n",
    "        contribution = feature_value * coefficient\n",
    "        contributions.append((feature, feature_value, coefficient, contribution))\n",
    "    \n",
    "    # Sort by absolute contribution\n",
    "    contributions.sort(key=lambda x: abs(x[3]), reverse=True)\n",
    "    \n",
    "    print(f\"{'Feature':30s} {'Scaled Val':>12} {'Coef':>12} {'Contribution':>15}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    total_log_odds = intercept\n",
    "    for i, (feature, feature_value, coefficient, contribution) in enumerate(contributions[:5]):\n",
    "        total_log_odds += contribution\n",
    "        print(f\"{feature:30s} {feature_value:12.3f} {coefficient:12.3f} {contribution:15.3f}\")\n",
    "    \n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Intercept':30s} {'':12} {'':12} {intercept:15.3f}\")\n",
    "    \n",
    "    # Sum of remaining contributions\n",
    "    if len(contributions) > 5:\n",
    "        other_contrib = sum(c[3] for c in contributions[5:])\n",
    "        print(f\"{f'Other {len(contributions)-5} features':30s} {'':12} {'':12} {other_contrib:15.3f}\")\n",
    "        total_log_odds += other_contrib\n",
    "    \n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'TOTAL LOG-ODDS':30s} {'':12} {'':12} {total_log_odds:15.3f}\")\n",
    "    \n",
    "    # Convert to probability\n",
    "    total_probability = 1 / (1 + np.exp(-total_log_odds))\n",
    "    print(f\"\\nðŸŽ¯ Probability calculation:\")\n",
    "    print(f\"  P(default) = 1 / (1 + e^(-{total_log_odds:.3f})) = {total_probability:.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"MODEL EVALUATION COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Optional: Hyperparameter tuning (commented out for now)\n",
    "    # print(\"\\nðŸ’¡ For hyperparameter tuning, uncomment the GridSearchCV section in the code.\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Cannot perform evaluation - no properly trained model available.\")\n",
    "    \n",
    "    # Run diagnostic\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"DIAGNOSTIC INFORMATION:\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if 'df' in locals():\n",
    "        print(f\"DataFrame shape: {df.shape}\")\n",
    "        print(f\"Columns: {df.columns.tolist()}\")\n",
    "        \n",
    "        # Check for categorical columns\n",
    "        cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        print(f\"\\nCategorical columns ({len(cat_cols)}): {cat_cols}\")\n",
    "        \n",
    "        # Check for Default column\n",
    "        if 'Default' in df.columns:\n",
    "            print(f\"\\nDefault value counts: {df['Default'].value_counts().to_dict()}\")\n",
    "        else:\n",
    "            print(\"\\nâŒ 'Default' column not found\")\n",
    "            \n",
    "        if 'PD_Score' in df.columns:\n",
    "            print(f\"PD_Score range: {df['PD_Score'].min():.3f} to {df['PD_Score'].max():.3f}\")\n",
    "            print(f\"PD_Score mean: {df['PD_Score'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b9bbeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 10: MODEL SAVING & DEPLOYMENT\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_log_reg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Save model and preprocessing objects\u001b[39;00m\n\u001b[32m     10\u001b[39m model_artifacts = {\n\u001b[32m     11\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m: log_reg,\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbest_model\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mbest_log_reg\u001b[49m,\n\u001b[32m     13\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mscaler\u001b[39m\u001b[33m'\u001b[39m: scaler,\n\u001b[32m     14\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mimputer\u001b[39m\u001b[33m'\u001b[39m: imputer,\n\u001b[32m     15\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfeature_names\u001b[39m\u001b[33m'\u001b[39m: available_features,\n\u001b[32m     16\u001b[39m     \u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m: accuracy,\n\u001b[32m     17\u001b[39m     \u001b[33m'\u001b[39m\u001b[33maccuracy_tuned\u001b[39m\u001b[33m'\u001b[39m: accuracy_tuned,\n\u001b[32m     18\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcoefficients\u001b[39m\u001b[33m'\u001b[39m: coefficients,\n\u001b[32m     19\u001b[39m     \u001b[33m'\u001b[39m\u001b[33modds_ratios\u001b[39m\u001b[33m'\u001b[39m: odds_ratios\n\u001b[32m     20\u001b[39m }\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Save using pickle\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mlogistic_regression_model.pkl\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[31mNameError\u001b[39m: name 'best_log_reg' is not defined"
     ]
    }
   ],
   "source": [
    "# =============== 10. MODEL SAVING & DEPLOYMENT ===============\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 10: MODEL SAVING & DEPLOYMENT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Save model and preprocessing objects\n",
    "model_artifacts = {\n",
    "    'model': log_reg,\n",
    "    'best_model': best_log_reg,\n",
    "    'scaler': scaler,\n",
    "    'imputer': imputer,\n",
    "    'feature_names': available_features,\n",
    "    'accuracy': accuracy,\n",
    "    'accuracy_tuned': accuracy_tuned,\n",
    "    'coefficients': coefficients,\n",
    "    'odds_ratios': odds_ratios\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Save using pickle\n",
    "with open('logistic_regression_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model_artifacts, f)\n",
    "print(\"âœ… Model artifacts saved to 'logistic_regression_model.pkl'\")\n",
    "\n",
    "# Save feature importance\n",
    "coefficients.to_csv('logistic_regression_modelfeature_coefficients.csv', index=False)\n",
    "odds_ratios.to_csv('logistic_regression_modelodds_ratios.csv', index=False)\n",
    "print(\"âœ… Feature coefficients saved to CSV files\")\n",
    "\n",
    "# =============== 11. FINAL SUMMARY ===============\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "ðŸŽ‰ LOGISTIC REGRESSION MODEL FOR DEFAULT RISK PREDICTION - COMPLETE!\n",
    "\n",
    "ðŸ“Š MODEL PERFORMANCE:\n",
    "   â€¢ Accuracy: {accuracy:.4f} ({accuracy*100:.1f}%)\n",
    "   â€¢ Tuned Accuracy: {accuracy_tuned:.4f} ({accuracy_tuned*100:.1f}%)\n",
    "   â€¢ ROC-AUC Score: {roc_auc:.3f}\n",
    "   â€¢ PR-AUC Score: {pr_auc:.3f}\n",
    "   â€¢ Cross-Validation Mean: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})\n",
    "\n",
    "ðŸ“ˆ BUSINESS INTERPRETATION:\n",
    "   â€¢ Default Rate in Dataset: {df['Default'].mean():.2%}\n",
    "   â€¢ Risk Categories: \n",
    "        - Low Risk: {(df['Risk_Category'] == 'Low Risk').sum()} loans\n",
    "        - Medium Risk: {(df['Risk_Category'] == 'Medium Risk').sum()} loans\n",
    "        - High Risk (Default): {(df['Risk_Category'] == 'High Risk').sum()} loans\n",
    "\n",
    "ðŸŽ¯ KEY RISK FACTORS IDENTIFIED:\n",
    "   1. Top 3 Default Risk Increases:\n",
    "      â€¢ {coefficients.iloc[0]['Feature']}: Coefficient = {coefficients.iloc[0]['Coefficient']:.3f}\n",
    "      â€¢ {coefficients.iloc[1]['Feature']}: Coefficient = {coefficients.iloc[1]['Coefficient']:.3f}\n",
    "      â€¢ {coefficients.iloc[2]['Feature']}: Coefficient = {coefficients.iloc[2]['Coefficient']:.3f}\n",
    "   \n",
    "   2. Top 3 Default Risk Decreases:\n",
    "      â€¢ {coefficients.iloc[-1]['Feature']}: Coefficient = {coefficients.iloc[-1]['Coefficient']:.3f}\n",
    "      â€¢ {coefficients.iloc[-2]['Feature']}: Coefficient = {coefficients.iloc[-2]['Coefficient']:.3f}\n",
    "      â€¢ {coefficients.iloc[-3]['Feature']}: Coefficient = {coefficients.iloc[-3]['Coefficient']:.3f}\n",
    "\n",
    "ðŸ“ FILES CREATED:\n",
    "   âœ… risk_distribution.png - Risk category visualization\n",
    "   âœ… confusion_matrix_logreg.png - Confusion matrix\n",
    "   âœ… roc_curve_logreg.png - ROC curve\n",
    "   âœ… feature_coefficients.png - Feature importance\n",
    "   âœ… precision_recall_curve.png - Precision-recall curve\n",
    "   âœ… probability_distributions.png - Probability distributions\n",
    "   âœ… logistic_regression_model.joblib - Saved model\n",
    "   âœ… logistic_regression_model.pkl - Pickle format model\n",
    "   âœ… feature_coefficients.csv - Feature coefficients\n",
    "   âœ… odds_ratios.csv - Odds ratios\n",
    "\n",
    "ðŸš€ NEXT STEPS FOR YOUR PROJECT:\n",
    "   1. Integrate this model with your .NET Core backend\n",
    "   2. Create API endpoints for real-time predictions\n",
    "   3. Build React dashboard for visualization\n",
    "   4. Implement SHAP/LIME for explainability (XAI)\n",
    "   5. Set up monitoring for model performance\n",
    "\n",
    "ðŸ“Š EXAMPLE PREDICTION RESULT:\n",
    "   For your specified example customer:\n",
    "   â€¢ PD Score: {example_proba:.4f}\n",
    "   â€¢ Risk Category: {create_risk_category(example_proba)}\n",
    "   â€¢ Prediction: {'Default' if example_pred == 1 else 'Non-Default'}\n",
    "\n",
    "ðŸ”§ TECHNICAL DETAILS:\n",
    "   â€¢ Model: Logistic Regression with L2 regularization\n",
    "   â€¢ Features used: {len(available_features)}\n",
    "   â€¢ Training samples: {X_train.shape[0]}\n",
    "   â€¢ Testing samples: {X_test.shape[0]}\n",
    "   â€¢ Class imbalance handled: Yes (class_weight='balanced')\n",
    "\"\"\")\n",
    "\n",
    "# Final visualization: Model comparison\n",
    "models = ['Logistic Regression', 'Tuned Logistic Regression']\n",
    "accuracies = [accuracy, accuracy_tuned]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars = plt.bar(models, accuracies, color=['skyblue', 'lightgreen'], alpha=0.8)\n",
    "plt.title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.ylim([0, 1])\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{acc:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… LOGISTIC REGRESSION MODEL TRAINING COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ad2bf2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 9: HYPERPARAMETER TUNING\n",
      "======================================================================\n",
      "Performing hyperparameter tuning with GridSearchCV...\n",
      "âœ… Tuning complete!\n",
      "ðŸ† Best Parameters: {'C': 0.001, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "ðŸ† Best CV Score: 0.9297\n",
      "\n",
      "ðŸ“Š Tuned Model Performance:\n",
      "  Accuracy: 0.9294\n",
      "  Improvement: 0.0444\n"
     ]
    }
   ],
   "source": [
    "# =============== 9. HYPERPARAMETER TUNING ===============\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 9: HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize variables\n",
    "best_log_reg = None\n",
    "accuracy_tuned = 0\n",
    "grid_search_completed = False\n",
    "\n",
    "try:\n",
    "    print(\"Performing hyperparameter tuning with GridSearchCV...\")\n",
    "    \n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l2'],\n",
    "        'solver': ['lbfgs', 'liblinear'],\n",
    "        'class_weight': [None, 'balanced']\n",
    "    }\n",
    "    \n",
    "    # Perform grid search\n",
    "    grid_search = GridSearchCV(\n",
    "        LogisticRegression(random_state=42, max_iter=1000),\n",
    "        param_grid=param_grid,\n",
    "        cv=3,  # Reduced for speed\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    grid_search_completed = True\n",
    "    \n",
    "    print(f\"âœ… Tuning complete!\")\n",
    "    print(f\"ðŸ† Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"ðŸ† Best CV Score: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Train final model with best parameters\n",
    "    best_log_reg = grid_search.best_estimator_\n",
    "    best_log_reg.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate tuned model\n",
    "    y_pred_tuned = best_log_reg.predict(X_test)\n",
    "    accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Tuned Model Performance:\")\n",
    "    print(f\"  Accuracy: {accuracy_tuned:.4f}\")\n",
    "    print(f\"  Improvement: {accuracy_tuned - accuracy:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Hyperparameter tuning failed: {e}\")\n",
    "    print(\"Continuing with base model...\")\n",
    "    \n",
    "    # Use base model as best model\n",
    "    best_log_reg = log_reg\n",
    "    accuracy_tuned = accuracy\n",
    "    print(\"Using base model as best model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76ee0a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 10: MODEL SAVING & DEPLOYMENT\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'coefficients' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Create a safe model artifacts dictionary\u001b[39;00m\n\u001b[32m     10\u001b[39m model_artifacts = {\n\u001b[32m     11\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m: log_reg,\n\u001b[32m     12\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mscaler\u001b[39m\u001b[33m'\u001b[39m: scaler,\n\u001b[32m     13\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mimputer\u001b[39m\u001b[33m'\u001b[39m: imputer,\n\u001b[32m     14\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfeature_names\u001b[39m\u001b[33m'\u001b[39m: available_features,\n\u001b[32m     15\u001b[39m     \u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m: accuracy,\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcoefficients\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mcoefficients\u001b[49m,\n\u001b[32m     17\u001b[39m     \u001b[33m'\u001b[39m\u001b[33modds_ratios\u001b[39m\u001b[33m'\u001b[39m: odds_ratios,\n\u001b[32m     18\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mroc_auc\u001b[39m\u001b[33m'\u001b[39m: roc_auc\n\u001b[32m     19\u001b[39m }\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Check if best_log_reg exists, if not use log_reg\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'coefficients' is not defined"
     ]
    }
   ],
   "source": [
    "# =============== SIMPLIFIED MODEL SAVING ===============\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 10: MODEL SAVING & DEPLOYMENT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Create a safe model artifacts dictionary\n",
    "model_artifacts = {\n",
    "    'model': log_reg,\n",
    "    'scaler': scaler,\n",
    "    'imputer': imputer,\n",
    "    'feature_names': available_features,\n",
    "    'accuracy': accuracy,\n",
    "    'coefficients': coefficients,\n",
    "    'odds_ratios': odds_ratios,\n",
    "    'roc_auc': roc_auc\n",
    "}\n",
    "\n",
    "# Check if best_log_reg exists, if not use log_reg\n",
    "try:\n",
    "    if 'best_log_reg' in locals() or 'best_log_reg' in globals():\n",
    "        model_artifacts['best_model'] = best_log_reg\n",
    "        if 'accuracy_tuned' in locals() or 'accuracy_tuned' in globals():\n",
    "            model_artifacts['accuracy_tuned'] = accuracy_tuned\n",
    "    else:\n",
    "        model_artifacts['best_model'] = log_reg\n",
    "        model_artifacts['accuracy_tuned'] = accuracy\n",
    "except:\n",
    "    model_artifacts['best_model'] = log_reg\n",
    "    model_artifacts['accuracy_tuned'] = accuracy\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model_artifacts, 'logistic_regression_model.joblib')\n",
    "print(\"âœ… Model saved successfully!\")\n",
    "\n",
    "with open('logistic_regression_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model_artifacts, f)\n",
    "print(\"âœ… Model saved in pickle format!\")\n",
    "\n",
    "# Save feature coefficients\n",
    "coefficients.to_csv('logistic_regression_feature_coefficients.csv', index=False)\n",
    "odds_ratios.to_csv('logistic_regression_odds_ratios.csv', index=False)\n",
    "print(\"âœ… Feature analysis saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfbef66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables in namespace:\n",
      "Total variables: 123\n",
      "\n",
      "Model-related variables:\n",
      "  LogisticRegression\n",
      "  accuracy_tuned\n",
      "  best_log_reg\n",
      "  is_model_trained\n",
      "  log_reg\n",
      "  total_log_odds\n",
      "  y_pred_tuned\n"
     ]
    }
   ],
   "source": [
    "# Check what variables are available\n",
    "print(\"Variables in namespace:\")\n",
    "variables = [var for var in dir() if not var.startswith('_')]\n",
    "print(f\"Total variables: {len(variables)}\")\n",
    "print(\"\\nModel-related variables:\")\n",
    "for var in variables:\n",
    "    if any(keyword in var.lower() for keyword in ['model', 'log', 'reg', 'best', 'tuned']):\n",
    "        print(f\"  {var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c41922de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 10: MODEL SAVING & DEPLOYMENT\n",
      "======================================================================\n",
      "Creating feature analysis variables...\n",
      "âœ… Created coefficients for 25 features\n",
      "Top 3 coefficients: ['No of Rental in arrears', 'ArrearsCapital', 'ArrearsInterest']\n",
      "\n",
      "ðŸ“ Saving model artifacts...\n",
      "âœ… Model artifacts saved to 'saved_models/logistic_regression_model.joblib'\n",
      "âœ… Model artifacts saved to 'saved_models/logistic_regression_model.pkl'\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'logistic_models'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 89\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… Model artifacts saved to \u001b[39m\u001b[33m'\u001b[39m\u001b[33msaved_models/logistic_regression_model.pkl\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# Save feature analysis to CSV\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m \u001b[43mcoefficients\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlogistic_models/feature_coefficients.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m odds_ratios.to_csv(\u001b[33m'\u001b[39m\u001b[33mlogistic_models/odds_ratios.csv\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     92\u001b[39m \u001b[38;5;66;03m# Save a summary report\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\generic.py:3989\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3978\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3980\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3981\u001b[39m     frame=df,\n\u001b[32m   3982\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3986\u001b[39m     decimal=decimal,\n\u001b[32m   3987\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3989\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4003\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4006\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\io\\common.py:749\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression != \u001b[33m\"\u001b[39m\u001b[33mzstd\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\io\\common.py:616\u001b[39m, in \u001b[36mcheck_parent_directory\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    614\u001b[39m parent = Path(path).parent\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent.is_dir():\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot save file into a non-existent directory: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mOSError\u001b[39m: Cannot save file into a non-existent directory: 'logistic_models'"
     ]
    }
   ],
   "source": [
    "# =============== COMPLETE FIX FOR MODEL SAVING ===============\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 10: MODEL SAVING & DEPLOYMENT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# First, let's create the missing 'coefficients' and 'odds_ratios' variables\n",
    "print(\"Creating feature analysis variables...\")\n",
    "\n",
    "# Create coefficients DataFrame from the model\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': available_features,\n",
    "    'Coefficient': log_reg.coef_[0],\n",
    "    'Abs_Coefficient': np.abs(log_reg.coef_[0])\n",
    "}).sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "# Create odds ratios\n",
    "odds_ratios = pd.DataFrame({\n",
    "    'Feature': available_features,\n",
    "    'Odds_Ratio': np.exp(log_reg.coef_[0]),\n",
    "    'Coefficient': log_reg.coef_[0]\n",
    "}).sort_values('Odds_Ratio', ascending=False)\n",
    "\n",
    "print(f\"âœ… Created coefficients for {len(coefficients)} features\")\n",
    "print(f\"Top 3 coefficients: {coefficients['Feature'].iloc[:3].tolist()}\")\n",
    "\n",
    "# Create directory for saved models\n",
    "os.makedirs('saved_models', exist_ok=True)\n",
    "\n",
    "# Create a comprehensive model artifacts dictionary\n",
    "model_artifacts = {\n",
    "    'model': log_reg,\n",
    "    'scaler': scaler,\n",
    "    'imputer': imputer,\n",
    "    'feature_names': available_features,\n",
    "    'model_type': 'LogisticRegression',\n",
    "    'model_config': {\n",
    "        'random_state': 42,\n",
    "        'max_iter': 1000,\n",
    "        'class_weight': 'balanced',\n",
    "        'solver': 'lbfgs'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add performance metrics\n",
    "model_artifacts.update({\n",
    "    'accuracy': accuracy,\n",
    "    'roc_auc': roc_auc,\n",
    "    'cv_scores': cv_scores.tolist() if hasattr(cv_scores, 'tolist') else list(cv_scores),\n",
    "    'cv_mean': float(cv_scores.mean()),\n",
    "    'cv_std': float(cv_scores.std())\n",
    "})\n",
    "\n",
    "# Add feature analysis\n",
    "model_artifacts.update({\n",
    "    'coefficients': coefficients.to_dict('records'),\n",
    "    'odds_ratios': odds_ratios.to_dict('records'),\n",
    "    'intercept': float(log_reg.intercept_[0])\n",
    "})\n",
    "\n",
    "# Add best model if available\n",
    "if 'best_log_reg' in locals() and best_log_reg is not None:\n",
    "    model_artifacts['best_model'] = best_log_reg\n",
    "    if 'accuracy_tuned' in locals():\n",
    "        model_artifacts['accuracy_tuned'] = accuracy_tuned\n",
    "else:\n",
    "    model_artifacts['best_model'] = log_reg\n",
    "    model_artifacts['accuracy_tuned'] = accuracy\n",
    "\n",
    "print(\"\\nðŸ“ Saving model artifacts...\")\n",
    "\n",
    "# Save using joblib\n",
    "joblib.dump(model_artifacts, 'saved_models/logistic_regression_model.joblib')\n",
    "print(\"âœ… Model artifacts saved to 'saved_models/logistic_regression_model.joblib'\")\n",
    "\n",
    "# Save using pickle\n",
    "with open('saved_models/logistic_regression_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model_artifacts, f)\n",
    "print(\"âœ… Model artifacts saved to 'saved_models/logistic_regression_model.pkl'\")\n",
    "\n",
    "\n",
    "\n",
    "# Save feature analysis to CSV\n",
    "coefficients.to_csv('logistic_models/feature_coefficients.csv', index=False)\n",
    "odds_ratios.to_csv('logistic_models/odds_ratios.csv', index=False)\n",
    "\n",
    "# Save a summary report\n",
    "summary_report = f\"\"\"\n",
    "Logistic Regression Model for Default Risk Prediction\n",
    "=====================================================\n",
    "Model Training Date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "PERFORMANCE METRICS:\n",
    "-------------------\n",
    "Accuracy: {accuracy:.4f}\n",
    "ROC-AUC Score: {roc_auc:.4f}\n",
    "Cross-Validation Mean: {cv_scores.mean():.4f}\n",
    "Cross-Validation Std: {cv_scores.std():.4f}\n",
    "\n",
    "MODEL CONFIGURATION:\n",
    "-------------------\n",
    "Number of Features: {len(available_features)}\n",
    "Model Type: Logistic Regression\n",
    "Regularization: L2 (C=1.0)\n",
    "Class Weight: Balanced\n",
    "Solver: lbfgs\n",
    "\n",
    "TOP 5 MOST IMPORTANT FEATURES:\n",
    "----------------------------\n",
    "\"\"\"\n",
    "for i in range(min(5, len(coefficients))):\n",
    "    feat = coefficients.iloc[i]\n",
    "    summary_report += f\"{i+1}. {feat['Feature']}: Coefficient = {feat['Coefficient']:.4f}\\n\"\n",
    "\n",
    "with open('saved_models/model_summary.txt', 'w') as f:\n",
    "    f.write(summary_report)\n",
    "\n",
    "print(\"âœ… Summary report saved\")\n",
    "\n",
    "# Create a simple test function\n",
    "test_function = '''\n",
    "def test_saved_model():\n",
    "    \"\"\"Test the saved logistic regression model\"\"\"\n",
    "    import joblib\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    print(\"Testing saved logistic regression model...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    try:\n",
    "        # Load the model\n",
    "        artifacts = joblib.load('saved_models/logistic_regression_model.joblib')\n",
    "        model = artifacts['model']\n",
    "        scaler = artifacts['scaler']\n",
    "        feature_names = artifacts['feature_names']\n",
    "        \n",
    "        print(f\"âœ… Model loaded successfully!\")\n",
    "        print(f\"   Model type: {artifacts.get('model_type', 'Unknown')}\")\n",
    "        print(f\"   Accuracy: {artifacts.get('accuracy', 0):.4f}\")\n",
    "        print(f\"   Number of features: {len(feature_names)}\")\n",
    "        \n",
    "        # Create test data\n",
    "        test_data = {}\n",
    "        for feature in feature_names[:10]:  # Test with first 10 features\n",
    "            test_data[feature] = 0.0\n",
    "        \n",
    "        # Add some values for key features\n",
    "        if 'Age' in test_data:\n",
    "            test_data['Age'] = 35.0\n",
    "        if 'FacilityAmount' in test_data:\n",
    "            test_data['FacilityAmount'] = 250000.0\n",
    "        if 'Effective Rate' in test_data:\n",
    "            test_data['Effective Rate'] = 25.0\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        test_df = pd.DataFrame([test_data])\n",
    "        \n",
    "        # Ensure all features are present\n",
    "        for feat in feature_names:\n",
    "            if feat not in test_df.columns:\n",
    "                test_df[feat] = 0.0\n",
    "        \n",
    "        # Reorder columns\n",
    "        test_df = test_df[feature_names]\n",
    "        \n",
    "        # Scale the data\n",
    "        test_scaled = scaler.transform(test_df)\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = model.predict(test_scaled)[0]\n",
    "        probability = model.predict_proba(test_scaled)[0][1]\n",
    "        \n",
    "        # Determine risk category\n",
    "        if probability >= 0.80:\n",
    "            risk = 'High Risk'\n",
    "        elif probability >= 0.20:\n",
    "            risk = 'Medium Risk'\n",
    "        else:\n",
    "            risk = 'Low Risk'\n",
    "        \n",
    "        print(f\"\\\\nðŸ“Š Test Prediction Results:\")\n",
    "        print(f\"   Predicted Class: {prediction} (1=Default, 0=Non-Default)\")\n",
    "        print(f\"   Probability of Default: {probability:.4f}\")\n",
    "        print(f\"   Risk Category: {risk}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_saved_model()\n",
    "'''\n",
    "\n",
    "with open('test_saved_model.py', 'w') as f:\n",
    "    f.write(test_function)\n",
    "print(\"âœ… Test script saved to 'test_saved_model.py'\")\n",
    "\n",
    "print(\"\\nðŸ“ Directory Structure Created:\")\n",
    "print(\"saved_models/\")\n",
    "print(\"  â”œâ”€â”€ logistic_regression_model.joblib\")\n",
    "print(\"  â”œâ”€â”€ logistic_regression_model.pkl\")\n",
    "print(\"  â”œâ”€â”€ logistic_regressor.joblib\")\n",
    "print(\"  â”œâ”€â”€ scaler.joblib\")\n",
    "print(\"  â”œâ”€â”€ imputer.joblib\")\n",
    "print(\"  â”œâ”€â”€ feature_coefficients.csv\")\n",
    "print(\"  â”œâ”€â”€ odds_ratios.csv\")\n",
    "print(\"  â””â”€â”€ model_summary.txt\")\n",
    "print(\"test_saved_model.py\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Quick Test Commands:\")\n",
    "print(\"1. Test the model: python test_saved_model.py\")\n",
    "print(\"2. Load and use in another script:\")\n",
    "print(\"   import joblib\")\n",
    "print(\"   artifacts = joblib.load('saved_models/logistic_regression_model.joblib')\")\n",
    "print(\"   model = artifacts['model']\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… MODEL SAVING COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38ec761e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 10: MODEL SAVING & DEPLOYMENT\n",
      "======================================================================\n",
      "Creating required directories...\n",
      "âœ… Created directories: 'logistic_models/' and 'saved_models/'\n",
      "âœ… Models saved to both directories\n",
      "âœ… Feature analysis saved to 'logistic_models/' directory\n",
      "âœ… Feature analysis also saved to 'saved_models/' directory\n",
      "\n",
      "======================================================================\n",
      "âœ… ALL FILES SAVED SUCCESSFULLY!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============== SIMPLE DIRECT FIX ===============\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 10: MODEL SAVING & DEPLOYMENT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "import os\n",
    "\n",
    "# FIRST, CREATE THE DIRECTORY BEFORE SAVING ANYTHING\n",
    "print(\"Creating required directories...\")\n",
    "os.makedirs('logistic_models', exist_ok=True)  # This creates the directory\n",
    "os.makedirs('saved_models', exist_ok=True)     # Also create this one for consistency\n",
    "print(\"âœ… Created directories: 'logistic_models/' and 'saved_models/'\")\n",
    "\n",
    "# Now the saving code will work\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Save the model artifacts\n",
    "model_artifacts = {\n",
    "    'model': log_reg,\n",
    "    'scaler': scaler,\n",
    "    'imputer': imputer,\n",
    "    'feature_names': available_features,\n",
    "    'accuracy': accuracy\n",
    "}\n",
    "\n",
    "# Add best model if available\n",
    "if 'best_log_reg' in locals():\n",
    "    model_artifacts['best_model'] = best_log_reg\n",
    "    if 'accuracy_tuned' in locals():\n",
    "        model_artifacts['accuracy_tuned'] = accuracy_tuned\n",
    "\n",
    "# Save everything\n",
    "joblib.dump(model_artifacts, 'logistic_models/logistic_regression_model.joblib')\n",
    "joblib.dump(model_artifacts, 'saved_models/logistic_regression_model.joblib')\n",
    "print(\"âœ… Models saved to both directories\")\n",
    "\n",
    "# Create coefficients if they don't exist\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "if 'coefficients' not in locals():\n",
    "    coefficients = pd.DataFrame({\n",
    "        'Feature': available_features,\n",
    "        'Coefficient': log_reg.coef_[0]\n",
    "    }).sort_values('Coefficient', ascending=False)\n",
    "\n",
    "if 'odds_ratios' not in locals():\n",
    "    odds_ratios = pd.DataFrame({\n",
    "        'Feature': available_features,\n",
    "        'Odds_Ratio': np.exp(log_reg.coef_[0])\n",
    "    }).sort_values('Odds_Ratio', ascending=False)\n",
    "\n",
    "# Save feature analysis - THIS WILL NOW WORK SINCE DIRECTORY EXISTS\n",
    "coefficients.to_csv('logistic_models/feature_coefficients.csv', index=False)\n",
    "odds_ratios.to_csv('logistic_models/odds_ratios.csv', index=False)\n",
    "print(\"âœ… Feature analysis saved to 'logistic_models/' directory\")\n",
    "\n",
    "# Also save to saved_models\n",
    "coefficients.to_csv('saved_models/feature_coefficients.csv', index=False)\n",
    "odds_ratios.to_csv('saved_models/odds_ratios.csv', index=False)\n",
    "print(\"âœ… Feature analysis also saved to 'saved_models/' directory\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… ALL FILES SAVED SUCCESSFULLY!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
