{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d0a7db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0e12580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/7] Loading data...\n",
      "âœ“ Data loaded: 99,888 rows, 10 columns\n",
      "\n",
      "[2/7] Preprocessing data...\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print(\"\\n[1/7] Loading data...\")\n",
    "file_path = 'data.xlsx'  # Change to your file path\n",
    "df = pd.read_excel(file_path)\n",
    "print(f\"âœ“ Data loaded: {df.shape[0]:,} rows, {df.shape[1]} columns\")\n",
    "\n",
    "# Data preprocessing\n",
    "print(\"\\n[2/7] Preprocessing data...\")\n",
    "if 'Due Date' in df.columns:\n",
    "    df['Due Date'] = pd.to_datetime(df['Due Date'], errors='coerce')\n",
    "    df['Days_to_Due'] = (df['Due Date'] - pd.Timestamp.now()).dt.days\n",
    "    df['Months_to_Due'] = df['Days_to_Due'] / 30\n",
    "    df['Years_to_Due'] = df['Days_to_Due'] / 365\n",
    "    df = df.drop('Due Date', axis=1)\n",
    "\n",
    "# Handle missing values\n",
    "df = df.fillna(df.median(numeric_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c791d3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/7] Engineering features...\n",
      "âœ“ Features created: 30 total features\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "print(\"\\n[3/7] Engineering features...\")\n",
    "\n",
    "# Create ratio and interaction features\n",
    "df['Rate_Difference'] = df['Effec. Rate'] - df['Flat Rate']\n",
    "df['Rental_to_Amount_Ratio'] = df['Net Rental'] / (df['Facility amount'] + 1)\n",
    "df['Amount_per_Tenor'] = df['Facility amount'] / (df['Tenor'] + 1)\n",
    "df['Rental_per_Tenor'] = df['Net Rental'] / (df['Tenor'] + 1)\n",
    "df['Arrears_Rate'] = df['No of Rental in arrears'] / (df['Tenor'] + 1)\n",
    "df['Total_Payment'] = df['Net Rental'] * df['Tenor']\n",
    "df['Payment_Capacity'] = df['Facility amount'] / (df['Total_Payment'] + 1)\n",
    "df['Risk_Score'] = df['No of Rental in arrears'] * df['Effec. Rate'] / 100\n",
    "df['Age_Tenor_Interaction'] = df['Age'] * df['Tenor']\n",
    "df['Amount_Rate_Interaction'] = df['Facility amount'] * df['Effec. Rate'] / 100\n",
    "df['Arrears_Amount'] = df['No of Rental in arrears'] * df['Net Rental']\n",
    "\n",
    "# Logarithmic features for skewed data\n",
    "df['Log_Facility_Amount'] = np.log1p(df['Facility amount'])\n",
    "df['Log_Net_Rental'] = np.log1p(df['Net Rental'])\n",
    "\n",
    "# Squared features\n",
    "df['Tenor_Squared'] = df['Tenor'] ** 2\n",
    "df['Age_Squared'] = df['Age'] ** 2\n",
    "df['Arrears_Squared'] = df['No of Rental in arrears'] ** 2\n",
    "\n",
    "# Polynomial features for key variables\n",
    "df['Rate_Squared'] = df['Effec. Rate'] ** 2\n",
    "df['Rate_Cubed'] = df['Effec. Rate'] ** 3\n",
    "\n",
    "print(f\"âœ“ Features created: {df.shape[1]} total features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a11a3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Train set: 79,910 samples | Test set: 19,978 samples\n"
     ]
    }
   ],
   "source": [
    "# Separate features and targets\n",
    "target_columns = ['Impairment', '1 yr ECL']\n",
    "feature_columns = [col for col in df.columns if col not in target_columns]\n",
    "\n",
    "X = df[feature_columns]\n",
    "y_impairment = df['Impairment']\n",
    "y_ecl = df['1 yr ECL']\n",
    "\n",
    "# Split data (80-20 split for large dataset)\n",
    "X_train, X_test, y_imp_train, y_imp_test = train_test_split(\n",
    "    X, y_impairment, test_size=0.2, random_state=42\n",
    ")\n",
    "_, _, y_ecl_train, y_ecl_test = train_test_split(\n",
    "    X, y_ecl, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Train set: {len(X_train):,} samples | Test set: {len(X_test):,} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a4225b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved successfully âœ…\n",
      "\n",
      "[4/7] Initializing advanced models...\n",
      "âœ“ 6 models initialized\n"
     ]
    }
   ],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "try:\n",
    "    joblib.dump(scaler, 'scaler_advanced.pkl')\n",
    "    print(\"Scaler saved successfully âœ…\")\n",
    "except Exception as e:\n",
    "    print(\"Error saving scaler:\", e)\n",
    "\n",
    "# Define advanced models with optimized hyperparameters\n",
    "print(\"\\n[4/7] Initializing advanced models...\")\n",
    "\n",
    "models = {\n",
    "    'Random Forest': RandomForestRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=20,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        max_features='sqrt',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'XGBoost': XGBRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'LightGBM': LGBMRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=15,\n",
    "        learning_rate=0.1,\n",
    "        num_leaves=50,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    ),\n",
    "    'CatBoost': CatBoostRegressor(\n",
    "        iterations=200,\n",
    "        depth=10,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'Ridge (Polynomial)': Ridge(alpha=1.0)\n",
    "}\n",
    "\n",
    "print(f\"âœ“ {len(models)} models initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b4215a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(y_true, y_pred, model_name, target_name):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-10))) * 100\n",
    "    \n",
    "    accuracy_percent = r2 * 100\n",
    "    status = \"âœ“ TARGET ACHIEVED\" if accuracy_percent >= 95 else \"âš  Below target\"\n",
    "    \n",
    "    print(f\"\\n  {model_name} - {target_name}:\")\n",
    "    print(f\"    RÂ² Score: {r2:.6f} ({accuracy_percent:.2f}%) {status}\")\n",
    "    print(f\"    RMSE: {rmse:.4f}\")\n",
    "    print(f\"    MAE: {mae:.4f}\")\n",
    "    print(f\"    MAPE: {mape:.2f}%\")\n",
    "    \n",
    "    return r2, rmse, mae, mape\n",
    "\n",
    "# Store results\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37b51109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5/7] Training models (this may take a few minutes)...\n",
      "\n",
      "======================================================================\n",
      "Training: Random Forest\n",
      "======================================================================\n",
      "\n",
      "--- IMPAIRMENT PREDICTION ---\n",
      "\n",
      "  Random Forest - Impairment:\n",
      "    RÂ² Score: 0.915779 (91.58%) âš  Below target\n",
      "    RMSE: 53717.5022\n",
      "    MAE: 5419.9504\n",
      "    MAPE: 195339157562795.75%\n",
      "    Model saved: random_forest_impairment.pkl\n",
      "\n",
      "--- 1 YR ECL PREDICTION ---\n",
      "\n",
      "  Random Forest - 1 yr ECL:\n",
      "    RÂ² Score: 0.879151 (87.92%) âš  Below target\n",
      "    RMSE: 7229.0728\n",
      "    MAE: 2709.1375\n",
      "    MAPE: 284742932561131.56%\n",
      "    Model saved: random_forest_ecl.pkl\n",
      "\n",
      "======================================================================\n",
      "Training: XGBoost\n",
      "======================================================================\n",
      "\n",
      "--- IMPAIRMENT PREDICTION ---\n",
      "\n",
      "  XGBoost - Impairment:\n",
      "    RÂ² Score: 0.978224 (97.82%) âœ“ TARGET ACHIEVED\n",
      "    RMSE: 27314.2927\n",
      "    MAE: 4845.7441\n",
      "    MAPE: 157433259095566.12%\n",
      "    Model saved: xgboost_impairment.pkl\n",
      "\n",
      "--- 1 YR ECL PREDICTION ---\n",
      "\n",
      "  XGBoost - 1 yr ECL:\n",
      "    RÂ² Score: 0.926418 (92.64%) âš  Below target\n",
      "    RMSE: 5640.8659\n",
      "    MAE: 2275.5480\n",
      "    MAPE: 177670187417804.09%\n",
      "    Model saved: xgboost_ecl.pkl\n",
      "\n",
      "======================================================================\n",
      "Training: LightGBM\n",
      "======================================================================\n",
      "\n",
      "--- IMPAIRMENT PREDICTION ---\n",
      "\n",
      "  LightGBM - Impairment:\n",
      "    RÂ² Score: 0.895909 (89.59%) âš  Below target\n",
      "    RMSE: 59718.7340\n",
      "    MAE: 6853.1781\n",
      "    MAPE: 218458091652220.81%\n",
      "    Model saved: lightgbm_impairment.pkl\n",
      "\n",
      "--- 1 YR ECL PREDICTION ---\n",
      "\n",
      "  LightGBM - 1 yr ECL:\n",
      "    RÂ² Score: 0.844245 (84.42%) âš  Below target\n",
      "    RMSE: 8206.9536\n",
      "    MAE: 3487.9981\n",
      "    MAPE: 373781797821789.25%\n",
      "    Model saved: lightgbm_ecl.pkl\n",
      "\n",
      "======================================================================\n",
      "Training: CatBoost\n",
      "======================================================================\n",
      "\n",
      "--- IMPAIRMENT PREDICTION ---\n",
      "\n",
      "  CatBoost - Impairment:\n",
      "    RÂ² Score: 0.988632 (98.86%) âœ“ TARGET ACHIEVED\n",
      "    RMSE: 19735.2536\n",
      "    MAE: 7149.1768\n",
      "    MAPE: 210083787720639.91%\n",
      "    Model saved: catboost_impairment.pkl\n",
      "\n",
      "--- 1 YR ECL PREDICTION ---\n",
      "\n",
      "  CatBoost - 1 yr ECL:\n",
      "    RÂ² Score: 0.829013 (82.90%) âš  Below target\n",
      "    RMSE: 8598.8951\n",
      "    MAE: 3741.4695\n",
      "    MAPE: 386955431034297.31%\n",
      "    Model saved: catboost_ecl.pkl\n",
      "\n",
      "======================================================================\n",
      "Training: Gradient Boosting\n",
      "======================================================================\n",
      "\n",
      "--- IMPAIRMENT PREDICTION ---\n",
      "\n",
      "  Gradient Boosting - Impairment:\n",
      "    RÂ² Score: 0.995887 (99.59%) âœ“ TARGET ACHIEVED\n",
      "    RMSE: 11870.6937\n",
      "    MAE: 3960.2524\n",
      "    MAPE: 132585157802307.62%\n",
      "    Model saved: gradient_boosting_impairment.pkl\n",
      "\n",
      "--- 1 YR ECL PREDICTION ---\n",
      "\n",
      "  Gradient Boosting - 1 yr ECL:\n",
      "    RÂ² Score: 0.921338 (92.13%) âš  Below target\n",
      "    RMSE: 5832.3408\n",
      "    MAE: 2290.0111\n",
      "    MAPE: 173299873394603.84%\n",
      "    Model saved: gradient_boosting_ecl.pkl\n",
      "\n",
      "======================================================================\n",
      "Training: Ridge (Polynomial)\n",
      "======================================================================\n",
      "\n",
      "--- IMPAIRMENT PREDICTION ---\n",
      "\n",
      "  Ridge (Polynomial) - Impairment:\n",
      "    RÂ² Score: 0.938960 (93.90%) âš  Below target\n",
      "    RMSE: 45731.0518\n",
      "    MAE: 18333.1925\n",
      "    MAPE: 212491306643338.22%\n",
      "    Model saved: ridge_polynomial_impairment.pkl\n",
      "\n",
      "--- 1 YR ECL PREDICTION ---\n",
      "\n",
      "  Ridge (Polynomial) - 1 yr ECL:\n",
      "    RÂ² Score: 0.491765 (49.18%) âš  Below target\n",
      "    RMSE: 14824.9436\n",
      "    MAE: 8258.8042\n",
      "    MAPE: 1254806821006038.00%\n",
      "    Model saved: ridge_polynomial_ecl.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[5/7] Training models (this may take a few minutes)...\")\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Training: {model_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # IMPAIRMENT\n",
    "    print(f\"\\n--- IMPAIRMENT PREDICTION ---\")\n",
    "    model_imp = model.__class__(**model.get_params()) if hasattr(model, 'get_params') else model\n",
    "    model_imp.fit(X_train_scaled, y_imp_train)\n",
    "    y_imp_pred = model_imp.predict(X_test_scaled)\n",
    "    r2_imp, rmse_imp, mae_imp, mape_imp = evaluate_model(\n",
    "        y_imp_test, y_imp_pred, model_name, \"Impairment\"\n",
    "    )\n",
    "    \n",
    "    # Save model\n",
    "    filename = f\"{model_name.replace(' ', '_').replace('(', '').replace(')', '').lower()}_impairment.pkl\"\n",
    "    joblib.dump(model_imp, filename)\n",
    "    print(f\"    Model saved: {filename}\")\n",
    "    \n",
    "    # 1 YR ECL\n",
    "    print(f\"\\n--- 1 YR ECL PREDICTION ---\")\n",
    "    model_ecl = model.__class__(**model.get_params()) if hasattr(model, 'get_params') else model\n",
    "    model_ecl.fit(X_train_scaled, y_ecl_train)\n",
    "    y_ecl_pred = model_ecl.predict(X_test_scaled)\n",
    "    r2_ecl, rmse_ecl, mae_ecl, mape_ecl = evaluate_model(\n",
    "        y_ecl_test, y_ecl_pred, model_name, \"1 yr ECL\"\n",
    "    )\n",
    "    \n",
    "    # Save model\n",
    "    filename = f\"{model_name.replace(' ', '_').replace('(', '').replace(')', '').lower()}_ecl.pkl\"\n",
    "    joblib.dump(model_ecl, filename)\n",
    "    print(f\"    Model saved: {filename}\")\n",
    "    \n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Target': 'Impairment',\n",
    "        'RÂ² Score': r2_imp,\n",
    "        'Accuracy %': r2_imp * 100,\n",
    "        'RMSE': rmse_imp,\n",
    "        'MAE': mae_imp,\n",
    "        'MAPE %': mape_imp,\n",
    "        'Status': 'âœ“ Achieved' if r2_imp * 100 >= 95 else 'âš  Below 95%'\n",
    "    })\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Target': '1 yr ECL',\n",
    "        'RÂ² Score': r2_ecl,\n",
    "        'Accuracy %': r2_ecl * 100,\n",
    "        'RMSE': rmse_ecl,\n",
    "        'MAE': mae_ecl,\n",
    "        'MAPE %': mape_ecl,\n",
    "        'Status': 'âœ“ Achieved' if r2_ecl * 100 >= 95 else 'âš  Below 95%'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40066ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Training ENSEMBLE STACKING MODEL (Meta-Model)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create ensemble stacking model\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Training ENSEMBLE STACKING MODEL (Meta-Model)\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "estimators = [\n",
    "    ('rf', RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)),\n",
    "    ('xgb', XGBRegressor(n_estimators=200, random_state=42, n_jobs=-1)),\n",
    "    ('lgb', LGBMRegressor(n_estimators=200, random_state=42, verbose=-1, n_jobs=-1))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "810f4d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STACKING ENSEMBLE - IMPAIRMENT ---\n",
      "\n",
      "  Stacking Ensemble - Impairment:\n",
      "    RÂ² Score: 0.992412 (99.24%) âœ“ TARGET ACHIEVED\n",
      "    RMSE: 16124.2605\n",
      "    MAE: 4982.4596\n",
      "    MAPE: 154303801377173.34%\n",
      "    Model saved: stacking_ensemble_impairment.pkl\n"
     ]
    }
   ],
   "source": [
    "# Stacking for Impairment\n",
    "print(f\"\\n--- STACKING ENSEMBLE - IMPAIRMENT ---\")\n",
    "stacking_imp = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=Ridge(),\n",
    "    cv=5\n",
    ")\n",
    "stacking_imp.fit(X_train_scaled, y_imp_train)\n",
    "y_imp_pred_stack = stacking_imp.predict(X_test_scaled)\n",
    "r2_imp_stack, rmse_imp_stack, mae_imp_stack, mape_imp_stack = evaluate_model(\n",
    "    y_imp_test, y_imp_pred_stack, \"Stacking Ensemble\", \"Impairment\"\n",
    ")\n",
    "joblib.dump(stacking_imp, 'stacking_ensemble_impairment.pkl')\n",
    "print(f\"    Model saved: stacking_ensemble_impairment.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae0db1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STACKING ENSEMBLE - 1 YR ECL ---\n",
      "\n",
      "  Stacking Ensemble - 1 yr ECL:\n",
      "    RÂ² Score: 0.928455 (92.85%) âš  Below target\n",
      "    RMSE: 5562.2574\n",
      "    MAE: 1899.7495\n",
      "    MAPE: 164874526842369.38%\n",
      "    Model saved: stacking_ensemble_ecl.pkl\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- STACKING ENSEMBLE - 1 YR ECL ---\")\n",
    "stacking_ecl = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=Ridge(),\n",
    "    cv=5\n",
    ")\n",
    "stacking_ecl.fit(X_train_scaled, y_ecl_train)\n",
    "y_ecl_pred_stack = stacking_ecl.predict(X_test_scaled)\n",
    "r2_ecl_stack, rmse_ecl_stack, mae_ecl_stack, mape_ecl_stack = evaluate_model(\n",
    "    y_ecl_test, y_ecl_pred_stack, \"Stacking Ensemble\", \"1 yr ECL\"\n",
    ")\n",
    "joblib.dump(stacking_ecl, 'stacking_ensemble_ecl.pkl')\n",
    "print(f\"    Model saved: stacking_ensemble_ecl.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87eecdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append({\n",
    "    'Model': 'Stacking Ensemble',\n",
    "    'Target': 'Impairment',\n",
    "    'RÂ² Score': r2_imp_stack,\n",
    "    'Accuracy %': r2_imp_stack * 100,\n",
    "    'RMSE': rmse_imp_stack,\n",
    "    'MAE': mae_imp_stack,\n",
    "    'MAPE %': mape_imp_stack,\n",
    "    'Status': 'âœ“ Achieved' if r2_imp_stack * 100 >= 95 else 'âš  Below 95%'\n",
    "})\n",
    "results.append({\n",
    "    'Model': 'Stacking Ensemble',\n",
    "    'Target': '1 yr ECL',\n",
    "    'RÂ² Score': r2_ecl_stack,\n",
    "    'Accuracy %': r2_ecl_stack * 100,\n",
    "    'RMSE': rmse_ecl_stack,\n",
    "    'MAE': mae_ecl_stack,\n",
    "    'MAPE %': mape_ecl_stack,\n",
    "    'Status': 'âœ“ Achieved' if r2_ecl_stack * 100 >= 95 else 'âš  Below 95%'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "914a8700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[6/7] Generating results summary...\n",
      "\n",
      "======================================================================\n",
      "COMPLETE RESULTS SUMMARY\n",
      "======================================================================\n",
      "\n",
      "              Model     Target  RÂ² Score  Accuracy %         RMSE          MAE       MAPE %      Status\n",
      " Stacking Ensemble   1 yr ECL  0.928455   92.845482  5562.257421  1899.749483 1.648745e+14 âš  Below 95%\n",
      "           XGBoost   1 yr ECL  0.926418   92.641831  5640.865915  2275.548013 1.776702e+14 âš  Below 95%\n",
      "           XGBoost   1 yr ECL  0.926418   92.641831  5640.865915  2275.548013 1.776702e+14 âš  Below 95%\n",
      " Gradient Boosting   1 yr ECL  0.921338   92.133818  5832.340819  2290.011066 1.732999e+14 âš  Below 95%\n",
      "     Random Forest   1 yr ECL  0.879151   87.915091  7229.072827  2709.137519 2.847429e+14 âš  Below 95%\n",
      "     Random Forest   1 yr ECL  0.879151   87.915091  7229.072827  2709.137519 2.847429e+14 âš  Below 95%\n",
      "          LightGBM   1 yr ECL  0.844245   84.424495  8206.953551  3487.998092 3.737818e+14 âš  Below 95%\n",
      "          LightGBM   1 yr ECL  0.844245   84.424495  8206.953551  3487.998092 3.737818e+14 âš  Below 95%\n",
      "          CatBoost   1 yr ECL  0.829013   82.901284  8598.895079  3741.469456 3.869554e+14 âš  Below 95%\n",
      "          CatBoost   1 yr ECL  0.829013   82.901284  8598.895079  3741.469456 3.869554e+14 âš  Below 95%\n",
      "Ridge (Polynomial)   1 yr ECL  0.491765   49.176533 14824.943611  8258.804214 1.254807e+15 âš  Below 95%\n",
      " Gradient Boosting Impairment  0.995887   99.588715 11870.693747  3960.252446 1.325852e+14  âœ“ Achieved\n",
      " Stacking Ensemble Impairment  0.992412   99.241160 16124.260480  4982.459612 1.543038e+14  âœ“ Achieved\n",
      "          CatBoost Impairment  0.988632   98.863221 19735.253649  7149.176805 2.100838e+14  âœ“ Achieved\n",
      "          CatBoost Impairment  0.988632   98.863221 19735.253649  7149.176805 2.100838e+14  âœ“ Achieved\n",
      "           XGBoost Impairment  0.978224   97.822438 27314.292674  4845.744132 1.574333e+14  âœ“ Achieved\n",
      "           XGBoost Impairment  0.978224   97.822438 27314.292674  4845.744132 1.574333e+14  âœ“ Achieved\n",
      "Ridge (Polynomial) Impairment  0.938960   93.896023 45731.051805 18333.192538 2.124913e+14 âš  Below 95%\n",
      "     Random Forest Impairment  0.915779   91.577866 53717.502223  5419.950440 1.953392e+14 âš  Below 95%\n",
      "     Random Forest Impairment  0.915779   91.577866 53717.502223  5419.950440 1.953392e+14 âš  Below 95%\n",
      "          LightGBM Impairment  0.895909   89.590935 59718.734033  6853.178052 2.184581e+14 âš  Below 95%\n",
      "          LightGBM Impairment  0.895909   89.590935 59718.734033  6853.178052 2.184581e+14 âš  Below 95%\n",
      "\n",
      "âœ“ Results saved: advanced_model_results.csv\n",
      "\n",
      "======================================================================\n",
      "BEST PERFORMING MODELS\n",
      "======================================================================\n",
      "\n",
      "ðŸ† BEST FOR IMPAIRMENT:\n",
      "   Model: Gradient Boosting\n",
      "   Accuracy: 99.59%\n",
      "   Status: âœ“ Achieved\n",
      "\n",
      "ðŸ† BEST FOR 1 YR ECL:\n",
      "   Model: Stacking Ensemble\n",
      "   Accuracy: 92.85%\n",
      "   Status: âš  Below 95%\n",
      "\n",
      "âœ“ 6 model(s) achieved 95%+ accuracy:\n",
      "   â€¢ Gradient Boosting (Impairment): 99.59%\n",
      "   â€¢ Stacking Ensemble (Impairment): 99.24%\n",
      "   â€¢ CatBoost (Impairment): 98.86%\n",
      "   â€¢ CatBoost (Impairment): 98.86%\n",
      "   â€¢ XGBoost (Impairment): 97.82%\n",
      "   â€¢ XGBoost (Impairment): 97.82%\n",
      "\n",
      "[7/7] Process complete!\n",
      "\n",
      "======================================================================\n",
      "ALL MODELS TRAINED AND EXPORTED SUCCESSFULLY!\n",
      "======================================================================\n",
      "\n",
      "ðŸ“¦ EXPORTED FILES:\n",
      "   â€¢ 22 model files (.pkl)\n",
      "   â€¢ scaler_advanced.pkl\n",
      "   â€¢ advanced_model_results.csv\n",
      "\n",
      "ðŸ’¡ USAGE EXAMPLE:\n",
      "\n",
      "# Load model and scaler\n",
      "import joblib\n",
      "scaler = joblib.load('scaler_advanced.pkl')\n",
      "model = joblib.load('catboost_impairment.pkl')  # Use best model\n",
      "\n",
      "# Prepare new data (must match training features exactly)\n",
      "new_data = pd.DataFrame({...})  # Add all features\n",
      "\n",
      "# Scale and predict\n",
      "new_data_scaled = scaler.transform(new_data)\n",
      "prediction = model.predict(new_data_scaled)\n",
      "print(f'Prediction: {prediction[0]}')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Results summary\n",
    "print(\"\\n[6/7] Generating results summary...\")\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"COMPLETE RESULTS SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(['Target', 'Accuracy %'], ascending=[True, False])\n",
    "\n",
    "print(\"\\n\", results_df.to_string(index=False))\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv('advanced_model_results.csv', index=False)\n",
    "print(f\"\\nâœ“ Results saved: advanced_model_results.csv\")\n",
    "\n",
    "# Best models\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"BEST PERFORMING MODELS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "best_imp = results_df[results_df['Target'] == 'Impairment'].iloc[0]\n",
    "best_ecl = results_df[results_df['Target'] == '1 yr ECL'].iloc[0]\n",
    "\n",
    "print(f\"\\nðŸ† BEST FOR IMPAIRMENT:\")\n",
    "print(f\"   Model: {best_imp['Model']}\")\n",
    "print(f\"   Accuracy: {best_imp['Accuracy %']:.2f}%\")\n",
    "print(f\"   Status: {best_imp['Status']}\")\n",
    "\n",
    "print(f\"\\nðŸ† BEST FOR 1 YR ECL:\")\n",
    "print(f\"   Model: {best_ecl['Model']}\")\n",
    "print(f\"   Accuracy: {best_ecl['Accuracy %']:.2f}%\")\n",
    "print(f\"   Status: {best_ecl['Status']}\")\n",
    "\n",
    "# Models achieving 95%+\n",
    "achieving_target = results_df[results_df['Accuracy %'] >= 95]\n",
    "if len(achieving_target) > 0:\n",
    "    print(f\"\\nâœ“ {len(achieving_target)} model(s) achieved 95%+ accuracy:\")\n",
    "    for _, row in achieving_target.iterrows():\n",
    "        print(f\"   â€¢ {row['Model']} ({row['Target']}): {row['Accuracy %']:.2f}%\")\n",
    "else:\n",
    "    print(\"\\nâš  No models achieved 95%+ accuracy yet.\")\n",
    "    print(\"   Consider:\")\n",
    "    print(\"   1. Check if Impairment/ECL are highly correlated with input features\")\n",
    "    print(\"   2. Add domain-specific features\")\n",
    "    print(\"   3. Check for data quality issues\")\n",
    "    print(\"   4. Try hyperparameter tuning (GridSearchCV)\")\n",
    "\n",
    "print(f\"\\n[7/7] Process complete!\")\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"ALL MODELS TRAINED AND EXPORTED SUCCESSFULLY!\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "print(\"\\nðŸ“¦ EXPORTED FILES:\")\n",
    "print(f\"   â€¢ {len(results_df)} model files (.pkl)\")\n",
    "print(\"   â€¢ scaler_advanced.pkl\")\n",
    "print(\"   â€¢ advanced_model_results.csv\")\n",
    "\n",
    "print(\"\\nðŸ’¡ USAGE EXAMPLE:\")\n",
    "print(\"\"\"\n",
    "# Load model and scaler\n",
    "import joblib\n",
    "scaler = joblib.load('scaler_advanced.pkl')\n",
    "model = joblib.load('catboost_impairment.pkl')  # Use best model\n",
    "\n",
    "# Prepare new data (must match training features exactly)\n",
    "new_data = pd.DataFrame({...})  # Add all features\n",
    "\n",
    "# Scale and predict\n",
    "new_data_scaled = scaler.transform(new_data)\n",
    "prediction = model.predict(new_data_scaled)\n",
    "print(f'Prediction: {prediction[0]}')\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
